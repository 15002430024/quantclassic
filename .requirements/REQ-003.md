# REQ-003: 滚动窗口训练后回测格式转换 OOM 崩溃排查与修复方案

**创建时间**: 2026-02-06 14:30  
**状态**: 待实施（Notebook 优先）

---

## 1. 需求背景

在 notebook `notebook/lstm+attention12011427.ipynb` 的步骤 3-DYNAMIC 中，15 个滚动窗口训练已完成（日志显示总预测样本 11,553,790、总耗时 25,193.1s）。  
Kernel 崩溃发生在同一单元步骤 5：

> `5️⃣ 转换为回测系统兼容格式...`

崩溃无 Python traceback，符合进程被系统 OOM Kill 的特征。

本需求仅处理「格式转换阶段的内存稳定性」，IC 计算口径修正见 `REQ-004`。

## 2. 已确认现状（基于当前代码）

1. `RollingDailyTrainer.get_all_predictions()` 最终调用 `pd.concat(self.all_predictions, ignore_index=True)` 合并 15 个窗口预测，存在一次额外峰值。
2. notebook 步骤 5 先拼接全量原始数据再取 3 列：
   - `pd.concat([dm._train_df, dm._val_df, dm._test_df], ignore_index=True)`
   - 然后才选 `trade_date/order_book_id/y_ret_10d`
3. 紧接着执行大表 `merge`，且中间变量未及时释放。
4. 预测结果在 `window_result.predictions` 与 `self.all_predictions` 中重复持有，训练后内存压力持续偏高。

## 3. 核心问题

1. 多次 `concat/merge` 叠加导致峰值内存不可控。
2. 构建 `df_returns` 时先拼全量列，造成不必要的内存复制。
3. `merge` 前若键（`trade_date`, `order_book_id`）出现重复，会导致行数膨胀并放大 OOM 风险。
4. 训练后未释放大对象，步骤 5 在高碎片状态下更容易被杀进程。

## 4. 解决方案

### 4.1 必做（仅改 notebook 单元，优先用于调试）

#### 步骤 1：在步骤 5 前做显式内存回收

```python
# 仅当后续不再依赖 window_loaders 时释放
del window_loaders

# 如果后续单元不需要逐窗口明细预测，可释放重复引用
KEEP_WINDOW_PREDICTIONS = False
if not KEEP_WINDOW_PREDICTIONS:
    for wr in results.get('window_results', []):
        wr.predictions = None

if torch.cuda.is_available():
    torch.cuda.empty_cache()
gc.collect()
```

#### 步骤 2：只拼接必要列构建 `df_returns`

```python
return_col_name = 'y_ret_10d' if 'y_ret_10d' in dm._train_df.columns else dm.config.label_col
cols_needed = ['trade_date', 'order_book_id', return_col_name]

df_returns = pd.concat([
    dm._train_df[cols_needed],
    dm._val_df[cols_needed],
    dm._test_df[cols_needed],
], ignore_index=True)

df_returns['trade_date'] = pd.to_datetime(df_returns['trade_date'])
df_returns = df_returns.rename(columns={return_col_name: 'future_return'})
```

#### 步骤 3：`merge` 前先去重键，避免行数膨胀

```python
df_returns = df_returns.drop_duplicates(
    subset=['trade_date', 'order_book_id'],
    keep='last'
)
```

#### 步骤 4：`merge` 后立即释放中间变量

```python
all_predictions_df = all_predictions_df.merge(
    df_returns, on=['trade_date', 'order_book_id'], how='left'
)
del df_returns
gc.collect()
```

### 4.2 可选（源码优化，非本次 notebook 调试阻塞项）

1. 在 `model/train/rolling_window_trainer.py` 的 `get_all_predictions()` 增加 `release` 参数，`concat` 后可选清空 `self.all_predictions`。
2. 增加训练后统一释放预测缓存的接口，避免 notebook 手工清理。

## 5. 需要修改的文件

| 文件路径 | 修改类型 | 优先级 | 修改说明 |
|---------|---------|--------|---------|
| `notebook/lstm+attention12011427.ipynb`（步骤 3-DYNAMIC 单元） | 修改 | 必做 | 步骤 5 前清理内存；仅拼 3 列构建 `df_returns`；`merge` 前去重键；`merge` 后释放中间变量 |
| `model/train/rolling_window_trainer.py` | 修改 | 可选 | `get_all_predictions()` 增加 `release` 参数，减少双份驻留 |

## 6. 验收标准

1. 步骤 3-DYNAMIC 单元可执行到 `rolling_dynamic_results` 生成完成，Kernel 不崩溃。
2. `all_predictions_df` 在 merge 前后行数一致（left join 不放大行数）。
3. `future_return` 非空样本数达到预期（以当前测试集覆盖范围为准）。
4. 系统监控中未再出现该单元阶段的 OOM Kill。

## 7. 风险与注意事项

- 若后续单元需要逐窗口预测明细，不能提前清空 `wr.predictions`。
- `drop_duplicates(keep='last')` 的保留规则需与数据口径一致（如需可改为 `first`）。
- 本需求不处理 IC 方法/因子聚合口径；相关变更在 `REQ-004`，建议与本需求联调但分阶段落地。
- 建议优先复用已保存模型 `output/rolling_models_dynamic/` 验证步骤 5，避免重复 7 小时训练。

## 8. 依赖关系

- **前置条件**：滚动窗口模型已可从 `output/rolling_models_dynamic/` 读取。
- **关联需求**：`REQ-004`（IC 计算口径修正）。

---
*变更记录: 2026-02-06 初始创建*  
*变更记录: 2026-02-06 复核后更新：补充 merge 前键去重、Notebook 优先策略、验收标准与风险边界*
