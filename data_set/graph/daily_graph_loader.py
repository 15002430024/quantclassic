"""
daily_graph_loader.py - æ—¥æ‰¹æ¬¡æ•°æ®åŠ è½½å™¨

å®ç°æŒ‰äº¤æ˜“æ—¥ç»„ç»‡çš„æ•°æ®åŠ è½½ï¼Œæ¯ä¸ª batch åŒ…å«å½“æ—¥æ‰€æœ‰è‚¡ç¥¨ã€‚
æ”¯æŒåŠ¨æ€å›¾æ„å»ºï¼šåœ¨ collate_fn ä¸­è°ƒç”¨ GraphBuilder ç”Ÿæˆé‚»æ¥çŸ©é˜µã€‚

æ ¸å¿ƒç»„ä»¶ï¼š
1. DailyBatchDataset: æŒ‰æ—¥ç»„ç»‡æ•°æ®ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯ä¸€å¤©çš„æ‰€æœ‰è‚¡ç¥¨
2. collate_daily: è‡ªå®šä¹‰ collate_fnï¼Œè½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
3. DailyGraphDataLoader: å°è£… DataLoaderï¼Œæä¾›ä¾¿æ·æ¥å£

ä½¿ç”¨ç¤ºä¾‹ï¼š
    from quantclassic.data_set.graph import (
        DailyBatchDataset, DailyGraphDataLoader
    )
    from quantclassic.data_processor.graph_builder import CorrGraphBuilder
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = DailyBatchDataset(
        df=df,
        feature_cols=feature_cols,
        label_col='alpha_label',
        window_size=20,
        time_col='trade_date',
        stock_col='order_book_id'
    )
    
    # åˆ›å»ºå›¾æ„å»ºå™¨
    graph_builder = CorrGraphBuilder(method='cosine', top_k=10)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    loader = DailyGraphDataLoader(
        dataset=dataset,
        graph_builder=graph_builder,
        shuffle_dates=True
    )
    
    # è®­ç»ƒå¾ªç¯
    for batch in loader:
        X, y, adj, stock_ids, date = batch
        logits = model(X, adj)
        loss = criterion(logits, y)
"""

import torch
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from typing import List, Tuple, Optional, Dict, Any, Union, Callable
from dataclasses import dataclass, field
import logging
from pathlib import Path

try:
    from ...config.base_config import BaseConfig
except ImportError:
    from config.base_config import BaseConfig


@dataclass
class DailyLoaderConfig(BaseConfig):
    """æ—¥æ‰¹æ¬¡åŠ è½½å™¨é…ç½®"""
    # åŸºç¡€é…ç½®
    window_size: int = 20
    feature_cols: Optional[List[str]] = None
    label_col: str = 'alpha_label'
    stock_col: str = 'order_book_id'
    time_col: str = 'trade_date'
    
    # çª—å£å˜æ¢
    enable_window_transform: bool = True
    window_price_log: bool = True
    window_volume_norm: bool = True
    price_cols: List[str] = field(default_factory=lambda: ['open', 'high', 'low', 'close', 'vwap'])
    close_col: str = 'close'
    volume_cols: List[str] = field(default_factory=lambda: ['vol', 'amount'])
    
    # æ ‡ç­¾å¤„ç†
    label_rank_normalize: bool = True
    label_rank_output_range: Tuple[float, float] = (-1, 1)
    
    # åŠ è½½å™¨é…ç½®
    shuffle_dates: bool = True
    num_workers: int = 0  # æ—¥æ‰¹æ¬¡æ¨¡å¼å»ºè®®å•è¿›ç¨‹
    pin_memory: bool = True
    
    # å›¾æ„å»ºé…ç½®ï¼ˆå¯é€‰ï¼‰
    graph_builder_config: Optional[Dict] = None


class DailyBatchDataset(Dataset):
    """
    æ—¥æ‰¹æ¬¡æ•°æ®é›†
    
    å°†æ•°æ®æŒ‰äº¤æ˜“æ—¥ç»„ç»‡ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯ä¸€å¤©çš„æ‰€æœ‰è‚¡ç¥¨æ•°æ®ã€‚
    é€‚ç”¨äº GNN è®­ç»ƒåœºæ™¯ï¼Œéœ€è¦åŒæ—¶çœ‹åˆ°å½“æ—¥æ‰€æœ‰è‚¡ç¥¨ã€‚
    
    ä¸ä¼ ç»Ÿ Dataset çš„åŒºåˆ«ï¼š
    - ä¼ ç»Ÿ: __getitem__ è¿”å›å•åªè‚¡ç¥¨çš„ (X, y)
    - æœ¬ç±»: __getitem__ è¿”å›å½“æ—¥æ‰€æœ‰è‚¡ç¥¨çš„ (X_day, y_day, stock_ids)
    
    Args:
        df: åŒ…å«æ‰€æœ‰è‚¡ç¥¨æ—¶åºæ•°æ®çš„ DataFrame
        feature_cols: ç‰¹å¾åˆ—åˆ—è¡¨
        label_col: æ ‡ç­¾åˆ—
        window_size: æ—¶é—´çª—å£å¤§å°
        time_col: æ—¶é—´åˆ—å
        stock_col: è‚¡ç¥¨ä»£ç åˆ—å
        enable_window_transform: æ˜¯å¦å¯ç”¨çª—å£çº§å˜æ¢
        window_price_log: æ˜¯å¦å¯¹ä»·æ ¼åšå¯¹æ•°å˜æ¢
        window_volume_norm: æ˜¯å¦å¯¹æˆäº¤é‡åšçª—å£å†…æ ‡å‡†åŒ–
        price_cols: ä»·æ ¼åˆ—åˆ—è¡¨
        close_col: æ”¶ç›˜ä»·åˆ—å
        volume_cols: æˆäº¤é‡åˆ—åˆ—è¡¨
        label_rank_normalize: æ˜¯å¦å¯¹æ ‡ç­¾åšæˆªé¢æ’åæ ‡å‡†åŒ–
        label_rank_output_range: æ’åæ ‡å‡†åŒ–è¾“å‡ºèŒƒå›´
    """
    
    def __init__(
        self,
        df: pd.DataFrame,
        feature_cols: List[str],
        label_col: str,
        window_size: int = 20,
        time_col: str = 'trade_date',
        stock_col: str = 'order_book_id',
        enable_window_transform: bool = True,
        window_price_log: bool = True,
        window_volume_norm: bool = True,
        price_cols: Optional[List[str]] = None,
        close_col: str = 'close',
        volume_cols: Optional[List[str]] = None,
        label_rank_normalize: bool = True,
        label_rank_output_range: Tuple[float, float] = (-1, 1),
        valid_label_start_date: Optional[pd.Timestamp] = None
    ):
        self.df = df.copy()
        self.feature_cols = feature_cols
        self.label_col = label_col
        self.window_size = window_size
        self.time_col = time_col
        self.stock_col = stock_col
        self.valid_label_start_date = valid_label_start_date
        
        # çª—å£å˜æ¢é…ç½®
        self.enable_window_transform = enable_window_transform
        self.window_price_log = window_price_log
        self.window_volume_norm = window_volume_norm
        self.price_cols = price_cols or ['open', 'high', 'low', 'close', 'vwap']
        self.close_col = close_col
        self.volume_cols = volume_cols or ['vol', 'amount']
        
        # æ ‡ç­¾å¤„ç†é…ç½®
        self.label_rank_normalize = label_rank_normalize
        self.label_rank_output_range = label_rank_output_range
        
        # é¢„è®¡ç®—ç‰¹å¾åˆ—ç´¢å¼•
        self._price_indices = [i for i, col in enumerate(feature_cols) if col in self.price_cols]
        self._close_index = feature_cols.index(close_col) if close_col in feature_cols else None
        self._volume_indices = [i for i, col in enumerate(feature_cols) if col in self.volume_cols]
        
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # æ„å»ºæ•°æ®ç´¢å¼•
        self._build_index()
    
    def _build_index(self):
        """
        æ„å»ºæ•°æ®ç´¢å¼•
        
        æŒ‰æ—¥æœŸç»„ç»‡æ•°æ®ï¼Œè®°å½•æ¯å¤©å¯ç”¨çš„è‚¡ç¥¨åŠå…¶æ—¶åºæ•°æ®ä½ç½®
        """
        self.logger.info("æ„å»ºæ—¥æ‰¹æ¬¡æ•°æ®ç´¢å¼•...")
        
        # ç¡®ä¿æ—¶é—´åˆ—æ˜¯ datetime
        self.df[self.time_col] = pd.to_datetime(self.df[self.time_col])
        
        # è·å–æ‰€æœ‰å”¯ä¸€æ—¥æœŸå¹¶æ’åºï¼ˆç›´æ¥ä½¿ç”¨ pandas DatetimeIndexï¼‰
        all_dates = pd.DatetimeIndex(sorted(self.df[self.time_col].unique()))
        
        # è¿‡æ»¤ï¼šåªä¿ç•™æœ‰è¶³å¤Ÿå†å²æ•°æ®çš„æ—¥æœŸ
        # éœ€è¦è‡³å°‘ window_size å¤©çš„å†å²æ•°æ®
        if len(all_dates) <= self.window_size:
            self.valid_dates = []
            self.date_to_stocks = {}
            self.stock_data = {}
            self.logger.warning(f"æ•°æ®å¤©æ•° ({len(all_dates)}) ä¸è¶³ window_size ({self.window_size})")
            return
        
        # æœ‰æ•ˆæ—¥æœŸæ˜¯ä»ç¬¬ window_size å¤©å¼€å§‹
        self.valid_dates = list(all_dates[self.window_size:])
        
        # å¦‚æœè®¾ç½®äº†æœ‰æ•ˆæ ‡ç­¾èµ·å§‹æ—¥æœŸï¼Œè¿›ä¸€æ­¥è¿‡æ»¤
        if self.valid_label_start_date is not None:
            self.valid_dates = [d for d in self.valid_dates if d >= self.valid_label_start_date]
        
        # åˆ›å»ºæ—¥æœŸåˆ°ç´¢å¼•çš„å…¨å±€æ˜ å°„ï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
        date_to_global_idx = {d: i for i, d in enumerate(all_dates)}
        
        # é¢„æ„å»ºæ¯åªè‚¡ç¥¨çš„å®Œæ•´æ—¶åºæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼šé¿å…é€è¡Œ pd.Timestamp è½¬æ¢ï¼‰
        self.stock_data = {}
        self.logger.info(f"  æ­£åœ¨æ„å»º {self.df[self.stock_col].nunique()} åªè‚¡ç¥¨çš„ç´¢å¼•...")
        
        for stock, group in self.df.groupby(self.stock_col):
            group_sorted = group.sort_values(self.time_col)
            
            # æå–ç‰¹å¾å’Œæ ‡ç­¾æ•°ç»„
            features = group_sorted[self.feature_cols].values.astype(np.float32)
            labels = group_sorted[self.label_col].values.astype(np.float32)
            # ğŸ”§ ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨ DatetimeIndexï¼Œé¿å…é€ä¸ªè½¬æ¢
            dates = pd.DatetimeIndex(group_sorted[self.time_col].values)
            
            self.stock_data[stock] = {
                'features': features,
                'labels': labels,
                'dates': dates,
                'date_to_idx': {d: i for i, d in enumerate(dates)}
            }
        
        # ğŸ”§ ä¼˜åŒ–ï¼šåå‘æ„å»º - å…ˆéå†è‚¡ç¥¨ï¼Œå†åˆ†é…åˆ°æ—¥æœŸ
        # æ¯”åŒå±‚å¾ªç¯å¿« 10 å€ä»¥ä¸Š
        self.logger.info(f"  æ­£åœ¨æ„å»ºæ¯æ—¥å¯ç”¨è‚¡ç¥¨åˆ—è¡¨...")
        from collections import defaultdict
        date_to_stocks_tmp = defaultdict(list)
        valid_dates_set = set(self.valid_dates)  # é¢„è®¡ç®— setï¼Œé¿å…é‡å¤åˆ›å»º
        
        for stock, data in self.stock_data.items():
            # æ‰¾å‡ºè¯¥è‚¡ç¥¨æœ‰è¶³å¤Ÿå†å²çª—å£çš„æ‰€æœ‰æ—¥æœŸ
            for i, date in enumerate(data['dates']):
                if i >= self.window_size and date in valid_dates_set:
                    date_to_stocks_tmp[date].append(stock)
        
        # æ’åºå¹¶è½¬æ¢ä¸ºæ™®é€š dict
        self.date_to_stocks = {
            date: sorted(stocks) 
            for date, stocks in date_to_stocks_tmp.items() 
            if stocks
        }
        
        # æ›´æ–°æœ‰æ•ˆæ—¥æœŸåˆ—è¡¨ï¼ˆæ’é™¤æ²¡æœ‰è‚¡ç¥¨çš„æ—¥æœŸï¼‰
        self.valid_dates = [d for d in self.valid_dates if d in self.date_to_stocks]
        
        self.logger.info(f"  æœ‰æ•ˆæ—¥æœŸ: {len(self.valid_dates)} å¤©")
        if self.valid_dates:
            avg_stocks = np.mean([len(self.date_to_stocks[d]) for d in self.valid_dates])
            self.logger.info(f"  å¹³å‡æ¯æ—¥è‚¡ç¥¨æ•°: {avg_stocks:.1f}")
    
    def __len__(self) -> int:
        """è¿”å›æœ‰æ•ˆæ—¥æœŸæ•°"""
        return len(self.valid_dates)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰è‚¡ç¥¨æ•°æ® (æ—¥æ‰¹æ¬¡æ¨¡å¼æ ¸å¿ƒå®ç° - ä¼˜åŒ–ç‰ˆ)
        
        âš ï¸ å…³é”®åŒºåˆ«ï¼šä¸ä¼ ç»Ÿ Dataset ä¸åŒï¼Œè¿™é‡Œè¿”å›çš„æ˜¯ä¸€å¤©ä¸­æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ®
        - ä¼ ç»Ÿæ¨¡å¼: __getitem__(idx) -> (X[T, F], y) å•åªè‚¡ç¥¨
        - æ—¥æ‰¹æ¬¡æ¨¡å¼: __getitem__(idx) -> {features:[N,T,F], labels:[N]} Nåªè‚¡ç¥¨
        
        æ€§èƒ½ä¼˜åŒ–ï¼š
        - é¢„åˆ†é… numpy æ•°ç»„ï¼Œé¿å…åŠ¨æ€åˆ—è¡¨æ‰©å±•
        - æ‰¹é‡åˆ‡ç‰‡æå–çª—å£ï¼Œå‡å°‘ Python å¾ªç¯å¼€é”€
        - æ‰¹é‡åº”ç”¨çª—å£å˜æ¢ï¼Œä½¿ç”¨å‘é‡åŒ–æ“ä½œ
        
        Args:
            idx: æ—¥æœŸç´¢å¼• (0 ~ len(valid_dates)-1)
            
        Returns:
            Dict åŒ…å«:
                - 'features': [N, T, F] ç‰¹å¾å¼ é‡ (N=å½“æ—¥è‚¡ç¥¨æ•°, T=æ—¶é—´çª—å£, F=ç‰¹å¾ç»´åº¦)
                - 'labels': [N] æ ‡ç­¾å¼ é‡
                - 'stock_ids': List[str] è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆé•¿åº¦ä¸ºNï¼‰
                - 'date': pd.Timestamp å½“å‰æ—¥æœŸ
                - 'n_stocks': int æœ‰æ•ˆè‚¡ç¥¨æ•°é‡
        """
        # ======================================================================
        # æ­¥éª¤1: æŒ‰æ—¥æœŸç´¢å¼•æŸ¥æ‰¾å½“æ—¥çš„è‚¡ç¥¨åˆ—è¡¨
        # ======================================================================
        date = self.valid_dates[idx]
        stocks = self.date_to_stocks[date]
        n_stocks = len(stocks)
        n_features = len(self.feature_cols)
        
        if n_stocks == 0:
            return {
                'features': torch.zeros(0, self.window_size, n_features),
                'labels': torch.zeros(0),
                'stock_ids': [],
                'date': date,
                'n_stocks': 0
            }
        
        # ======================================================================
        # æ­¥éª¤2: é¢„åˆ†é…æ•°ç»„ï¼Œæ‰¹é‡æå–çª—å£ï¼ˆæ€§èƒ½å…³é”®ï¼‰
        # ======================================================================
        # é¢„åˆ†é…ï¼Œé¿å…åŠ¨æ€æ‰©å±•
        features_array = np.empty((n_stocks, self.window_size, n_features), dtype=np.float32)
        labels_array = np.empty(n_stocks, dtype=np.float32)
        valid_mask = np.ones(n_stocks, dtype=bool)
        
        for i, stock in enumerate(stocks):
            data = self.stock_data[stock]
            stock_idx = data['date_to_idx'][date]
            
            # çª—å£åˆ‡ç‰‡ï¼ˆnumpy åˆ‡ç‰‡æ˜¯ O(1) è§†å›¾æ“ä½œï¼‰
            start_idx = stock_idx - self.window_size
            features_array[i] = data['features'][start_idx:stock_idx]
            labels_array[i] = data['labels'][stock_idx]
            
            # æ ‡è®°æ— æ•ˆæ ·æœ¬ï¼ˆæ ‡ç­¾ç¼ºå¤±ï¼‰
            if np.isnan(labels_array[i]):
                valid_mask[i] = False
        
        # ======================================================================
        # æ­¥éª¤3: è¿‡æ»¤æ— æ•ˆæ ·æœ¬
        # ======================================================================
        if not valid_mask.all():
            features_array = features_array[valid_mask]
            labels_array = labels_array[valid_mask]
            valid_stocks = [s for s, m in zip(stocks, valid_mask) if m]
        else:
            valid_stocks = stocks
        
        # å¤„ç†ç©ºæ•°æ®
        if len(valid_stocks) == 0:
            return {
                'features': torch.zeros(0, self.window_size, n_features),
                'labels': torch.zeros(0),
                'stock_ids': [],
                'date': date,
                'n_stocks': 0
            }
        
        # ======================================================================
        # æ­¥éª¤4: æ‰¹é‡åº”ç”¨çª—å£å˜æ¢ï¼ˆå‘é‡åŒ–æ“ä½œï¼Œæ¯”é€ä¸ªå˜æ¢å¿« 10 å€ï¼‰
        # ======================================================================
        if self.enable_window_transform:
            features_array = self._apply_window_transform_batch(features_array)
        
        # ======================================================================
        # æ­¥éª¤5: è½¬æ¢ä¸º Tensor
        # ======================================================================
        features = torch.from_numpy(features_array)
        labels = torch.from_numpy(labels_array)
        
        # ======================================================================
        # æ­¥éª¤6: æ ‡ç­¾æˆªé¢æ’åæ ‡å‡†åŒ–
        # ======================================================================
        if self.label_rank_normalize and len(labels) > 1:
            labels = self._rank_normalize(labels)
        
        return {
            'features': features,
            'labels': labels,
            'stock_ids': valid_stocks,
            'date': date,
            'n_stocks': len(valid_stocks)
        }
    
    def _apply_window_transform(self, window: np.ndarray) -> np.ndarray:
        """
        åº”ç”¨çª—å£çº§å˜æ¢ï¼ˆå‘é‡åŒ–ä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            window: [T, F] çª—å£æ•°æ®
            
        Returns:
            å˜æ¢åçš„çª—å£æ•°æ®
        """
        # ä½¿ç”¨è§†å›¾é¿å…ä¸å¿…è¦çš„æ‹·è´
        window = window.copy()
        
        # ä»·æ ¼å¯¹æ•°å˜æ¢: log(price / close_T) - å‘é‡åŒ–
        if self.window_price_log and self._close_index is not None and self._price_indices:
            close_T = window[-1, self._close_index]
            if close_T > 0:
                price_cols = np.array(self._price_indices)
                prices = window[:, price_cols]
                prices = np.maximum(prices, 1e-8)
                window[:, price_cols] = np.log(prices / close_T)
        
        # æˆäº¤é‡çª—å£æ ‡å‡†åŒ–: volume / mean(volume) - å‘é‡åŒ–
        if self.window_volume_norm and self._volume_indices:
            vol_cols = np.array(self._volume_indices)
            volumes = window[:, vol_cols]
            mean_vols = np.mean(volumes, axis=0, keepdims=True)
            mean_vols = np.maximum(mean_vols, 1e-8)  # é¿å…é™¤é›¶
            window[:, vol_cols] = volumes / mean_vols
        
        # å¤„ç† NaN å’Œ Inf
        np.nan_to_num(window, copy=False, nan=0.0, posinf=0.0, neginf=0.0)
        
        return window
    
    def _apply_window_transform_batch(self, windows: np.ndarray) -> np.ndarray:
        """
        æ‰¹é‡åº”ç”¨çª—å£çº§å˜æ¢ï¼ˆå‘é‡åŒ–ä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            windows: [N, T, F] æ‰¹é‡çª—å£æ•°æ®
            
        Returns:
            å˜æ¢åçš„çª—å£æ•°æ® [N, T, F]
        """
        # ä»·æ ¼å¯¹æ•°å˜æ¢: log(price / close_T) - å‘é‡åŒ–
        if self.window_price_log and self._close_index is not None and self._price_indices:
            price_cols = np.array(self._price_indices)
            # close_T: [N, 1]
            close_T = windows[:, -1:, self._close_index:self._close_index+1]
            close_T = np.maximum(close_T, 1e-8)
            # prices: [N, T, len(price_cols)]
            prices = windows[:, :, price_cols]
            prices = np.maximum(prices, 1e-8)
            windows[:, :, price_cols] = np.log(prices / close_T)
        
        # æˆäº¤é‡çª—å£æ ‡å‡†åŒ–: volume / mean(volume) - å‘é‡åŒ–
        if self.window_volume_norm and self._volume_indices:
            vol_cols = np.array(self._volume_indices)
            volumes = windows[:, :, vol_cols]  # [N, T, len(vol_cols)]
            mean_vols = np.mean(volumes, axis=1, keepdims=True)  # [N, 1, len(vol_cols)]
            mean_vols = np.maximum(mean_vols, 1e-8)
            windows[:, :, vol_cols] = volumes / mean_vols
        
        # å¤„ç† NaN å’Œ Inf
        np.nan_to_num(windows, copy=False, nan=0.0, posinf=0.0, neginf=0.0)
        
        return windows
    
    def _rank_normalize(self, labels: torch.Tensor) -> torch.Tensor:
        """
        æˆªé¢æ’åæ ‡å‡†åŒ–
        
        å°†æ ‡ç­¾è½¬æ¢ä¸º [low, high] èŒƒå›´å†…çš„æ’ååˆ†æ•°
        """
        n = len(labels)
        if n <= 1:
            return labels
        
        # è®¡ç®—æ’å
        sorted_indices = torch.argsort(labels)
        ranks = torch.zeros_like(labels)
        ranks[sorted_indices] = torch.arange(n, dtype=labels.dtype)
        
        # å½’ä¸€åŒ–åˆ° [0, 1]
        normalized = ranks / (n - 1)
        
        # æ˜ å°„åˆ°ç›®æ ‡èŒƒå›´
        low, high = self.label_rank_output_range
        return normalized * (high - low) + low
    
    def get_date_list(self) -> List:
        """è·å–æ‰€æœ‰æœ‰æ•ˆæ—¥æœŸ"""
        return self.valid_dates
    
    def get_stocks_for_date(self, date) -> List[str]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„è‚¡ç¥¨åˆ—è¡¨"""
        return self.date_to_stocks.get(date, [])


def collate_daily(
    batch: List[Dict[str, Any]],
    graph_builder: Optional[Any] = None,
    feature_cols: Optional[List[str]] = None
) -> Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor], List[str], Any]:
    """
    æ—¥æ‰¹æ¬¡ collate å‡½æ•°ï¼ˆåŠ¨æ€å›¾æ„å»ºçš„å…³é”®å…¥å£ - ä¼˜åŒ–ç‰ˆï¼‰
    
    âš ï¸ æ ¸å¿ƒåŠŸèƒ½ï¼šå°† DailyBatchDataset è¿”å›çš„å­—å…¸è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥ï¼Œå¹¶åŠ¨æ€æ„å»ºé‚»æ¥çŸ©é˜µ
    
    æ€§èƒ½ä¼˜åŒ–ï¼š
    - å¯¹äºè¡Œä¸šå›¾ï¼šç›´æ¥ä¼ é€’ stock_idsï¼Œé¿å…åˆ›å»º DataFrame
    - å¯¹äºç›¸å…³æ€§å›¾ï¼šä½¿ç”¨è½»é‡çº§å­—å…¸ä»£æ›¿ DataFrame
    
    Args:
        batch: DailyBatchDataset.__getitem__ è¿”å›çš„å­—å…¸åˆ—è¡¨
        graph_builder: GraphBuilder å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        feature_cols: ç‰¹å¾åˆ—ååˆ—è¡¨ï¼ˆä¼ é€’ç»™ GraphBuilderï¼‰
        
    Returns:
        X, y, adj, stock_ids, date
    """
    # ==========================================================================
    # æƒ…å†µ1: å•æ—¥æ‰¹æ¬¡ï¼ˆæ¨èæ¨¡å¼ï¼‰
    # ==========================================================================
    if len(batch) == 1:
        item = batch[0]
        X = item['features']      # [N, T, F]
        y = item['labels']        # [N]
        stock_ids = item['stock_ids']
        date = item['date']
        n_stocks = item['n_stocks']
        
        # ----------------------------------------------------------------------
        # ã€å…³é”®æ­¥éª¤ã€‘åŠ¨æ€æ„å»ºé‚»æ¥çŸ©é˜µï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        # ----------------------------------------------------------------------
        adj = None
        if graph_builder is not None and n_stocks > 0:
            # ğŸ†• åŠ¨æ€è·å– stock_colï¼Œæ”¯æŒ ts_code/order_book_id å…¼å®¹
            stock_col = 'order_book_id'  # é»˜è®¤å€¼
            if hasattr(graph_builder, 'config') and hasattr(graph_builder.config, 'stock_col'):
                stock_col = graph_builder.config.stock_col
            
            # æ£€æŸ¥å›¾æ„å»ºå™¨ç±»å‹ï¼Œé€‰æ‹©æœ€ä¼˜è·¯å¾„
            builder_type = getattr(graph_builder, 'config', None)
            builder_type = getattr(builder_type, 'type', 'corr') if builder_type else 'corr'
            
            if builder_type == 'industry':
                # ã€ä¼˜åŒ–ã€‘è¡Œä¸šå›¾ï¼šåªéœ€è¦ stock_idsï¼Œä¸éœ€è¦ç‰¹å¾
                # åˆ›å»ºæœ€å°åŒ–çš„ DataFrameï¼ˆä½¿ç”¨åŠ¨æ€ stock_colï¼‰
                df_day = pd.DataFrame({stock_col: stock_ids})
                adj, _, _ = graph_builder(df_day)
            else:
                # ç›¸å…³æ€§å›¾æˆ–æ··åˆå›¾ï¼šéœ€è¦ç‰¹å¾
                # ä½¿ç”¨ numpy ç›´æ¥æ„å»ºï¼Œé¿å…é€åˆ—å­—å…¸è§£æ
                last_step_features = X[:, -1, :].numpy()  # [N, F]
                
                # æ„å»º DataFrameï¼ˆè¿™é‡Œä»éœ€è¦ DataFrameï¼Œä½†ç”¨æ›´é«˜æ•ˆçš„æ–¹å¼ï¼‰
                df_day = pd.DataFrame(
                    last_step_features,
                    columns=feature_cols if feature_cols else [f'feature_{i}' for i in range(X.size(2))]
                )
                # ğŸ†• ä½¿ç”¨åŠ¨æ€ stock_col è€Œéç¡¬ç¼–ç  order_book_id
                df_day.insert(0, stock_col, stock_ids)
                
                adj, _, _ = graph_builder(df_day)
        
        return X, y, adj, stock_ids, date
    
    # ==========================================================================
    # æƒ…å†µ2: å¤šæ—¥æ‰¹æ¬¡ï¼ˆè¾ƒå°‘ä½¿ç”¨ï¼‰
    # ==========================================================================
    else:
        all_X = []
        all_y = []
        all_adj = []
        all_stocks = []
        all_dates = []
        
        # ğŸ†• è·å–åŠ¨æ€ stock_colï¼ˆå¤šæ—¥æ‰¹æ¬¡ï¼‰
        stock_col = 'order_book_id'  # é»˜è®¤å€¼
        if graph_builder is not None:
            if hasattr(graph_builder, 'config') and hasattr(graph_builder.config, 'stock_col'):
                stock_col = graph_builder.config.stock_col
        
        for item in batch:
            all_X.append(item['features'])
            all_y.append(item['labels'])
            all_stocks.append(item['stock_ids'])
            all_dates.append(item['date'])
            
            # ä¸ºæ¯ä¸€å¤©åˆ†åˆ«æ„å»ºé‚»æ¥çŸ©é˜µ
            if graph_builder is not None and item['n_stocks'] > 0:
                X = item['features']
                # ğŸ†• ä½¿ç”¨åŠ¨æ€ stock_col
                df_day = pd.DataFrame({
                    stock_col: item['stock_ids'],
                    **{f'feature_{i}': X[:, -1, i].numpy() for i in range(X.size(2))}
                })
                adj, _, _ = graph_builder(df_day)
                all_adj.append(adj)
            else:
                all_adj.append(None)
        
        return all_X, all_y, all_adj, all_stocks, all_dates


class DailyGraphDataLoader:
    """
    æ—¥æ‰¹æ¬¡å›¾æ•°æ®åŠ è½½å™¨
    
    å°è£… DataLoaderï¼Œæä¾›æ›´ä¾¿æ·çš„æ¥å£å’ŒåŠ¨æ€å›¾æ„å»ºæ”¯æŒã€‚
    
    ç‰¹ç‚¹ï¼š
    1. æ¯ä¸ª batch æ˜¯ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨
    2. æ”¯æŒåŠ¨æ€å›¾æ„å»º
    3. æ—¥æœŸé¡ºåºå¯æ‰“ä¹±ï¼ˆè®­ç»ƒï¼‰æˆ–ä¿æŒï¼ˆæ¨ç†ï¼‰
    
    Args:
        dataset: DailyBatchDataset å®ä¾‹
        graph_builder: GraphBuilder å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        shuffle_dates: æ˜¯å¦æ‰“ä¹±æ—¥æœŸé¡ºåº
        num_workers: å·¥ä½œè¿›ç¨‹æ•°
        pin_memory: æ˜¯å¦ä½¿ç”¨ pinned memory
        device: ç›®æ ‡è®¾å¤‡
    """
    
    def __init__(
        self,
        dataset: DailyBatchDataset,
        graph_builder: Optional[Any] = None,
        feature_cols: Optional[List[str]] = None,
        shuffle_dates: bool = True,
        num_workers: int = 0,
        pin_memory: bool = True,
        device: str = 'cuda'
    ):
        self.dataset = dataset
        self.graph_builder = graph_builder
        self.feature_cols = feature_cols or dataset.feature_cols
        self.device = device
        self.shuffle_dates = shuffle_dates
        
        # åˆ›å»ºå†…éƒ¨ DataLoader
        # batch_size=1 ç¡®ä¿æ¯ä¸ªæ‰¹æ¬¡æ˜¯ä¸€å¤©
        self._loader = DataLoader(
            dataset,
            batch_size=1,
            shuffle=shuffle_dates,
            num_workers=num_workers,
            pin_memory=pin_memory,
            collate_fn=self._collate
        )
    
    def _collate(self, batch):
        """å†…éƒ¨ collate å‡½æ•°ï¼ˆè¿”å› CPU å¼ é‡ï¼Œè®­ç»ƒæ—¶å†è½¬ GPUï¼‰"""
        return collate_daily(
            batch,
            graph_builder=self.graph_builder,
            feature_cols=self.feature_cols
        )
    
    def __iter__(self):
        """è¿­ä»£å™¨ï¼ˆè¿‡æ»¤ç©ºæ‰¹æ¬¡ï¼‰"""
        for batch in self._loader:
            X, y, adj, stock_ids, date = batch
            # ğŸ†• è·³è¿‡ç©ºæ‰¹æ¬¡ï¼ˆn_stocks=0 ä¼šå¯¼è‡´ GAT å±‚ N=0 reshape å¼‚å¸¸ï¼‰
            if X.size(0) == 0:
                continue
            yield batch
    
    def __len__(self):
        """è¿”å›å¤©æ•°"""
        return len(self.dataset)
    
    @property
    def n_days(self) -> int:
        """æœ‰æ•ˆå¤©æ•°"""
        return len(self.dataset)
    
    def get_date_list(self) -> List:
        """è·å–æ—¥æœŸåˆ—è¡¨"""
        return self.dataset.get_date_list()


class DailyBatchSampler:
    """
    æ—¥æ‰¹æ¬¡é‡‡æ ·å™¨
    
    ç”¨äºåœ¨æ™®é€š Dataset ä¸Šå®ç°æŒ‰æ—¥é‡‡æ ·ï¼Œæ¯ä¸ª batch åŒ…å«åŒä¸€å¤©çš„æ ·æœ¬ã€‚
    """
    
    def __init__(
        self,
        df: pd.DataFrame,
        time_col: str = 'trade_date',
        shuffle_dates: bool = True,
        drop_last: bool = False
    ):
        self.time_col = time_col
        self.shuffle_dates = shuffle_dates
        self.drop_last = drop_last
        
        # æ„å»ºæ—¥æœŸåˆ°ç´¢å¼•çš„æ˜ å°„
        self.date_to_indices = {}
        for idx, row in df.iterrows():
            date = row[time_col]
            if date not in self.date_to_indices:
                self.date_to_indices[date] = []
            self.date_to_indices[date].append(idx)
        
        self.dates = list(self.date_to_indices.keys())
    
    def __iter__(self):
        dates = self.dates.copy()
        if self.shuffle_dates:
            np.random.shuffle(dates)
        
        for date in dates:
            indices = self.date_to_indices[date]
            yield indices
    
    def __len__(self):
        return len(self.dates)


# ==================== å·¥å‚å‡½æ•° ====================

def create_daily_loader(
    df: pd.DataFrame,
    feature_cols: List[str],
    label_col: str,
    window_size: int = 20,
    time_col: str = 'trade_date',
    stock_col: str = 'order_book_id',
    graph_builder_config: Optional[Dict] = None,
    shuffle_dates: bool = True,
    device: str = 'cuda',
    **kwargs
) -> DailyGraphDataLoader:
    """
    åˆ›å»ºæ—¥æ‰¹æ¬¡æ•°æ®åŠ è½½å™¨çš„ä¾¿æ·å‡½æ•°
    
    Args:
        df: æ•°æ® DataFrame
        feature_cols: ç‰¹å¾åˆ—
        label_col: æ ‡ç­¾åˆ—
        window_size: çª—å£å¤§å°
        time_col: æ—¶é—´åˆ—
        stock_col: è‚¡ç¥¨åˆ—
        graph_builder_config: å›¾æ„å»ºå™¨é…ç½®
        shuffle_dates: æ˜¯å¦æ‰“ä¹±æ—¥æœŸ
        device: è®¾å¤‡
        **kwargs: å…¶ä»–å‚æ•°ä¼ é€’ç»™ DailyBatchDataset
        
    Returns:
        DailyGraphDataLoader å®ä¾‹
    """
    # åˆ›å»ºæ•°æ®é›†
    dataset = DailyBatchDataset(
        df=df,
        feature_cols=feature_cols,
        label_col=label_col,
        window_size=window_size,
        time_col=time_col,
        stock_col=stock_col,
        **kwargs
    )
    
    # åˆ›å»ºå›¾æ„å»ºå™¨
    graph_builder = None
    if graph_builder_config is not None:
        from quantclassic.data_processor.graph_builder import GraphBuilderFactory
        graph_builder = GraphBuilderFactory.create(graph_builder_config)
    
    # åˆ›å»ºåŠ è½½å™¨
    loader = DailyGraphDataLoader(
        dataset=dataset,
        graph_builder=graph_builder,
        feature_cols=feature_cols,
        shuffle_dates=shuffle_dates,
        device=device
    )
    
    return loader


# ==================== å•å…ƒæµ‹è¯• ====================

if __name__ == '__main__':
    import logging
    logging.basicConfig(level=logging.INFO)
    
    print("=" * 80)
    print("DailyBatchDataset å•å…ƒæµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼š30å¤©ï¼Œ5åªè‚¡ç¥¨
    np.random.seed(42)
    
    n_days = 30
    stocks = ['000001', '000002', '000003', '000004', '000005']
    dates = pd.date_range('2024-01-01', periods=n_days, freq='D')
    
    rows = []
    for date in dates:
        for stock in stocks:
            rows.append({
                'trade_date': date,
                'order_book_id': stock,
                'industry_name': 'TEST',
                'open': 10 + np.random.randn(),
                'high': 11 + np.random.randn(),
                'low': 9 + np.random.randn(),
                'close': 10 + np.random.randn(),
                'vol': 1000 + np.random.randn() * 100,
                'amount': 10000 + np.random.randn() * 1000,
                'alpha_label': np.random.randn()
            })
    
    df = pd.DataFrame(rows)
    feature_cols = ['open', 'high', 'low', 'close', 'vol', 'amount']
    
    print(f"\nğŸ“Š æµ‹è¯•æ•°æ®: {len(df)} è¡Œ, {len(stocks)} åªè‚¡ç¥¨, {n_days} å¤©")
    
    # æµ‹è¯• 1: åˆ›å»ºæ•°æ®é›†
    print("\nã€æµ‹è¯• 1: åˆ›å»º DailyBatchDatasetã€‘")
    window_size = 10
    dataset = DailyBatchDataset(
        df=df,
        feature_cols=feature_cols,
        label_col='alpha_label',
        window_size=window_size,
        enable_window_transform=True,
        label_rank_normalize=True
    )
    
    print(f"  æœ‰æ•ˆå¤©æ•°: {len(dataset)}")
    print(f"  æœŸæœ›å¤©æ•°: {n_days - window_size} = 30 - 10")
    assert len(dataset) == n_days - window_size, "æœ‰æ•ˆå¤©æ•°è®¡ç®—é”™è¯¯"
    print("  âœ“ æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯• 2: è·å–å•æ—¥æ•°æ®
    print("\nã€æµ‹è¯• 2: è·å–å•æ—¥æ•°æ®ã€‘")
    sample = dataset[0]
    print(f"  æ—¥æœŸ: {sample['date']}")
    print(f"  è‚¡ç¥¨æ•°: {sample['n_stocks']}")
    print(f"  ç‰¹å¾å½¢çŠ¶: {sample['features'].shape}")  # [N, T, F]
    print(f"  æ ‡ç­¾å½¢çŠ¶: {sample['labels'].shape}")  # [N]
    
    assert sample['features'].shape[0] == sample['n_stocks'], "ç‰¹å¾å’Œè‚¡ç¥¨æ•°ä¸åŒ¹é…"
    assert sample['features'].shape[1] == window_size, "çª—å£å¤§å°é”™è¯¯"
    assert sample['features'].shape[2] == len(feature_cols), "ç‰¹å¾æ•°é”™è¯¯"
    print("  âœ“ å•æ—¥æ•°æ®è·å–æˆåŠŸ")
    
    # æµ‹è¯• 3: æ ‡ç­¾æ’åæ ‡å‡†åŒ–
    print("\nã€æµ‹è¯• 3: æ ‡ç­¾æ’åæ ‡å‡†åŒ–ã€‘")
    labels = sample['labels']
    print(f"  æ ‡ç­¾èŒƒå›´: [{labels.min():.4f}, {labels.max():.4f}]")
    assert labels.min() >= -1 and labels.max() <= 1, "æ ‡ç­¾èŒƒå›´é”™è¯¯"
    print("  âœ“ æ ‡ç­¾æ’åæ ‡å‡†åŒ–æ­£ç¡®")
    
    # æµ‹è¯• 4: collate_daily
    print("\nã€æµ‹è¯• 4: collate_dailyã€‘")
    batch = [dataset[0]]
    X, y, adj, stock_ids, date = collate_daily(batch, graph_builder=None)
    
    print(f"  X å½¢çŠ¶: {X.shape}")
    print(f"  y å½¢çŠ¶: {y.shape}")
    print(f"  è‚¡ç¥¨IDæ•°: {len(stock_ids)}")
    print(f"  æ—¥æœŸ: {date}")
    print("  âœ“ collate_daily æ­£ç¡®")
    
    # æµ‹è¯• 5: é…åˆ GraphBuilder
    print("\nã€æµ‹è¯• 5: é…åˆ GraphBuilderã€‘")
    import sys
    try:
        import quantclassic
    except ImportError:
         # å°è¯•åŠ¨æ€æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
        project_root = str(Path(__file__).resolve().parents[3])
        if project_root not in sys.path:
            sys.path.insert(0, project_root)
            
    from quantclassic.data_processor.graph_builder import CorrGraphBuilder
    
    graph_builder = CorrGraphBuilder(method='cosine', top_k=2)
    
    X, y, adj, stock_ids, date = collate_daily(
        batch=[dataset[0]],
        graph_builder=graph_builder,
        feature_cols=feature_cols
    )
    
    print(f"  é‚»æ¥çŸ©é˜µå½¢çŠ¶: {adj.shape}")
    print(f"  éé›¶è¾¹æ•°: {(adj > 0).sum().item()}")
    assert adj.shape[0] == len(stock_ids), "é‚»æ¥çŸ©é˜µå°ºå¯¸é”™è¯¯"
    print("  âœ“ åŠ¨æ€å›¾æ„å»ºæ­£ç¡®")
    
    # æµ‹è¯• 6: DailyGraphDataLoader
    print("\nã€æµ‹è¯• 6: DailyGraphDataLoaderã€‘")
    loader = DailyGraphDataLoader(
        dataset=dataset,
        graph_builder=graph_builder,
        feature_cols=feature_cols,
        shuffle_dates=True,
        device='cpu'
    )
    
    print(f"  åŠ è½½å™¨å¤©æ•°: {len(loader)}")
    
    # éå†ä¸€ä¸ª epoch
    for i, (X, y, adj, stock_ids, date) in enumerate(loader):
        if i >= 2:  # åªæµ‹è¯•å‰2å¤©
            break
        print(f"  Batch {i}: date={date}, n_stocks={len(stock_ids)}, adj={adj.shape if adj is not None else None}")
    
    print("  âœ“ DailyGraphDataLoader æ­£ç¡®")
    
    # æµ‹è¯• 7: create_daily_loader å·¥å‚å‡½æ•°
    print("\nã€æµ‹è¯• 7: create_daily_loaderã€‘")
    loader2 = create_daily_loader(
        df=df,
        feature_cols=feature_cols,
        label_col='alpha_label',
        window_size=10,
        graph_builder_config={'type': 'corr', 'corr_method': 'cosine', 'top_k': 2},
        device='cpu'
    )
    print(f"  å·¥å‚åˆ›å»ºçš„åŠ è½½å™¨å¤©æ•°: {len(loader2)}")
    print("  âœ“ å·¥å‚å‡½æ•°æ­£ç¡®")
    
    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰ DailyBatchDataset æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 80)
