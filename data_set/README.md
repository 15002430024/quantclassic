# DataManager - å·¥ç¨‹åŒ–æ•°æ®ç®¡ç†æ¨¡å—

## ğŸ“– æ¦‚è¿°

DataManager æ˜¯ä¸€ä¸ªå®Œæ•´çš„å·¥ç¨‹åŒ–æ•°æ®ç®¡ç†è§£å†³æ–¹æ¡ˆï¼Œä¸“ä¸ºé‡åŒ–äº¤æ˜“å’Œæœºå™¨å­¦ä¹ é¡¹ç›®è®¾è®¡ã€‚å®ƒæä¾›äº†ä»æ•°æ®åŠ è½½ã€éªŒè¯ã€ç‰¹å¾å·¥ç¨‹åˆ°æ•°æ®é›†åˆ›å»ºçš„å®Œæ•´æµç¨‹ï¼Œå…·æœ‰é«˜åº¦çš„å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ¯ å®Œæ•´çš„æ•°æ®å¤„ç†æµæ°´çº¿
- **è‡ªåŠ¨åŒ–æµç¨‹**: ä¸€é”®å®Œæˆæ•°æ®åŠ è½½ã€éªŒè¯ã€ç‰¹å¾å·¥ç¨‹å’Œæ•°æ®é›†åˆ›å»º
- **æ¨¡å—åŒ–è®¾è®¡**: æ¯ä¸ªç»„ä»¶å¯ç‹¬ç«‹ä½¿ç”¨ï¼Œä¹Ÿå¯ç»„åˆä½¿ç”¨
- **çµæ´»é…ç½®**: æ”¯æŒYAMLé…ç½®æ–‡ä»¶å’Œä»£ç é…ç½®

### ğŸ”§ å¼ºå¤§çš„åŠŸèƒ½ç»„ä»¶
- **DataConfig**: ç»Ÿä¸€çš„é…ç½®ç®¡ç†ï¼Œæ”¯æŒå¤šç§é¢„è®¾æ¨¡æ¿
- **DataLoader**: å¤šæ ¼å¼æ”¯æŒï¼ˆParquet/CSV/HDF5ï¼‰ï¼Œå†…å­˜ä¼˜åŒ–
- **FeatureEngineer**: è‡ªåŠ¨ç‰¹å¾é€‰æ‹©ã€è¿‡æ»¤å’Œç»Ÿè®¡åˆ†æ
- **DataSplitter**: å¤šç§åˆ’åˆ†ç­–ç•¥ï¼ˆæ—¶é—´åºåˆ—ã€åˆ†å±‚ã€æ»šåŠ¨çª—å£ï¼‰
- **DataValidator**: å…¨é¢çš„æ•°æ®è´¨é‡æ£€æŸ¥å’ŒæŠ¥å‘Š
- **DatasetFactory**: PyTorch Datasetå’ŒDataLoaderåˆ›å»º

### ğŸš€ æ€§èƒ½ä¼˜åŒ–
- **å†…å­˜ä¼˜åŒ–**: è‡ªåŠ¨æ•°æ®ç±»å‹ä¼˜åŒ–ï¼Œå‡å°‘å†…å­˜å ç”¨
- **æ™ºèƒ½ç¼“å­˜**: å¤šçº§ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤è®¡ç®—
- **æ‰¹é‡å¤„ç†**: æ”¯æŒå¤§æ•°æ®é›†çš„åˆ†å—åŠ è½½

### ğŸ“Š æ•°æ®è´¨é‡ä¿éšœ
- **è‡ªåŠ¨éªŒè¯**: ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€æ—¶åºè¿ç»­æ€§æ£€æŸ¥
- **è´¨é‡æŠ¥å‘Š**: ç”Ÿæˆè¯¦ç»†çš„æ•°æ®è´¨é‡æŠ¥å‘Š
- **é—®é¢˜è¯Šæ–­**: è‡ªåŠ¨è¯†åˆ«å¸¸è§æ•°æ®é—®é¢˜

## ğŸ“ æ¨¡å—ç»“æ„

```
data_manager/
â”œâ”€â”€ __init__.py           # æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ config.py             # é…ç½®ç®¡ç†ï¼ˆDataConfigï¼‰
â”œâ”€â”€ loader.py             # æ•°æ®åŠ è½½å™¨ï¼ˆDataLoaderEngineï¼‰
â”œâ”€â”€ feature_engineer.py   # ç‰¹å¾å·¥ç¨‹å¸ˆï¼ˆFeatureEngineerï¼‰
â”œâ”€â”€ splitter.py           # æ•°æ®åˆ’åˆ†å™¨ï¼ˆDataSplitterç³»åˆ—ï¼‰
â”œâ”€â”€ validator.py          # æ•°æ®éªŒè¯å™¨ï¼ˆDataValidatorï¼‰
â”œâ”€â”€ factory.py            # æ•°æ®é›†å·¥å‚ï¼ˆDatasetFactoryï¼‰
â”œâ”€â”€ manager.py            # ä¸»æ§ç±»ï¼ˆDataManagerï¼‰
â”œâ”€â”€ examples.py           # ä½¿ç”¨ç¤ºä¾‹
â””â”€â”€ README.md             # æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
```

âœ… å·²å®Œæˆçš„é…ç½®ç±»ï¼š

âœ… LabelConfig - label_generator.pyï¼ˆæ ‡ç­¾ç”Ÿæˆé…ç½®ï¼‰

âœ… ProcessingStep - preprocess_config.pyï¼ˆå¤„ç†æ­¥éª¤ï¼‰

âœ… NeutralizeConfig - preprocess_config.pyï¼ˆä¸­æ€§åŒ–é…ç½®ï¼‰

âœ… PreprocessConfig - preprocess_config.pyï¼ˆé¢„å¤„ç†æ€»é…ç½®ï¼‰

âœ… DataConfig - config.pyï¼ˆæ•°æ®ç®¡ç†é…ç½®ï¼‰

âœ… BaseModelConfig - model_config.pyï¼ˆåŸºç¡€æ¨¡å‹é…ç½®ï¼‰

âœ… LSTMConfig - model_config.pyï¼ˆLSTM æ¨¡å‹é…ç½®ï¼‰

âœ… GRUConfig - model_config.pyï¼ˆGRU æ¨¡å‹é…ç½®ï¼‰

âœ… TimeConfig - config_manager.pyï¼ˆæ—¶é—´é…ç½®ï¼‰

âœ… DataSourceConfig - config_manager.pyï¼ˆæ•°æ®æºé…ç½®ï¼‰

âœ… UniverseConfig - config_manager.pyï¼ˆè‚¡ç¥¨æ± é…ç½®ï¼‰

âœ… BacktestConfig - backtest_config.pyï¼ˆå›æµ‹é…ç½®ï¼‰

âœ… RecorderConfig - workflow_config.pyï¼ˆè®°å½•å™¨é…ç½®ï¼‰

âœ… CheckpointConfig - workflow_config.pyï¼ˆæ£€æŸ¥ç‚¹é…ç½®ï¼‰

âœ… ArtifactConfig - workflow_config.pyï¼ˆå·¥ä»¶é…ç½®ï¼‰

âœ… WorkflowConfig - workflow_config.pyï¼ˆå·¥ä½œæµé…ç½®ï¼‰



## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼

```python
from data_manager import DataManager, DataConfig

# åˆ›å»ºé…ç½®
config = DataConfig(
    base_dir='rq_data_parquet',
    data_file='train_data_final.parquet'
)

# åˆ›å»ºç®¡ç†å™¨å¹¶è¿è¡Œå®Œæ•´æµæ°´çº¿
manager = DataManager(config)
loaders = manager.run_full_pipeline()

# ä½¿ç”¨æ•°æ®åŠ è½½å™¨è®­ç»ƒæ¨¡å‹
for batch_x, batch_y in loaders.train:
    # è®­ç»ƒä»£ç 
    pass
```

### 2. é€æ­¥æ‰§è¡Œæµæ°´çº¿

```python
manager = DataManager(config)

# æ­¥éª¤1: åŠ è½½æ•°æ®
raw_data = manager.load_raw_data()

# æ­¥éª¤2: éªŒè¯æ•°æ®è´¨é‡
report = manager.validate_data_quality()

# æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹
feature_cols = manager.preprocess_features(auto_filter=True)

# æ­¥éª¤4-5: åˆ›å»ºæ•°æ®é›†
datasets = manager.create_datasets()

# æ­¥éª¤6: è·å–æ•°æ®åŠ è½½å™¨
loaders = manager.get_dataloaders(batch_size=256)
```

## ğŸ“ è¯¦ç»†ä½¿ç”¨æŒ‡å—

### é…ç½®ç®¡ç†

#### ä½¿ç”¨é»˜è®¤é…ç½®
```python
from data_manager import DataConfig

config = DataConfig()  # ä½¿ç”¨é»˜è®¤å‚æ•°
```

#### è‡ªå®šä¹‰é…ç½®
```python
config = DataConfig(
    # æ•°æ®è·¯å¾„
    base_dir='rq_data_parquet',
    data_file='train_data_final.parquet',
    
    # ç‰¹å¾å‚æ•°
    window_size=60,         # æ—¶é—´çª—å£
    label_col='y_processed',
    
    # æ•°æ®åˆ’åˆ†
    split_strategy='time_series',  # æˆ– 'stratified', 'rolling', 'random'
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15,
    
    # æ•°æ®åŠ è½½
    batch_size=512,
    num_workers=4,
    
    # ä¼˜åŒ–é€‰é¡¹
    use_dtype_optimization=True,
    enable_cache=True,
    enable_validation=True,
)
```

#### ä½¿ç”¨é…ç½®æ¨¡æ¿
```python
from data_manager import ConfigTemplates

# å¿«é€Ÿæµ‹è¯•é…ç½®
config = ConfigTemplates.quick_test()

# ç”Ÿäº§ç¯å¢ƒé…ç½®
config = ConfigTemplates.production()

# å›æµ‹é…ç½®
config = ConfigTemplates.backtest()
```

#### YAMLé…ç½®æ–‡ä»¶
```python
# ä¿å­˜é…ç½®
config.to_yaml('my_config.yaml')

# åŠ è½½é…ç½®
config = DataConfig.from_yaml('my_config.yaml')
```

### æ•°æ®åˆ’åˆ†ç­–ç•¥

#### 1. æ—¶é—´åºåˆ—åˆ’åˆ†ï¼ˆæ¨èï¼‰
```python
config = DataConfig(
    split_strategy='time_series',
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15
)
```

#### 2. åˆ†å±‚è‚¡ç¥¨åˆ’åˆ†
```python
config = DataConfig(
    split_strategy='stratified',  # ç¡®ä¿æ¯åªè‚¡ç¥¨åœ¨å„æ•°æ®é›†ä¸­éƒ½æœ‰æ ·æœ¬
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15
)
```

#### 3. æ»šåŠ¨çª—å£åˆ’åˆ†ï¼ˆç”¨äºå›æµ‹ï¼‰
```python
config = DataConfig(
    split_strategy='rolling',
    rolling_window_size=252,  # è®­ç»ƒçª—å£ï¼š252ä¸ªäº¤æ˜“æ—¥ï¼ˆçº¦1å¹´ï¼‰
    rolling_step=63           # æ»šåŠ¨æ­¥é•¿ï¼š63ä¸ªäº¤æ˜“æ—¥ï¼ˆçº¦1å­£åº¦ï¼‰
)
```

### ç‰¹å¾å·¥ç¨‹

#### è‡ªåŠ¨ç‰¹å¾é€‰æ‹©
```python
manager = DataManager(config)
raw_data = manager.load_raw_data()

# è‡ªåŠ¨é€‰æ‹©æ•°å€¼å‹ç‰¹å¾ï¼ˆæ’é™¤æŒ‡å®šåˆ—ï¼‰
features = manager.feature_engineer.select_features(raw_data)
```

#### ç‰¹å¾è¿‡æ»¤
```python
# è¿‡æ»¤ä½è´¨é‡ç‰¹å¾
filtered_features = manager.feature_engineer.filter_features(
    raw_data,
    min_variance=1e-5,        # æœ€å°æ–¹å·®
    max_missing_ratio=0.3,    # æœ€å¤§ç¼ºå¤±ç‡
    max_correlation=0.95      # æœ€å¤§ç›¸å…³æ€§
)
```

#### ç‰¹å¾ç»Ÿè®¡
```python
# è®¡ç®—ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
stats = manager.feature_engineer.compute_feature_stats(raw_data)

# ä¿å­˜ç‰¹å¾ä¿¡æ¯
manager.feature_engineer.save_feature_info('output/')
```

### æ•°æ®éªŒè¯

```python
# æ‰§è¡Œæ•°æ®è´¨é‡éªŒè¯
report = manager.validate_data_quality()

# æŸ¥çœ‹éªŒè¯ç»“æœ
if report.is_valid:
    print("æ•°æ®éªŒè¯é€šè¿‡")
else:
    print(f"å‘ç° {len(report.errors)} ä¸ªé”™è¯¯")
    for error in report.errors:
        print(f"  - {error}")

# æŸ¥çœ‹è­¦å‘Š
for warning in report.warnings:
    print(f"  âš ï¸ {warning}")

# æ‰“å°å®Œæ•´æŠ¥å‘Š
report.print_report()
```

### è®¿é—®å¤„ç†åçš„æ•°æ®

```python
# è¿è¡Œå®Œæ•´æµæ°´çº¿
loaders = manager.run_full_pipeline()

# è®¿é—®åŸå§‹æ•°æ®
raw_data = manager.raw_data

# è®¿é—®ç‰¹å¾åˆ—
feature_cols = manager.feature_cols

# è®¿é—®åˆ’åˆ†åçš„æ•°æ®
train_df, val_df, test_df = manager.split_data

# è®¿é—®æ•°æ®é›†
datasets = manager.datasets
print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(datasets.train)}")
print(f"éªŒè¯æ ·æœ¬æ•°: {len(datasets.val)}")
print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(datasets.test)}")

# è®¿é—®å…ƒæ•°æ®
metadata = datasets.metadata
print(f"ç‰¹å¾æ•°é‡: {metadata['num_features']}")
print(f"çª—å£å¤§å°: {metadata['window_size']}")
```

### ä¸æ¨¡å‹è®­ç»ƒé›†æˆ

```python
import torch
import torch.nn as nn

# å‡†å¤‡æ•°æ®
manager = DataManager(config)
loaders = manager.run_full_pipeline()

# åˆ›å»ºæ¨¡å‹ï¼ˆç¤ºä¾‹ï¼‰
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model = YourModel(...).to(device)
# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    # è®­ç»ƒ
    model.train()
    for batch_x, batch_y in loaders.train:
        batch_x = batch_x.to(device)
        batch_y = batch_y.to(device)
        
        # å‰å‘ä¼ æ’­
        # pred = model(batch_x)
        # loss = criterion(pred, batch_y)
        
        # åå‘ä¼ æ’­
        # optimizer.zero_grad()
        # loss.backward()
        # optimizer.step()
    
    # éªŒè¯
    model.eval()
    with torch.no_grad():
        for batch_x, batch_y in loaders.val:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            # éªŒè¯ä»£ç 
            # val_pred = model(batch_x)
            # val_loss = criterion(val_pred, batch_y)
```

### çŠ¶æ€ä¿å­˜å’ŒåŠ è½½

```python
# ä¿å­˜ç®¡ç†å™¨çŠ¶æ€
manager.save_state('cache/manager_state.pkl')

# åœ¨å¦ä¸€ä¸ªä¼šè¯ä¸­åŠ è½½
new_manager = DataManager()
new_manager.load_state('cache/manager_state.pkl')

# ç»§ç»­ä½¿ç”¨
loaders = new_manager.get_dataloaders()
```

## ğŸ“Š é¢„æœŸè¾“å‡ºç¤ºä¾‹

### è¿è¡Œå®Œæ•´æµæ°´çº¿çš„è¾“å‡º

```
================================================================================
ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®å¤„ç†æµæ°´çº¿
================================================================================

================================================================================
æ­¥éª¤ 1/5: åŠ è½½åŸå§‹æ•°æ®
================================================================================
ğŸ“ åŠ è½½æ•°æ®: rq_data_parquet/train_data_final.parquet
ğŸ”§ ä¼˜åŒ–æ•°æ®ç±»å‹...
   å†…å­˜ä¼˜åŒ–: 1250.45MB â†’ 625.23MB (å‡å°‘ 50.0%)
âœ… æ•°æ®åŠ è½½å®Œæˆ: 1,234,567 è¡Œ, 156 åˆ—

================================================================================
ğŸ“Š æ•°æ®æ‘˜è¦
================================================================================
å½¢çŠ¶: 1,234,567 è¡Œ Ã— 156 åˆ—
å†…å­˜å ç”¨: 625.23 MB
è‚¡ç¥¨æ•°é‡: 4,500
æ—¶é—´èŒƒå›´: 2015-01-01 ~ 2023-12-31

æ•°æ®ç±»å‹åˆ†å¸ƒ:
  float32: 150 åˆ—
  int32: 3 åˆ—
  category: 3 åˆ—

ç¼ºå¤±å€¼ (å‰10åˆ—):
  feature_42: 12345 (1.00%)
  feature_87: 8901 (0.72%)
================================================================================

================================================================================
æ­¥éª¤ 2/5: éªŒè¯æ•°æ®è´¨é‡
================================================================================
ğŸ” å¼€å§‹æ•°æ®éªŒè¯...
âœ… éªŒè¯å®Œæˆ: 0 é”™è¯¯, 2 è­¦å‘Š

================================================================================
ğŸ“‹ æ•°æ®éªŒè¯æŠ¥å‘Š
================================================================================

çŠ¶æ€: âœ… é€šè¿‡

è­¦å‘Š (2):
  1. âš ï¸  åˆ— 'feature_42' ç¼ºå¤±å€¼è¿‡é«˜: 1.00% (12345/1234567)
  2. âš ï¸  10 åªè‚¡ç¥¨æ ·æœ¬æ•°å°‘äº 60

ç»Ÿè®¡ä¿¡æ¯:
  total_rows: 1234567
  total_columns: 156
  num_stocks: 4500
  date_range: ('2015-01-01', '2023-12-31')
  num_features: 150
  numeric_features: 150
================================================================================

================================================================================
æ­¥éª¤ 3/5: ç‰¹å¾å·¥ç¨‹
================================================================================
ğŸ” è‡ªåŠ¨æ£€æµ‹ç‰¹å¾åˆ—...
âœ… è‡ªåŠ¨é€‰æ‹©ç‰¹å¾åˆ—: 150 åˆ—
ğŸ“Š è®¡ç®—ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯...
ğŸ”§ è¿‡æ»¤ä½è´¨é‡ç‰¹å¾...
   ç§»é™¤ 15 ä¸ªç‰¹å¾:
   - ä½æ–¹å·®: 5
   - é«˜ç¼ºå¤±: 3
   - é«˜ç›¸å…³: 7
âœ… ä¿ç•™ 135 ä¸ªç‰¹å¾
ğŸ’¾ ç‰¹å¾ä¿¡æ¯å·²ä¿å­˜åˆ°: output/

================================================================================
æ­¥éª¤ 4/5: æ•°æ®åˆ’åˆ†
================================================================================
ğŸ“… æ—¶é—´åºåˆ—åˆ’åˆ†...
   è®­ç»ƒé›†: 864,197 è¡Œ (2015-01-01 ~ 2021-12-31)
   éªŒè¯é›†: 185,185 è¡Œ (2022-01-01 ~ 2022-12-31)
   æµ‹è¯•é›†: 185,185 è¡Œ (2023-01-01 ~ 2023-12-31)

================================================================================
æ­¥éª¤ 5/5: åˆ›å»ºæ•°æ®é›†
================================================================================
ğŸ­ åˆ›å»ºæ•°æ®é›†...
   è®­ç»ƒé›†: 820,157 æ ·æœ¬
   éªŒè¯é›†: 175,145 æ ·æœ¬
   æµ‹è¯•é›†: 175,145 æ ·æœ¬

================================================================================
âœ… å®Œæ•´æ•°æ®å¤„ç†æµæ°´çº¿å®Œæˆ
================================================================================

================================================================================
ğŸ“Š æ•°æ®å¤„ç†æ‘˜è¦
================================================================================
åŸå§‹æ•°æ®: 1,234,567 è¡Œ
ç‰¹å¾æ•°é‡: 135

æ•°æ®é›†:
  è®­ç»ƒé›†: 820,157 æ ·æœ¬
  éªŒè¯é›†: 175,145 æ ·æœ¬
  æµ‹è¯•é›†: 175,145 æ ·æœ¬

é…ç½®:
  çª—å£å¤§å°: 40
  æ‰¹é‡å¤§å°: 256
  åˆ’åˆ†ç­–ç•¥: time_series
================================================================================
```

### æ•°æ®åŠ è½½å™¨ä½¿ç”¨è¾“å‡º

```python
# éå†è®­ç»ƒé›†
for i, (batch_x, batch_y) in enumerate(loaders.train):
    print(f"æ‰¹æ¬¡ {i+1}: X={batch_x.shape}, Y={batch_y.shape}")
    if i >= 2:
        break

# è¾“å‡º:
# æ‰¹æ¬¡ 1: X=torch.Size([256, 40, 135]), Y=torch.Size([256])
# æ‰¹æ¬¡ 2: X=torch.Size([256, 40, 135]), Y=torch.Size([256])
# æ‰¹æ¬¡ 3: X=torch.Size([256, 40, 135]), Y=torch.Size([256])
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰æ•°æ®é›†

```python
from data_manager.factory import TimeSeriesStockDataset

# åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†
custom_dataset = TimeSeriesStockDataset(
    df=my_dataframe,
    feature_cols=my_features,
    label_col='my_label',
    window_size=60,
    stock_col='ts_code',
    time_col='trade_date'
)
```

### æ¨ç†æ•°æ®é›†ï¼ˆæ— æ ‡ç­¾ï¼‰

```python
from data_manager.factory import InferenceDataset

# åˆ›å»ºæ¨ç†æ•°æ®é›†
inference_dataset = manager.factory.create_inference_dataset(
    df=test_data,
    feature_cols=feature_cols
)

# è·å–é¢„æµ‹æ ·æœ¬
for sample in inference_dataset:
    # sample å½¢çŠ¶: [window_size, n_features]
    prediction = model(sample)
```

### çª—å£çº§æ•°æ®å˜æ¢ï¼ˆç ”æŠ¥æ ‡å‡†ï¼‰ğŸ†•

åœ¨ `Dataset.__getitem__` ä¸­å¯¹æ¯ä¸ªçª—å£å®æ—¶è¿›è¡Œä»·æ ¼å¯¹æ•°å˜æ¢å’Œæˆäº¤é‡æ ‡å‡†åŒ–ã€‚è¿™ç¡®ä¿äº†æ¯ä¸ªçª—å£ä½¿ç”¨è‡ªå·±çš„åŸºå‡†ç‚¹ï¼ˆçª—å£æœ«ç«¯çš„æ”¶ç›˜ä»·ï¼‰ï¼Œè€Œä¸æ˜¯å…¨å±€å¤„ç†ã€‚

```python
# å¯ç”¨çª—å£çº§å˜æ¢
config = DataConfig(
    # å¯ç”¨çª—å£å˜æ¢
    enable_window_transform=True,
    
    # ä»·æ ¼å¯¹æ•°å˜æ¢: log(price / close_t)
    window_price_log=True,
    price_cols=['open', 'high', 'low', 'close', 'vwap'],
    close_col='close',
    
    # æˆäº¤é‡æ ‡å‡†åŒ–: volume / mean(volume_in_window)
    window_volume_norm=True,
    volume_cols=['vol', 'amount']
)
```

**å˜æ¢å…¬å¼è¯´æ˜**ï¼š

| å˜æ¢ç±»å‹ | å…¬å¼ | æ•ˆæœ |
|---------|------|------|
| ä»·æ ¼å¯¹æ•°å˜æ¢ | `log(price_{t-i} / close_t)` | close_t = 0, å…¶ä»–ä¸ºç›¸å¯¹åå·® |
| æˆäº¤é‡æ ‡å‡†åŒ– | `vol_{t-i} / mean(vol_window)` | å‡å€¼é™„è¿‘ â‰ˆ 1.0 |

**ä¸ºä»€ä¹ˆåœ¨ Dataset é˜¶æ®µåšï¼Ÿ**
- æ¯ä¸ªçª—å£æœ‰ä¸åŒçš„åŸºå‡†ç‚¹ `close_t`
- å…¨å±€é¢„å¤„ç†æ— æ³•å®ç°"çª—å£ç›¸å¯¹"å˜æ¢
- é¿å…æ•°æ®é‡çˆ†ç‚¸ï¼ˆåŒä¸€å¤©æ•°æ®åœ¨ä¸åŒçª—å£ä¸­æ•°å€¼ä¸åŒï¼‰

### è‡ªå®šä¹‰éªŒè¯è§„åˆ™

```python
# ä¿®æ”¹éªŒè¯å‚æ•°
config = DataConfig(
    max_na_ratio=0.5,              # å…è®¸50%ç¼ºå¤±
    min_samples_per_stock=100,     # æ¯åªè‚¡ç¥¨è‡³å°‘100æ ·æœ¬
    detect_outliers=True,
    outlier_std_threshold=5.0      # 5å€æ ‡å‡†å·®ä¸ºå¼‚å¸¸å€¼
)
```

## ğŸ¤ ä¸å…¶ä»–æ¨¡å—çš„åä½œ

### ä¸ data_loader æ¨¡å—åä½œ
- DataManager ä½¿ç”¨è‡ªå·±çš„æ•°æ®åŠ è½½é€»è¾‘ï¼Œ**ä¸ä¾èµ–** data_loader
- data_loader ä¸“æ³¨äºåŸå§‹æ•°æ®è·å–å’Œå­˜å‚¨
- DataManager ä¸“æ³¨äºæ¨¡å‹è®­ç»ƒçš„æ•°æ®ç®¡ç†

### ä¸ data_processor æ¨¡å—åä½œ
- data_processor å¤„ç†åŸå§‹æ•°æ®çš„æ¸…æ´—å’Œç‰¹å¾è®¡ç®—
- DataManager ä½¿ç”¨å·²å¤„ç†çš„æ•°æ®è¿›è¡Œè®­ç»ƒå‡†å¤‡
- æ¨èæµç¨‹: data_loader â†’ data_processor â†’ DataManager

### ä¸æ¨¡å‹è®­ç»ƒæ¨¡å—åä½œ
- DataManager æä¾›æ ‡å‡†çš„ PyTorch DataLoader
- æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒçš„æ•°æ®åˆ†ç‰‡
- æä¾›ä¸€è‡´çš„æ•°æ®æ¥å£

### ä¸å›æµ‹æ¡†æ¶åä½œ
- ä½¿ç”¨ `InferenceDataset` è¿›è¡Œå› å­ç”Ÿæˆ
- æ”¯æŒæ»šåŠ¨çª—å£å›æµ‹
- æä¾›æ—¶é—´ç‚¹æ•°æ®åˆ‡ç‰‡

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å†…å­˜ä¼˜åŒ–
```python
config = DataConfig(
    use_dtype_optimization=True,  # ä½¿ç”¨float32è€Œéfloat64
    chunk_size=100000,            # åˆ†å—åŠ è½½å¤§æ–‡ä»¶
)
```

### è®¡ç®—ä¼˜åŒ–
```python
config = DataConfig(
    num_workers=4,       # å¤šè¿›ç¨‹æ•°æ®åŠ è½½
    pin_memory=True,     # ä½¿ç”¨é”é¡µå†…å­˜ï¼ˆGPUè®­ç»ƒï¼‰
    enable_cache=True,   # å¯ç”¨ç¼“å­˜
)
```

### å¤§æ•°æ®é›†å¤„ç†
```python
# å¯¹äºè¶…å¤§æ•°æ®é›†
config = DataConfig(
    chunk_size=50000,              # åˆ†å—åŠ è½½
    use_dtype_optimization=True,   # ç±»å‹ä¼˜åŒ–
    cache_feature_engineering=False,  # ä¸ç¼“å­˜ä¸­é—´ç»“æœ
)
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ—¶åºæ•°æ®**: å»ºè®®ä½¿ç”¨ `time_series` æˆ– `stratified` åˆ’åˆ†ç­–ç•¥ï¼Œé¿å…ä½¿ç”¨ `random`
2. **æ•°æ®æ³„æ¼**: åˆ’åˆ†æ•°æ®å‰ä¸è¦è¿›è¡Œè·¨æ—¶é—´çš„æ ‡å‡†åŒ–
3. **å†…å­˜ç®¡ç†**: å¤„ç†å¤§æ•°æ®é›†æ—¶æ³¨æ„ç›‘æ§å†…å­˜ä½¿ç”¨
4. **ç¼“å­˜æ¸…ç†**: é•¿æ—¶é—´è¿è¡Œæ—¶å®šæœŸæ¸…ç†ç¼“å­˜

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜: å†…å­˜ä¸è¶³
```python
# è§£å†³æ–¹æ¡ˆ: å‡å°æ‰¹é‡å¤§å°æˆ–ä½¿ç”¨åˆ†å—åŠ è½½
config = DataConfig(
    batch_size=128,      # å‡å°æ‰¹é‡
    chunk_size=50000,    # åˆ†å—åŠ è½½
)
```

### é—®é¢˜: æ•°æ®éªŒè¯å¤±è´¥
```python
# è§£å†³æ–¹æ¡ˆ: è°ƒæ•´éªŒè¯å‚æ•°æˆ–è·³è¿‡éªŒè¯
config = DataConfig(
    enable_validation=False,  # è·³è¿‡éªŒè¯
    # æˆ–è°ƒæ•´å‚æ•°
    max_na_ratio=0.5,
    min_samples_per_stock=30,
)
```

### é—®é¢˜: ç‰¹å¾è¿‡æ»¤å¤ªæ¿€è¿›
```python
# è§£å†³æ–¹æ¡ˆ: æ”¾å®½è¿‡æ»¤æ¡ä»¶
filtered = manager.feature_engineer.filter_features(
    df,
    min_variance=1e-8,       # é™ä½æ–¹å·®é˜ˆå€¼
    max_missing_ratio=0.6,   # æé«˜ç¼ºå¤±ç‡å®¹å¿
    max_correlation=0.99     # æé«˜ç›¸å…³æ€§é˜ˆå€¼
)
```

## ğŸ“š æ›´å¤šç¤ºä¾‹

è¯¦ç»†ç¤ºä¾‹è¯·æŸ¥çœ‹ `examples.py` æ–‡ä»¶ï¼ŒåŒ…å«ï¼š
- å¿«é€Ÿå¼€å§‹
- è‡ªå®šä¹‰é…ç½®
- é€æ­¥æ‰§è¡Œæµæ°´çº¿
- ä¸åŒåˆ’åˆ†ç­–ç•¥
- é…ç½®æ¨¡æ¿ä½¿ç”¨
- çŠ¶æ€ä¿å­˜å’ŒåŠ è½½
- ä¸è®­ç»ƒé›†æˆ
- ç‰¹å¾è¿‡æ»¤
- æ•°æ®è®¿é—®
- YAMLé…ç½®

è¿è¡Œç¤ºä¾‹ï¼š
```bash
python examples.py
```

## ğŸ“„ è®¸å¯è¯

æœ¬æ¨¡å—ä¸ºå†…éƒ¨é¡¹ç›®çš„ä¸€éƒ¨åˆ†ï¼Œéµå¾ªé¡¹ç›®æ•´ä½“è®¸å¯åè®®ã€‚

## ğŸ‘¥ è´¡çŒ®è€…

quantclassic å›¢é˜Ÿ

---

**ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2025-11-19
