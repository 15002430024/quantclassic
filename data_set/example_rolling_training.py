"""
æ»šåŠ¨çª—å£è®­ç»ƒå¿«é€Ÿç¤ºä¾‹
=====================

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ quantclassic è¿›è¡Œæ»šåŠ¨çª—å£æ¨¡å‹è®­ç»ƒ
"""

import sys
sys.path.insert(0, '/home/u2025210237/jupyterlab')

from pathlib import Path
from quantclassic.data_set import DataManager, DataConfig
from quantclassic.model.pytorch_models import GRUModel
from quantclassic.model.model_config import GRUConfig

def main():
    print("=" * 80)
    print("ğŸ”„ æ»šåŠ¨çª—å£æ¨¡å‹è®­ç»ƒç¤ºä¾‹")
    print("=" * 80)
    
    # ==================== 1. é…ç½® ====================
    print("\nğŸ“ æ­¥éª¤ 1: åˆ›å»ºé…ç½®")
    
    # æ•°æ®é…ç½® - ä½¿ç”¨ rolling ç­–ç•¥
    data_config = DataConfig(
        base_dir='output',
        data_file='train_data_final_01.parquet',
        stock_col='order_book_id',
        time_col='trade_date',
        label_col='alpha_label',
        split_strategy='rolling',        # å…³é”®ï¼šä½¿ç”¨æ»šåŠ¨çª—å£
        rolling_window_size=252,         # 1å¹´è®­ç»ƒçª—å£
        rolling_step=63,                 # 1å­£åº¦æ»šåŠ¨æ­¥é•¿
        window_size=40,
        batch_size=512,
        enable_cache=False
    )
    
    print("âœ… æ•°æ®é…ç½®åˆ›å»ºå®Œæˆ")
    print(f"  çª—å£å¤§å°: {data_config.rolling_window_size} å¤©")
    print(f"  æ»šåŠ¨æ­¥é•¿: {data_config.rolling_step} å¤©")
    
    # ==================== 2. æ•°æ®å‡†å¤‡ ====================
    print("\nğŸ“Š æ­¥éª¤ 2: æ•°æ®å‡†å¤‡")
    
    dm = DataManager(config=data_config)
    loaders = dm.run_full_pipeline()
    
    print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ")
    print(f"  ç‰¹å¾ç»´åº¦: {len(dm.feature_cols)}")
    
    # ==================== 3. åˆ›å»ºè®­ç»ƒå™¨ ====================
    print("\nğŸ”§ æ­¥éª¤ 3: åˆ›å»ºæ»šåŠ¨çª—å£è®­ç»ƒå™¨")
    
    trainer = dm.create_rolling_window_trainer()
    
    if trainer is None:
        raise ValueError("æ— æ³•åˆ›å»ºæ»šåŠ¨çª—å£è®­ç»ƒå™¨ï¼Œè¯·æ£€æŸ¥é…ç½®")
    
    print(f"âœ… è®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
    print(f"  çª—å£æ•°é‡: {trainer.n_windows}")
    
    # ==================== 4. æ¨¡å‹é…ç½® ====================
    print("\nâš™ï¸  æ­¥éª¤ 4: é…ç½®æ¨¡å‹")
    
    gru_config = GRUConfig(
        d_feat=len(dm.feature_cols),
        hidden_size=64,
        num_layers=2,
        dropout=0.3,
        n_epochs=30,
        batch_size=512,
        learning_rate=0.001,
        early_stop=10,
        optimizer='adam',
        device='cuda'
    )
    
    print("âœ… æ¨¡å‹é…ç½®å®Œæˆ")
    print(f"  æ¨¡å‹: GRU")
    print(f"  éšè—å±‚: {gru_config.hidden_size}")
    print(f"  å±‚æ•°: {gru_config.num_layers}")
    
    # ==================== 5. è®­ç»ƒæ‰€æœ‰çª—å£ ====================
    print("\nğŸš€ æ­¥éª¤ 5: è®­ç»ƒæ‰€æœ‰çª—å£")
    print(f"âš ï¸  æ³¨æ„: å°†è®­ç»ƒ {trainer.n_windows} ä¸ªç‹¬ç«‹æ¨¡å‹ï¼Œéœ€è¦è¾ƒé•¿æ—¶é—´")
    
    # ç¡®è®¤æ˜¯å¦ç»§ç»­
    response = input("\næ˜¯å¦ç»§ç»­? (y/n): ")
    
    if response.lower() != 'y':
        print("âŒ å·²å–æ¶ˆè®­ç»ƒ")
        return
    
    results = trainer.train_all_windows(
        model_class=GRUModel,
        model_config=gru_config,
        save_dir='output/rolling_models',
        val_ratio=0.2,
        incremental=False  # False=ç‹¬ç«‹è®­ç»ƒï¼ŒTrue=å¢é‡è®­ç»ƒ
    )
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆ")
    
    # ==================== 6. é¢„æµ‹ ====================
    print("\nğŸ”® æ­¥éª¤ 6: é¢„æµ‹æ‰€æœ‰çª—å£")
    
    predictions = trainer.predict_all_windows(results)
    
    # ==================== 7. ä¿å­˜ç»“æœ ====================
    print("\nğŸ’¾ æ­¥éª¤ 7: ä¿å­˜ç»“æœ")
    
    output_dir = Path('output')
    output_dir.mkdir(exist_ok=True)
    
    predictions.to_parquet('output/rolling_predictions.parquet')
    print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜: output/rolling_predictions.parquet")
    
    # ==================== 8. åˆ†æç»“æœ ====================
    print("\nğŸ“ˆ æ­¥éª¤ 8: ç»“æœåˆ†æ")
    print("=" * 80)
    
    # è®­ç»ƒæ±‡æ€»
    summary = trainer.get_summary()
    
    print("\nã€è®­ç»ƒæ±‡æ€»ã€‘")
    print(f"  çª—å£æ•°é‡: {summary['n_windows']}")
    print(f"  å¹³å‡è®­ç»ƒæŸå¤±: {summary['avg_train_loss']:.6f}")
    print(f"  å¹³å‡éªŒè¯æŸå¤±: {summary['avg_val_loss']:.6f}")
    print(f"  å¹³å‡æœ€ä½³Epoch: {summary['avg_best_epoch']:.1f}")
    
    # é¢„æµ‹æ±‡æ€»
    print("\nã€é¢„æµ‹æ±‡æ€»ã€‘")
    print(f"  æ€»é¢„æµ‹æ ·æœ¬: {len(predictions):,}")
    print(f"  æ—¶é—´èŒƒå›´: {predictions[data_config.time_col].min()} ~ {predictions[data_config.time_col].max()}")
    print(f"  è‚¡ç¥¨æ•°é‡: {predictions[data_config.stock_col].nunique()}")
    
    # ICåˆ†æ
    print("\nã€ICåˆ†æã€‘")
    from scipy.stats import pearsonr, spearmanr
    import numpy as np
    
    pred_values = predictions['pred_alpha'].values
    label_values = predictions[data_config.label_col].values
    
    overall_ic, _ = pearsonr(pred_values, label_values)
    overall_rank_ic, _ = spearmanr(pred_values, label_values)
    
    print(f"  æ€»ä½“ Pearson IC: {overall_ic:.4f}")
    print(f"  æ€»ä½“ Spearman IC: {overall_rank_ic:.4f}")
    
    # å„çª—å£IC
    print("\n  å„çª—å£IC:")
    window_ics = []
    for window_idx in sorted(predictions['window_idx'].unique()):
        window_data = predictions[predictions['window_idx'] == window_idx]
        window_ic, _ = pearsonr(
            window_data['pred_alpha'].values,
            window_data[data_config.label_col].values
        )
        window_ics.append(window_ic)
        print(f"    çª—å£ {window_idx:2d}: IC={window_ic:7.4f}")
    
    # ICç¨³å®šæ€§
    print("\n  ICç¨³å®šæ€§:")
    print(f"    å¹³å‡IC: {np.mean(window_ics):.4f}")
    print(f"    ICæ ‡å‡†å·®: {np.std(window_ics):.4f}")
    print(f"    ICèƒœç‡: {np.mean(np.array(window_ics) > 0):.2%}")
    
    print("\n" + "=" * 80)
    print("âœ… æ»šåŠ¨çª—å£è®­ç»ƒæµç¨‹å®Œæˆï¼")
    print("=" * 80)
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. æŸ¥çœ‹ output/rolling_models/ ç›®å½•ä¸­çš„å„çª—å£æ¨¡å‹")
    print("  2. å¯¹æ¯”ä¸åŒçª—å£çš„ICè¡¨ç°ï¼Œåˆ†æå¸‚åœºç¯å¢ƒå½±å“")
    print("  3. ä½¿ç”¨ backtest è¿›è¡Œæ›´æ·±å…¥çš„å› å­åˆ†æ")
    print("  4. å‚è€ƒæ–‡æ¡£: quantclassic/data_set/ROLLING_WINDOW_GUIDE.md")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
