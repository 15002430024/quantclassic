"""
FeatureEngineer - ç‰¹å¾å·¥ç¨‹å¸ˆ

æä¾›ç‰¹å¾é€‰æ‹©ã€ç‰¹å¾ç¼“å­˜å’Œè‡ªåŠ¨ç­›é€‰åŠŸèƒ½
"""

import os
import pandas as pd
import numpy as np
from typing import List, Optional, Dict, Any
import logging
import pickle
from pathlib import Path
from .config import DataConfig


class FeatureEngineer:
    """ç‰¹å¾å·¥ç¨‹å¸ˆ - ç®¡ç†ç‰¹å¾é€‰æ‹©å’Œå¤„ç†"""
    
    def __init__(self, config: DataConfig):
        """
        Args:
            config: DataConfigé…ç½®å¯¹è±¡
        """
        self.config = config
        self.logger = self._setup_logger()
        self.feature_cols: Optional[List[str]] = None
        self.feature_stats: Optional[Dict[str, Any]] = None
    
    def _setup_logger(self) -> logging.Logger:
        """é…ç½®æ—¥å¿—"""
        logger = logging.getLogger('FeatureEngineer')
        logger.setLevel(getattr(logging, self.config.log_level))
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def select_features(self, df: pd.DataFrame, 
                       auto_select: bool = True) -> List[str]:
        """
        é€‰æ‹©ç‰¹å¾åˆ—
        
        Args:
            df: æ•°æ®DataFrame
            auto_select: æ˜¯å¦è‡ªåŠ¨é€‰æ‹©ç‰¹å¾
            
        Returns:
            ç‰¹å¾åˆ—åˆ—è¡¨
        """
        # å¦‚æœé…ç½®ä¸­å·²æŒ‡å®šç‰¹å¾åˆ—
        if self.config.feature_cols is not None:
            self.feature_cols = self.config.feature_cols
            self.logger.info(f"âœ… ä½¿ç”¨é…ç½®çš„ç‰¹å¾åˆ—: {len(self.feature_cols)} åˆ—")
            return self.feature_cols
        
        if not auto_select:
            raise ValueError("æœªæŒ‡å®šç‰¹å¾åˆ—ä¸”auto_select=False")
        
        self.logger.info("ğŸ” è‡ªåŠ¨æ£€æµ‹ç‰¹å¾åˆ—...")
        
        # æ’é™¤åˆ—ï¼ˆåŒ…æ‹¬é…ç½®çš„æ’é™¤åˆ— + ç³»ç»Ÿåˆ—ï¼‰
        exclude = set(self.config.exclude_cols)
        
        # ã€ä¿®å¤ã€‘å¼ºåˆ¶æ’é™¤ç³»ç»Ÿåˆ—ï¼ˆstock_col, time_col, label_colï¼‰
        system_cols = {
            self.config.stock_col,
            self.config.time_col,
            self.config.label_col
        }
        exclude.update(system_cols)
        
        # é€‰æ‹©æ•°å€¼å‹åˆ—
        feature_cols = [
            col for col in df.columns
            if col not in exclude and pd.api.types.is_numeric_dtype(df[col])
        ]
        
        self.feature_cols = feature_cols
        self.logger.info(f"âœ… è‡ªåŠ¨é€‰æ‹©ç‰¹å¾åˆ—: {len(feature_cols)} åˆ—")
        
        return feature_cols
    
    def compute_feature_stats(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è®¡ç®—ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            df: æ•°æ®DataFrame
            
        Returns:
            ç‰¹å¾ç»Ÿè®¡å­—å…¸
        """
        if self.feature_cols is None:
            self.select_features(df)
        
        self.logger.info("ğŸ“Š è®¡ç®—ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯...")
        
        stats = {}
        for col in self.feature_cols:
            col_data = df[col].dropna()
            
            stats[col] = {
                'mean': float(col_data.mean()),
                'std': float(col_data.std()),
                'min': float(col_data.min()),
                'max': float(col_data.max()),
                'q25': float(col_data.quantile(0.25)),
                'q50': float(col_data.quantile(0.50)),
                'q75': float(col_data.quantile(0.75)),
                'missing_ratio': float(df[col].isnull().sum() / len(df)),
                'unique_ratio': float(df[col].nunique() / len(df)),
            }
        
        self.feature_stats = stats
        return stats
    
    def filter_features(self, df: pd.DataFrame,
                       min_variance: float = 1e-6,
                       max_missing_ratio: float = 0.5,
                       max_correlation: float = 0.95) -> List[str]:
        """
        è¿‡æ»¤ä½è´¨é‡ç‰¹å¾
        
        Args:
            df: æ•°æ®DataFrame
            min_variance: æœ€å°æ–¹å·®é˜ˆå€¼
            max_missing_ratio: æœ€å¤§ç¼ºå¤±ç‡
            max_correlation: æœ€å¤§ç›¸å…³æ€§é˜ˆå€¼
            
        Returns:
            è¿‡æ»¤åçš„ç‰¹å¾åˆ—åˆ—è¡¨
        """
        if self.feature_cols is None:
            self.select_features(df)
        
        self.logger.info("ğŸ”§ è¿‡æ»¤ä½è´¨é‡ç‰¹å¾...")
        
        filtered_cols = self.feature_cols.copy()
        remove_reasons = {}
        
        # 1. è¿‡æ»¤ä½æ–¹å·®ç‰¹å¾
        for col in self.feature_cols:
            if df[col].var() < min_variance:
                if col in filtered_cols:
                    filtered_cols.remove(col)
                    remove_reasons[col] = 'low_variance'
        
        # 2. è¿‡æ»¤é«˜ç¼ºå¤±ç‡ç‰¹å¾
        for col in self.feature_cols:
            missing_ratio = df[col].isnull().sum() / len(df)
            if missing_ratio > max_missing_ratio:
                if col in filtered_cols:
                    filtered_cols.remove(col)
                    remove_reasons[col] = 'high_missing'
        
        # 3. è¿‡æ»¤é«˜ç›¸å…³æ€§ç‰¹å¾
        if len(filtered_cols) > 1:
            corr_matrix = df[filtered_cols].corr().abs()
            
            # æ‰¾åˆ°é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹
            high_corr_pairs = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    if corr_matrix.iloc[i, j] > max_correlation:
                        col1, col2 = corr_matrix.columns[i], corr_matrix.columns[j]
                        high_corr_pairs.append((col1, col2, corr_matrix.iloc[i, j]))
            
            # ç§»é™¤é«˜ç›¸å…³æ€§ç‰¹å¾ï¼ˆä¿ç•™æ–¹å·®è¾ƒå¤§çš„ï¼‰
            for col1, col2, corr_val in high_corr_pairs:
                if col1 in filtered_cols and col2 in filtered_cols:
                    var1, var2 = df[col1].var(), df[col2].var()
                    remove_col = col1 if var1 < var2 else col2
                    filtered_cols.remove(remove_col)
                    remove_reasons[remove_col] = f'high_correlation_with_{col2 if remove_col==col1 else col1}'
        
        # è¾“å‡ºè¿‡æ»¤ç»“æœ
        removed_count = len(self.feature_cols) - len(filtered_cols)
        self.logger.info(f"   ç§»é™¤ {removed_count} ä¸ªç‰¹å¾:")
        self.logger.info(f"   - ä½æ–¹å·®: {sum(1 for v in remove_reasons.values() if v=='low_variance')}")
        self.logger.info(f"   - é«˜ç¼ºå¤±: {sum(1 for v in remove_reasons.values() if v=='high_missing')}")
        self.logger.info(f"   - é«˜ç›¸å…³: {sum(1 for v in remove_reasons.values() if 'correlation' in v)}")
        self.logger.info(f"âœ… ä¿ç•™ {len(filtered_cols)} ä¸ªç‰¹å¾")
        
        self.feature_cols = filtered_cols
        return filtered_cols
    
    def save_feature_info(self, save_dir: Optional[str] = None):
        """ä¿å­˜ç‰¹å¾ä¿¡æ¯"""
        if save_dir is None:
            save_dir = self.config.output_dir
        
        Path(save_dir).mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜ç‰¹å¾åˆ—è¡¨
        feature_list_path = os.path.join(save_dir, 'feature_columns.txt')
        with open(feature_list_path, 'w') as f:
            f.write('\n'.join(self.feature_cols))
        
        # ä¿å­˜ç‰¹å¾ç»Ÿè®¡
        if self.feature_stats:
            stats_path = os.path.join(save_dir, 'feature_stats.pkl')
            with open(stats_path, 'wb') as f:
                pickle.dump(self.feature_stats, f)
        
        self.logger.info(f"ğŸ’¾ ç‰¹å¾ä¿¡æ¯å·²ä¿å­˜åˆ°: {save_dir}")
    
    def load_feature_info(self, load_dir: Optional[str] = None):
        """åŠ è½½ç‰¹å¾ä¿¡æ¯"""
        if load_dir is None:
            load_dir = self.config.output_dir
        
        # åŠ è½½ç‰¹å¾åˆ—è¡¨
        feature_list_path = os.path.join(load_dir, 'feature_columns.txt')
        if os.path.exists(feature_list_path):
            with open(feature_list_path, 'r') as f:
                self.feature_cols = [line.strip() for line in f]
        
        # åŠ è½½ç‰¹å¾ç»Ÿè®¡
        stats_path = os.path.join(load_dir, 'feature_stats.pkl')
        if os.path.exists(stats_path):
            with open(stats_path, 'rb') as f:
                self.feature_stats = pickle.load(f)
        
        self.logger.info(f"ğŸ“ ç‰¹å¾ä¿¡æ¯å·²åŠ è½½: {len(self.feature_cols)} åˆ—")


if __name__ == '__main__':
    # æµ‹è¯•ç‰¹å¾å·¥ç¨‹å¸ˆ
    from config import DataConfig
    
    print("=" * 80)
    print("FeatureEngineer æµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºé…ç½®
    config = DataConfig()
    
    # åˆ›å»ºç‰¹å¾å·¥ç¨‹å¸ˆ
    engineer = FeatureEngineer(config)
    
    # æ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    df = pd.DataFrame({
        'ts_code': ['000001.SZ'] * 100,
        'trade_date': pd.date_range('2020-01-01', periods=100),
        'y_processed': np.random.randn(100),
        'feature1': np.random.randn(100),
        'feature2': np.random.randn(100),
        'feature3': np.random.randn(100) * 0.0001,  # ä½æ–¹å·®
        'feature4': [np.nan] * 60 + list(np.random.randn(40)),  # é«˜ç¼ºå¤±
    })
    
    # æµ‹è¯•ç‰¹å¾é€‰æ‹©
    features = engineer.select_features(df)
    print(f"\n1. è‡ªåŠ¨é€‰æ‹©ç‰¹å¾: {len(features)} åˆ—")
    print(f"   {features}")
    
    # æµ‹è¯•ç‰¹å¾è¿‡æ»¤
    filtered = engineer.filter_features(df, min_variance=1e-4, max_missing_ratio=0.5)
    print(f"\n2. è¿‡æ»¤åç‰¹å¾: {len(filtered)} åˆ—")
    print(f"   {filtered}")
    
    # æµ‹è¯•ç»Ÿè®¡è®¡ç®—
    stats = engineer.compute_feature_stats(df)
    print(f"\n3. ç‰¹å¾ç»Ÿè®¡: {len(stats)} åˆ—")
    
    print("\nâœ… ç‰¹å¾å·¥ç¨‹å¸ˆæµ‹è¯•å®Œæˆ")
