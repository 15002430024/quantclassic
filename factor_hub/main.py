#!/usr/bin/env python3
"""
FactorHub - ç«¯åˆ°ç«¯æ¼”ç¤ºè„šæœ¬

è¯¥è„šæœ¬æ¨¡æ‹Ÿç”¨æˆ·è°ƒç”¨è¿‡ç¨‹ï¼š
1. ç”¨æˆ·æŒ‡å®šè‚¡ç¥¨æ± å’Œæ—¶é—´
2. ç”¨æˆ·é€‰æ‹©å› å­åˆ—è¡¨
3. ç³»ç»Ÿè‡ªåŠ¨æ‹‰å–æ•°æ® -> è®¡ç®— -> ä¿å­˜æ–‡ä»¶

Usage:
    python main.py
    
    æˆ–è€…ä½œä¸ºæ¨¡å—è¿è¡Œ:
    python -m quantclassic.factor_hub.main
"""

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
sys.path.insert(0, project_root)

from datetime import datetime
from typing import List

import pandas as pd

# å¯¼å…¥ FactorHub ç»„ä»¶
from quantclassic.factor_hub.factors import demo_factors  # noqa: è§¦å‘å› å­æ³¨å†Œ
from quantclassic.factor_hub.providers.mock_provider import MockDataProvider
from quantclassic.factor_hub.engine.factor_engine import FactorEngine
from quantclassic.factor_hub.io.writers import CSVWriter, ParquetWriter, FactorWriterFactory


def run_factor_pipeline(
    symbols: List[str],
    factor_names: List[str],
    start: str,
    end: str,
    output_dir: str = "./output",
    output_format: str = "csv",
) -> pd.DataFrame:
    """
    è¿è¡Œå› å­è®¡ç®—æµæ°´çº¿
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        factor_names: å› å­åç§°åˆ—è¡¨
        start: èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
        end: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        output_dir: è¾“å‡ºç›®å½•
        output_format: è¾“å‡ºæ ¼å¼ (csv/parquet)
        
    Returns:
        pd.DataFrame: å› å­è®¡ç®—ç»“æœ
    """
    print("\n" + "=" * 70)
    print("         FactorHub - å› å­è®¡ç®—æ¡†æ¶ v1.0.0")
    print("=" * 70)
    
    # 1. é…ç½®å‚æ•°æ˜¾ç¤º
    print("\nğŸ“‹ é…ç½®å‚æ•°:")
    print(f"    è‚¡ç¥¨æ± : {symbols}")
    print(f"    å› å­åˆ—è¡¨: {factor_names}")
    print(f"    æ—¶é—´èŒƒå›´: {start} ~ {end}")
    print(f"    è¾“å‡ºç›®å½•: {output_dir}")
    print(f"    è¾“å‡ºæ ¼å¼: {output_format}")
    
    # 2. åˆå§‹åŒ–æ•°æ®æä¾›è€…
    print("\nğŸ“Š åˆå§‹åŒ–æ•°æ®æä¾›è€…...")
    provider = MockDataProvider(seed=2024)  # ä½¿ç”¨å›ºå®šç§å­ä¿è¯å¯å¤ç°
    print(f"    âœ“ ä½¿ç”¨ {provider.name}")
    
    # 3. åˆå§‹åŒ–å› å­è®¡ç®—å¼•æ“
    print("\nâš™ï¸ åˆå§‹åŒ–å› å­è®¡ç®—å¼•æ“...")
    engine = FactorEngine(provider, continue_on_error=True, verbose=False)
    print(f"    âœ“ å¯ç”¨å› å­: {engine.list_available_factors()}")
    
    # 4. åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # 5. è¿è¡Œå› å­è®¡ç®—
    print("\nğŸš€ å¼€å§‹å› å­è®¡ç®—...")
    print("-" * 60)
    
    result = engine.run(
        symbols=symbols,
        factor_names=factor_names,
        start=start,
        end=end,
        factor_params={
            "volatility": {"window": 20},
            "return_5d": {"period": 5},
            "turnover_ratio": {"window": 20},
        }
    )
    
    print("-" * 60)
    
    # 6. æ˜¾ç¤ºè®¡ç®—ç»“æœ
    print("\nğŸ“ˆ è®¡ç®—ç»“æœ:")
    print(f"    æˆåŠŸå› å­: {result.successful_factors}")
    print(f"    å¤±è´¥å› å­: {result.failed_factors}")
    print(f"    ç»“æœå½¢çŠ¶: {result.factors_data.shape}")
    print(f"    æ€»è€—æ—¶: {result.total_time:.2f}s")
    
    if not result.factors_data.empty:
        print("\n    å› å­æ•°æ®é¢„è§ˆ (å‰10è¡Œ):")
        print(result.factors_data.head(10))
        
        # å› å­ç»Ÿè®¡
        print("\n    å› å­ç»Ÿè®¡ä¿¡æ¯:")
        print(result.factors_data.describe())
    
    # 7. ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ä¿å­˜ç»“æœ...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜ CSV
    csv_path = os.path.join(output_dir, f"factors_{timestamp}.csv")
    csv_writer = CSVWriter()
    csv_writer.write(result.factors_data, csv_path)
    print(f"    âœ“ CSV æ–‡ä»¶å·²ä¿å­˜: {csv_path}")
    
    # ä¿å­˜ Parquet
    parquet_path = os.path.join(output_dir, f"factors_{timestamp}.parquet")
    parquet_writer = ParquetWriter(compression="snappy")
    parquet_writer.write(result.factors_data, parquet_path)
    print(f"    âœ“ Parquet æ–‡ä»¶å·²ä¿å­˜: {parquet_path}")
    
    # 8. éªŒè¯ä¿å­˜çš„æ–‡ä»¶
    print("\nâœ… éªŒè¯ä¿å­˜çš„æ–‡ä»¶...")
    
    # è¯»å–å¹¶æ˜¾ç¤º CSV æ–‡ä»¶ä¿¡æ¯
    df_csv = pd.read_csv(csv_path, index_col=[0, 1], parse_dates=True)
    print(f"    CSV æ–‡ä»¶:")
    print(f"        - å¤§å°: {os.path.getsize(csv_path) / 1024:.2f} KB")
    print(f"        - è¡Œæ•°: {len(df_csv)}")
    print(f"        - åˆ—æ•°: {len(df_csv.columns)}")
    
    # è¯»å–å¹¶æ˜¾ç¤º Parquet æ–‡ä»¶ä¿¡æ¯
    df_parquet = pd.read_parquet(parquet_path)
    print(f"    Parquet æ–‡ä»¶:")
    print(f"        - å¤§å°: {os.path.getsize(parquet_path) / 1024:.2f} KB")
    print(f"        - è¡Œæ•°: {len(df_parquet)}")
    print(f"        - åˆ—æ•°: {len(df_parquet.columns)}")
    
    print("\n" + "=" * 70)
    print("         âœ“ ç«¯åˆ°ç«¯æµç¨‹å®Œæˆ!")
    print("=" * 70)
    
    return result.factors_data


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´çš„å› å­è®¡ç®—æµç¨‹"""
    
    # ç”¨æˆ·é…ç½®
    SYMBOLS = [
        "000001.SZ",  # å¹³å®‰é“¶è¡Œ
        "000002.SZ",  # ä¸‡ç§‘A
        "600000.SH",  # æµ¦å‘é“¶è¡Œ
        "600519.SH",  # è´µå·èŒ…å°
        "000858.SZ",  # äº”ç²®æ¶²
    ]
    
    FACTOR_NAMES = [
        "return_1d",      # 1æ—¥æ”¶ç›Šç‡
        "return_5d",      # 5æ—¥æ”¶ç›Šç‡
        "volatility",     # æ³¢åŠ¨ç‡
        "turnover_ratio", # æ¢æ‰‹ç‡
        "price_range",    # ä»·æ ¼æŒ¯å¹…
    ]
    
    START_DATE = "2024-01-01"
    END_DATE = "2024-03-31"
    OUTPUT_DIR = "./quantclassic/factor_hub/output"
    
    # è¿è¡Œæµæ°´çº¿
    factors_df = run_factor_pipeline(
        symbols=SYMBOLS,
        factor_names=FACTOR_NAMES,
        start=START_DATE,
        end=END_DATE,
        output_dir=OUTPUT_DIR,
    )
    
    return factors_df


if __name__ == "__main__":
    main()
