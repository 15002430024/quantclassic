# QuantClassic Workflowä½¿ç”¨ç¤ºä¾‹

## ç›®å½•
1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [åŸºæœ¬ä½¿ç”¨](#åŸºæœ¬ä½¿ç”¨)
3. [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
4. [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)

---

## å¿«é€Ÿå¼€å§‹

### æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼

```python
from quantclassic.workflow import R

# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨ç®¡ç†å®éªŒç”Ÿå‘½å‘¨æœŸ
with R.start(experiment_name="my_first_exp"):
    # è®°å½•å‚æ•°
    R.log_params(learning_rate=0.001, batch_size=32)
    
    # è®°å½•æŒ‡æ ‡
    R.log_metrics(epoch=1, loss=0.5, accuracy=0.85)
    
    # ä¿å­˜å¯¹è±¡
    R.save_objects(model=my_model, config=config_dict)
```

### ä¸ºä»€ä¹ˆä½¿ç”¨Workflowï¼Ÿ

- âœ… **è‡ªåŠ¨è¿½è¸ª**: æ— éœ€æ‰‹åŠ¨ç®¡ç†æ—¥å¿—æ–‡ä»¶
- âœ… **ç‰ˆæœ¬ç®¡ç†**: æ¯æ¬¡è¿è¡Œè‡ªåŠ¨ç”Ÿæˆå”¯ä¸€ID
- âœ… **å¯å¤ç°**: å‚æ•°ã€æŒ‡æ ‡ã€æ¨¡å‹å…¨éƒ¨ä¿å­˜
- âœ… **å¯¹æ¯”åˆ†æ**: è½»æ¾æ¯”è¾ƒä¸åŒå®éªŒç»“æœ

---

## åŸºæœ¬ä½¿ç”¨

### 1. è®°å½•è®­ç»ƒè¿‡ç¨‹

```python
from quantclassic.workflow import R
import torch
import torch.nn as nn

# å®šä¹‰æ¨¡å‹
model = nn.LSTM(input_size=10, hidden_size=64, num_layers=2)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# å¼€å§‹å®éªŒ
with R.start(experiment_name="lstm_training", 
             model_type="LSTM",
             hidden_size=64,
             num_layers=2):
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(10):
        # ... è®­ç»ƒä»£ç  ...
        train_loss = train_one_epoch(model, train_loader, optimizer)
        val_loss = validate(model, val_loader)
        
        # è®°å½•æ¯ä¸ªepochçš„æŒ‡æ ‡
        R.log_metrics(
            epoch=epoch,
            train_loss=train_loss,
            val_loss=val_loss
        )
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    R.save_objects(
        model=model.state_dict(),
        optimizer=optimizer.state_dict()
    )
```

### 2. è¶…å‚æ•°è°ƒä¼˜

```python
from quantclassic.workflow import R

# å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´
param_grid = {
    'learning_rate': [0.001, 0.01, 0.1],
    'hidden_size': [32, 64, 128],
    'dropout': [0.1, 0.3, 0.5]
}

# éå†æ‰€æœ‰ç»„åˆ
for lr in param_grid['learning_rate']:
    for hidden in param_grid['hidden_size']:
        for dropout in param_grid['dropout']:
            
            # æ¯ç»„å‚æ•°å¯åŠ¨ä¸€ä¸ªæ–°çš„recorder
            with R.start(experiment_name="hyperparameter_search",
                        learning_rate=lr,
                        hidden_size=hidden,
                        dropout=dropout):
                
                # è®­ç»ƒæ¨¡å‹
                model = build_model(hidden, dropout)
                train_model(model, lr)
                
                # è®°å½•æœ€ç»ˆæ€§èƒ½
                val_ic = evaluate(model, val_data)
                R.log_metrics(val_ic=val_ic)
                
                # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜
                if val_ic > best_ic:
                    R.save_objects(best_model=model)
```

### 3. æŸ¥çœ‹å®éªŒç»“æœ

```python
from quantclassic.workflow import R

# åˆ—å‡ºæ‰€æœ‰å®éªŒ
experiments = R.list_experiments()
print("æ‰€æœ‰å®éªŒ:")
for name, info in experiments.items():
    print(f"  {name}: {info['recorder_count']} runs")

# æŸ¥çœ‹æŸä¸ªå®éªŒçš„æ‰€æœ‰runs
recorders = R.list_recorders("hyperparameter_search")
for rec_id, rec_info in recorders.items():
    params = rec_info.get('params', {})
    print(f"Run {rec_id}:")
    print(f"  LR={params.get('learning_rate')}, "
          f"Hidden={params.get('hidden_size')}")

# æœç´¢æœ€ä½³run
best_runs = R.search_recorders(
    experiment_name="hyperparameter_search",
    status="FINISHED"
)

# æ‰¾å‡ºICæœ€é«˜çš„run
best_ic = -float('inf')
best_recorder = None

for run in best_runs:
    recorder = R.get_recorder(
        experiment_name="hyperparameter_search",
        recorder_id=run['recorder_id']
    )
    metrics = recorder.get_metrics()
    if metrics and 'val_ic' in metrics:
        ic = metrics['val_ic'][-1][1]  # è·å–æœ€åä¸€ä¸ªICå€¼
        if ic > best_ic:
            best_ic = ic
            best_recorder = recorder

print(f"æœ€ä½³IC: {best_ic}")
print(f"æœ€ä½³å‚æ•°: {best_recorder.params}")
```

### 4. åŠ è½½å·²ä¿å­˜çš„å¯¹è±¡

```python
from quantclassic.workflow import R

# åŠ è½½ä¹‹å‰ä¿å­˜çš„æ¨¡å‹
model_state = R.load_object(
    experiment_name="lstm_training",
    recorder_id="rec_20240115_120000_abc123",
    object_name="model"
)

# æ¢å¤æ¨¡å‹
model = build_model()
model.load_state_dict(model_state)

# ç»§ç»­è®­ç»ƒæˆ–æ¨ç†
predictions = model(test_data)
```

---

## é«˜çº§åŠŸèƒ½

### 1. æ¢å¤ä¸­æ–­çš„è®­ç»ƒ

```python
from quantclassic.workflow import R

# æ¢å¤ä¹‹å‰çš„recorder
with R.start(experiment_name="long_training",
            recorder_name="my_training",
            resume=True):
    
    # åŠ è½½checkpoint
    checkpoint = R.current_recorder.load_object("checkpoint")
    start_epoch = checkpoint['epoch']
    
    # ä»ä¸­æ–­å¤„ç»§ç»­
    for epoch in range(start_epoch, total_epochs):
        train_loss = train_one_epoch(model, train_loader)
        R.log_metrics(epoch=epoch, loss=train_loss)
        
        # å®šæœŸä¿å­˜checkpoint
        if epoch % 10 == 0:
            R.save_objects(
                checkpoint={
                    'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': optimizer.state_dict()
                }
            )
```

### 2. åµŒå¥—å®éªŒç®¡ç†

```python
from quantclassic.workflow import R

# ä¸»å®éªŒ: æµ‹è¯•ä¸åŒæ¨¡å‹æ¶æ„
model_types = ['LSTM', 'GRU', 'Transformer']

for model_type in model_types:
    with R.start(experiment_name=f"model_comparison_{model_type}",
                model_type=model_type):
        
        # å­å®éªŒ: æ¯ä¸ªæ¶æ„çš„è¶…å‚æ•°è°ƒä¼˜
        for lr in [0.001, 0.01]:
            for hidden in [64, 128]:
                
                with R.start(experiment_name=f"tuning_{model_type}",
                            learning_rate=lr,
                            hidden_size=hidden):
                    
                    model = build_model(model_type, hidden)
                    train_model(model, lr)
                    
                    val_ic = evaluate(model, val_data)
                    R.log_metrics(val_ic=val_ic)
```

### 3. è‡ªå®šä¹‰Recorder

```python
from quantclassic.workflow import ExpManager, Recorder

# ä¸ä½¿ç”¨å…¨å±€Rï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨ExpManager
exp_manager = ExpManager(exp_dir="custom_output/experiments")

# æ‰‹åŠ¨åˆ›å»ºexperiment
experiment = exp_manager.create_experiment("custom_exp")

# æ‰‹åŠ¨åˆ›å»ºrecorder
recorder_id = exp_manager.start_recorder(
    experiment_name="custom_exp",
    recorder_name="custom_run"
)

# è·å–recorderå®ä¾‹
recorder = exp_manager.get_recorder("custom_exp", recorder_id)

# ä½¿ç”¨recorder
recorder.log_params(custom_param=123)
recorder.log_metrics(step=1, custom_metric=0.99)

# æ‰‹åŠ¨ç»“æŸ
exp_manager.end_recorder("custom_exp", recorder_id, status="FINISHED")
```

---

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1: å› å­æŒ–æ˜å®éªŒ

```python
from quantclassic.workflow import R
from quantclassic.Factorsystem import FactorGenerator
import pandas as pd

# å®éªŒ: æµ‹è¯•ä¸åŒå› å­ç»„åˆ
factor_combinations = [
    ['momentum', 'reversal'],
    ['momentum', 'volatility'],
    ['value', 'quality']
]

for factors in factor_combinations:
    factor_name = "+".join(factors)
    
    with R.start(experiment_name="factor_mining",
                factor_combination=factors):
        
        # ç”Ÿæˆå› å­
        fg = FactorGenerator()
        factor_data = fg.generate(factors)
        
        # è®¡ç®—IC
        ic_values = calculate_ic(factor_data, returns)
        
        # è®°å½•ç»“æœ
        R.log_metrics(
            mean_ic=ic_values.mean(),
            ic_std=ic_values.std(),
            ic_ir=ic_values.mean() / ic_values.std()
        )
        
        # ä¿å­˜å› å­æ•°æ®
        R.save_objects(
            factor_data=factor_data,
            ic_series=ic_values
        )

# åˆ†ææœ€ä½³å› å­ç»„åˆ
all_runs = R.list_recorders("factor_mining")
best_ir = -float('inf')

for rec_id, rec_info in all_runs.items():
    recorder = R.get_recorder("factor_mining", rec_id)
    metrics = recorder.get_metrics()
    
    if 'ic_ir' in metrics:
        ir = metrics['ic_ir'][-1][1]
        if ir > best_ir:
            best_ir = ir
            best_factors = recorder.params['factor_combination']

print(f"æœ€ä½³å› å­ç»„åˆ: {best_factors}, IR={best_ir}")
```

### æ¡ˆä¾‹2: æ¨¡å‹é›†æˆå®éªŒ

```python
from quantclassic.workflow import R
from quantclassic.model import ModelFactory
import numpy as np

# è®­ç»ƒå¤šä¸ªæ¨¡å‹
models_info = []

for i in range(5):
    with R.start(experiment_name="ensemble_training",
                model_id=i,
                random_seed=i*100):
        
        # ä½¿ç”¨ä¸åŒéšæœºç§å­è®­ç»ƒ
        np.random.seed(i * 100)
        
        model = ModelFactory.create_model('LSTM', config)
        train_model(model, train_data)
        
        # è¯„ä¼°
        val_pred = model.predict(val_data)
        val_ic = calculate_ic(val_pred, val_returns)
        
        R.log_metrics(val_ic=val_ic)
        R.save_objects(model=model)
        
        # è®°å½•æ¨¡å‹ä¿¡æ¯ç”¨äºåç»­é›†æˆ
        models_info.append({
            'experiment': 'ensemble_training',
            'recorder_id': R.current_recorder.recorder_id,
            'ic': val_ic
        })

# é›†æˆæ‰€æœ‰æ¨¡å‹
with R.start(experiment_name="ensemble_prediction"):
    predictions = []
    
    for info in models_info:
        # åŠ è½½æ¯ä¸ªæ¨¡å‹
        model = R.load_object(
            experiment_name=info['experiment'],
            recorder_id=info['recorder_id'],
            object_name='model'
        )
        
        # é¢„æµ‹
        pred = model.predict(test_data)
        predictions.append(pred)
    
    # å¹³å‡é›†æˆ
    ensemble_pred = np.mean(predictions, axis=0)
    
    # è¯„ä¼°é›†æˆæ•ˆæœ
    test_ic = calculate_ic(ensemble_pred, test_returns)
    R.log_metrics(
        test_ic=test_ic,
        num_models=len(predictions)
    )
    
    R.save_objects(
        ensemble_prediction=ensemble_pred,
        individual_predictions=predictions
    )
```

### æ¡ˆä¾‹3: A/Bæµ‹è¯•

```python
from quantclassic.workflow import R
import datetime

# ç­–ç•¥A: åŸºç¡€ç‰ˆæœ¬
with R.start(experiment_name="strategy_ab_test",
            strategy_version="A",
            test_date=str(datetime.date.today())):
    
    # è¿è¡Œç­–ç•¥A
    positions_a = strategy_a.generate_positions(data)
    returns_a = backtest(positions_a, price_data)
    
    R.log_metrics(
        total_return=returns_a.sum(),
        sharpe_ratio=calculate_sharpe(returns_a),
        max_drawdown=calculate_mdd(returns_a)
    )
    
    R.save_objects(
        positions=positions_a,
        returns=returns_a
    )

# ç­–ç•¥B: æ”¹è¿›ç‰ˆæœ¬
with R.start(experiment_name="strategy_ab_test",
            strategy_version="B",
            test_date=str(datetime.date.today())):
    
    # è¿è¡Œç­–ç•¥B
    positions_b = strategy_b.generate_positions(data)
    returns_b = backtest(positions_b, price_data)
    
    R.log_metrics(
        total_return=returns_b.sum(),
        sharpe_ratio=calculate_sharpe(returns_b),
        max_drawdown=calculate_mdd(returns_b)
    )
    
    R.save_objects(
        positions=positions_b,
        returns=returns_b
    )

# å¯¹æ¯”åˆ†æ
recorders = R.list_recorders("strategy_ab_test")

print("A/Bæµ‹è¯•ç»“æœå¯¹æ¯”:")
print("-" * 50)

for rec_id, rec_info in recorders.items():
    version = rec_info['params']['strategy_version']
    recorder = R.get_recorder("strategy_ab_test", rec_id)
    metrics = recorder.get_metrics()
    
    print(f"\nç­–ç•¥ {version}:")
    print(f"  æ€»æ”¶ç›Š: {metrics['total_return'][-1][1]:.2%}")
    print(f"  å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio'][-1][1]:.3f}")
    print(f"  æœ€å¤§å›æ’¤: {metrics['max_drawdown'][-1][1]:.2%}")
```

---

## æœ€ä½³å®è·µ

### 1. å‘½åè§„èŒƒ

```python
# âœ… å¥½çš„å‘½å
with R.start(experiment_name="lstm_price_prediction_v2"):
    ...

# âŒ é¿å…çš„å‘½å
with R.start(experiment_name="test"):
    ...
```

### 2. å‚æ•°è®°å½•

```python
# âœ… è®°å½•æ‰€æœ‰é‡è¦å‚æ•°
with R.start(experiment_name="training",
            learning_rate=0.001,
            batch_size=256,
            hidden_size=64,
            dropout=0.3,
            optimizer="Adam",
            data_range="2020-2023"):
    ...

# âŒ å‚æ•°è®°å½•ä¸å®Œæ•´
with R.start(experiment_name="training"):
    R.log_params(lr=0.001)  # å…¶ä»–å‚æ•°ç¼ºå¤±
```

### 3. æŒ‡æ ‡è®°å½•

```python
# âœ… ä½¿ç”¨stepå‚æ•°ä¿æŒé¡ºåº
for epoch in range(100):
    R.log_metrics(epoch=epoch, loss=loss, acc=acc)

# âœ… è®°å½•å¤šç»´åº¦æŒ‡æ ‡
R.log_metrics(
    train_loss=0.1,
    val_loss=0.15,
    test_loss=0.12,
    train_ic=0.05,
    val_ic=0.04
)
```

### 4. å¯¹è±¡ä¿å­˜

```python
# âœ… ä¿å­˜å®Œæ•´çš„å¯å¤ç°ä¿¡æ¯
R.save_objects(
    model=model.state_dict(),
    optimizer=optimizer.state_dict(),
    config=config_dict,
    scaler=data_scaler,
    feature_names=feature_columns
)

# âš ï¸ åªä¿å­˜æ¨¡å‹å¯èƒ½ä¸å¤Ÿ
R.save_objects(model=model)
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜1: "è¯·å…ˆä½¿ç”¨ R.start() å¯åŠ¨recorder"

```python
# âŒ é”™è¯¯: åœ¨startä¹‹å¤–ä½¿ç”¨
R.log_metrics(loss=0.5)  # æŠ¥é”™!

# âœ… æ­£ç¡®: åœ¨startå†…éƒ¨ä½¿ç”¨
with R.start(experiment_name="test"):
    R.log_metrics(loss=0.5)  # OK
```

### é—®é¢˜2: Recorderç›®å½•æ‰¾ä¸åˆ°

```python
# æ£€æŸ¥å®éªŒç›®å½•
experiments = R.list_experiments()
print(experiments)

# æ£€æŸ¥recorder
recorders = R.list_recorders("my_experiment")
print(recorders)
```

### é—®é¢˜3: åŠ è½½å¯¹è±¡å¤±è´¥

```python
# ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„experiment_nameå’Œrecorder_id
try:
    obj = R.load_object(
        experiment_name="training",
        recorder_id="rec_20240115_120000_abc123",
        object_name="model"
    )
except FileNotFoundError:
    print("å¯¹è±¡ä¸å­˜åœ¨ï¼Œæ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®")
```

---

## ä¸Qlibçš„å¯¹æ¯”

| åŠŸèƒ½ | Qlib | QuantClassic |
|------|------|--------------|
| å…¨å±€æ¥å£ | `R` | `R` âœ… |
| ä¸Šä¸‹æ–‡ç®¡ç†å™¨ | `R.start()` | `R.start()` âœ… |
| å‚æ•°è®°å½• | `R.log_params()` | `R.log_params()` âœ… |
| æŒ‡æ ‡è®°å½• | `R.log_metrics()` | `R.log_metrics()` âœ… |
| å¯¹è±¡ä¿å­˜ | `R.save_objects()` | `R.save_objects()` âœ… |
| å®éªŒæœç´¢ | `R.search_recorders()` | `R.search_recorders()` âœ… |
| åç«¯å­˜å‚¨ | MLflow/Custom | File-based âœ… |

---

## æ€»ç»“

QuantClassic Workflowæä¾›äº†ä¸Qlibå…¼å®¹çš„å®éªŒç®¡ç†æ¥å£ï¼Œè®©ä½ å¯ä»¥:

1. ğŸ¯ **è½»æ¾è¿½è¸ª**: è‡ªåŠ¨è®°å½•æ‰€æœ‰å®éªŒå‚æ•°å’Œç»“æœ
2. ğŸ“Š **å¯¹æ¯”åˆ†æ**: æ–¹ä¾¿æ¯”è¾ƒä¸åŒæ¨¡å‹å’Œç­–ç•¥
3. ğŸ”„ **å¯å¤ç°**: å®Œæ•´ä¿å­˜å®éªŒçŠ¶æ€ï¼Œéšæ—¶å¯æ¢å¤
4. ğŸš€ **æé«˜æ•ˆç‡**: ä¸“æ³¨äºæ¨¡å‹å¼€å‘ï¼Œè€Œä¸æ˜¯æ—¥å¿—ç®¡ç†

å¼€å§‹ä½¿ç”¨å§ï¼ ğŸ‰
