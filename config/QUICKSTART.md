# QuantClassic Config - å¿«é€Ÿå¼€å§‹

## ğŸš€ 5åˆ†é’Ÿä¸Šæ‰‹

### 1. æŸ¥çœ‹å¯ç”¨æ¨¡æ¿

```bash
ls quantclassic/config/templates/
# lstm_basic.yaml  gru_basic.yaml
```

### 2. å¤åˆ¶å¹¶ä¿®æ”¹æ¨¡æ¿

```bash
cp quantclassic/config/templates/lstm_basic.yaml my_experiment.yaml
```

ç¼–è¾‘ `my_experiment.yaml`:
```yaml
task:
  model:
    class: LSTM
    module_path: quantclassic.model.pytorch_models
    kwargs:
      d_feat: 20
      hidden_size: 128  # ä¿®æ”¹è¿™é‡Œ
      num_layers: 2
      n_epochs: 50      # ä¿®æ”¹è¿™é‡Œ
```

### 3. è¿è¡Œå®éªŒ

```bash
# æ–¹å¼1: ä½¿ç”¨Pythonæ¨¡å—
cd quantclassic
python -m config.cli my_experiment.yaml

# æ–¹å¼2: ä½¿ç”¨Pythonä»£ç 
python << EOF
from config import ConfigLoader, TaskRunner

config = ConfigLoader.load('my_experiment.yaml')
runner = TaskRunner()
results = runner.run(config, experiment_name='my_exp')
print(f"å®Œæˆ! æ¨¡å‹: {type(results['model']).__name__}")
EOF
```

### 4. æŸ¥çœ‹ç»“æœ

```bash
# å®éªŒè‡ªåŠ¨è®°å½•åœ¨
ls output/experiments/my_exp_*/

# åŒ…å«:
# - meta.json         # å…ƒæ•°æ®
# - artifacts/        # ä¿å­˜çš„å¯¹è±¡ï¼ˆæ¨¡å‹ç­‰ï¼‰
```

---

## ğŸ“ å¸¸ç”¨é…ç½®

### ä¿®æ”¹æ•°æ®è·¯å¾„

```yaml
task:
  dataset:
    kwargs:
      config:
        base_dir: /path/to/your/data  # ä¿®æ”¹è¿™é‡Œ
```

### ä¿®æ”¹æ¨¡å‹å‚æ•°

```yaml
task:
  model:
    kwargs:
      hidden_size: 128    # éšè—å±‚å¤§å°
      num_layers: 3       # å±‚æ•°
      dropout: 0.5        # Dropout
      n_epochs: 200       # è®­ç»ƒè½®æ•°
      lr: 0.0001          # å­¦ä¹ ç‡
```

### ä¿®æ”¹è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ’åˆ†

```yaml
task:
  dataset:
    kwargs:
      config:
        train_ratio: 0.7  # 70% è®­ç»ƒ
        val_ratio: 0.15   # 15% éªŒè¯
        # å‰©ä½™15%è‡ªåŠ¨ç”¨äºæµ‹è¯•
```

---

## ğŸ¯ å®ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: å¿«é€Ÿæµ‹è¯•ï¼ˆå°‘é‡epochï¼‰

```yaml
experiment_name: quick_test

task:
  model:
    class: LSTM
    kwargs:
      d_feat: 20
      hidden_size: 64
      n_epochs: 5        # åªè®­ç»ƒ5ä¸ªepoch
      early_stop: 3
```

```bash
python -m config.cli quick_test.yaml
```

### ç¤ºä¾‹2: å¯¹æ¯”ä¸åŒhidden_size

åˆ›å»º3ä¸ªé…ç½®:

**h32.yaml**:
```yaml
experiment_name: lstm_h32
task:
  model:
    kwargs:
      hidden_size: 32
```

**h64.yaml**:
```yaml
experiment_name: lstm_h64
task:
  model:
    kwargs:
      hidden_size: 64
```

**h128.yaml**:
```yaml
experiment_name: lstm_h128
task:
  model:
    kwargs:
      hidden_size: 128
```

æ‰¹é‡è¿è¡Œ:
```bash
for config in h*.yaml; do
    python -m config.cli $config
done
```

æŸ¥çœ‹å¯¹æ¯”:
```python
from workflow import R

# æŸ¥çœ‹æ‰€æœ‰å®éªŒ
experiments = R.list_experiments()
for exp in experiments:
    if exp['name'].startswith('lstm_h'):
        recs = R.list_recorders(exp['name'])
        print(f"{exp['name']}: {len(recs)} runs")
```

### ç¤ºä¾‹3: ä½¿ç”¨é…ç½®ç»§æ‰¿

**base.yaml** (åŸºç¡€é…ç½®):
```yaml
task:
  dataset:
    class: DataManager
    kwargs:
      config:
        base_dir: rq_data_parquet
        window_size: 20
        train_ratio: 0.6
        val_ratio: 0.2
```

**experiment1.yaml** (ç»§æ‰¿base):
```yaml
BASE_CONFIG_PATH: "base.yaml"

experiment_name: exp1

task:
  model:
    class: LSTM
    kwargs:
      hidden_size: 64
```

**experiment2.yaml** (ç»§æ‰¿base):
```yaml
BASE_CONFIG_PATH: "base.yaml"

experiment_name: exp2

task:
  model:
    class: GRU
    kwargs:
      hidden_size: 64
```

---

## ğŸ”§ å‘½ä»¤è¡Œå¿«æ·æ–¹å¼

### åˆ›å»ºåˆ«å (å¯é€‰)

åœ¨ `~/.bashrc` æˆ– `~/.zshrc` ä¸­æ·»åŠ :

```bash
# æ·»åŠ åˆ°é…ç½®æ–‡ä»¶
echo 'alias qcrun="python -m quantclassic.config.cli"' >> ~/.bashrc
source ~/.bashrc

# ç°åœ¨å¯ä»¥ä½¿ç”¨
qcrun my_config.yaml
```

---

## ğŸ“Š ä¸æ‰‹å†™ä»£ç å¯¹æ¯”

### æ‰‹å†™ä»£ç  (âŒ ç¹ç)

```python
# éœ€è¦50-100è¡Œ
from quantclassic.data_manager import DataManager, DataConfig
from quantclassic.model import LSTM
from quantclassic.workflow import R

# é…ç½®æ•°æ®
data_config = DataConfig(
    base_dir='rq_data_parquet',
    window_size=20,
    train_ratio=0.6,
    val_ratio=0.2,
    batch_size=256,
    shuffle=True
)

# å‡†å¤‡æ•°æ®
manager = DataManager()
loaders = manager.run_full_pipeline(data_config)

# é…ç½®æ¨¡å‹
model = LSTM(
    d_feat=20,
    hidden_size=64,
    num_layers=2,
    dropout=0.3,
    n_epochs=100,
    lr=0.001,
    early_stop=10,
    batch_size=256
)

# è®­ç»ƒ
with R.start(experiment_name='manual_exp'):
    R.log_params(
        hidden_size=64,
        num_layers=2,
        # ... æ›´å¤šå‚æ•°
    )
    
    model.fit(loaders.train, loaders.val)
    
    R.log_metrics(**model.best_metrics)
    R.save_objects(model=model)
```

### ä½¿ç”¨Config (âœ… ç®€æ´)

**config.yaml**:
```yaml
task:
  model:
    class: LSTM
    kwargs:
      d_feat: 20
      hidden_size: 64
      num_layers: 2
      dropout: 0.3
      n_epochs: 100
      lr: 0.001
  
  dataset:
    class: DataManager
    kwargs:
      config:
        base_dir: rq_data_parquet
        window_size: 20
```

```bash
python -m config.cli config.yaml
```

---

## âš¡ æ•ˆç‡æå‡

| ä»»åŠ¡ | æ‰‹å†™ä»£ç  | ä½¿ç”¨Config | æå‡ |
|------|---------|-----------|------|
| **ä»£ç è¡Œæ•°** | 50-100è¡Œ | 10-20è¡Œ | **5å€** |
| **é…ç½®æ—¶é—´** | 5-10åˆ†é’Ÿ | 1-2åˆ†é’Ÿ | **5å€** |
| **å‡ºé”™æ¦‚ç‡** | é«˜ | ä½ | **10å€** |
| **å¤ç”¨æ€§** | ä½ | é«˜ | **å®Œç¾** |

---

## ğŸ“š ä¸‹ä¸€æ­¥

1. é˜…è¯» [å®Œæ•´æ–‡æ¡£](./README.md)
2. æŸ¥çœ‹ [é…ç½®æ¨¡æ¿](./templates/)
3. å­¦ä¹  [Workflowç³»ç»Ÿ](../workflow/README.md)
4. æ¢ç´¢ [é«˜çº§åŠŸèƒ½](./README.md#é«˜çº§åŠŸèƒ½)

---

**å¼€å§‹ä½ çš„ç¬¬ä¸€ä¸ªé…ç½®é©±åŠ¨å®éªŒå§ï¼** ğŸš€
---

## ğŸ†• è®­ç»ƒæ¶æ„ (2026-01 é‡æ„)

### æ¨èè®­ç»ƒå™¨

| è®­ç»ƒå™¨ | ç”¨é€” | é€‚ç”¨åœºæ™¯ |
|--------|------|----------|
| `SimpleTrainer` | å¸¸è§„å•çª—å£è®­ç»ƒ | å¸¸è§„è®­ç»ƒã€éªŒè¯ |
| `RollingWindowTrainer` | æ»šåŠ¨çª—å£è®­ç»ƒ | Walk-Forward éªŒè¯ |
| `RollingDailyTrainer` | æ—¥çº§æ»šåŠ¨è®­ç»ƒ | é«˜é¢‘æ¨¡å‹åˆ‡æ¢ã€åŠ¨æ€å›¾ |

### ç¤ºä¾‹: æ»šåŠ¨çª—å£è®­ç»ƒ

```yaml
experiment_name: rolling_training

task:
  # æ•°æ®é…ç½®
  dataset:
    class: DataManager
    kwargs:
      config:
        base_dir: rq_data_parquet
        split_strategy: rolling  # å¯ç”¨æ»šåŠ¨çª—å£
        rolling_window_days: 60
        rolling_test_days: 5
  
  # æ¨¡å‹é…ç½®
  model:
    class: HybridGraphModel
    kwargs:
      d_feat: 20
      hidden_size: 64
  
  # ğŸ†• è®­ç»ƒå™¨é…ç½®
  trainer_class: RollingDailyTrainer
  use_rolling_loaders: true
  trainer_kwargs:
    n_epochs: 20
    weight_inheritance: true   # ç»§æ‰¿ä¸Šä¸€çª—å£æƒé‡
    save_each_window: true     # ä¿å­˜æ¯ä¸ªçª—å£æ¨¡å‹
    gc_interval: 5             # æ˜¾å­˜æ¸…ç†é—´éš”
```

### ç¤ºä¾‹: åŠ¨æ€å›¾è®­ç»ƒ

```yaml
task:
  dataset:
    kwargs:
      config:
        graph_builder_config:
          type: hybrid
          alpha: 0.7
          top_k: 10
  
  trainer_class: SimpleTrainer  # æˆ– RollingDailyTrainer
  use_daily_loaders: true       # å¯ç”¨æ—¥æ‰¹æ¬¡åŠ è½½å™¨
  trainer_kwargs:
    loss_fn: ic_corr            # ICæŸå¤± + ç›¸å…³æ€§æ­£åˆ™
    lambda_corr: 0.01
```

### Python API ç¤ºä¾‹

```python
from quantclassic.model.train import RollingDailyTrainer, RollingTrainerConfig
from quantclassic.data_set import DataManager

# 1. å‡†å¤‡æ•°æ®
dm = DataManager(config=data_config)
dm.run_full_pipeline()
rolling_loaders = dm.create_rolling_daily_loaders()

# 2. å®šä¹‰æ¨¡å‹å·¥å‚
def model_factory():
    return MyModel(d_feat=len(dm.feature_cols))

# 3. åˆ›å»ºè®­ç»ƒå™¨å¹¶è®­ç»ƒ
config = RollingTrainerConfig(n_epochs=20, weight_inheritance=True)
trainer = RollingDailyTrainer(model_factory, config)
trainer.fit(rolling_loaders, save_dir='output/models')

# 4. è·å–é¢„æµ‹
predictions = trainer.get_all_predictions()
```

### âš ï¸ åºŸå¼ƒ API

ä»¥ä¸‹ API å·²åºŸå¼ƒï¼Œè¯·è¿ç§»åˆ°æ–°è®­ç»ƒæ¶æ„:

| åºŸå¼ƒ API | æ›¿ä»£æ–¹æ¡ˆ |
|----------|----------|
| `DataManager.create_rolling_window_trainer()` | `model.train.RollingWindowTrainer` |
| `model.rolling_daily_trainer.RollingDailyTrainer` | `model.train.RollingDailyTrainer` |
| `trainer_class='DynamicGraphTrainer'` | `trainer_class='SimpleTrainer'` |