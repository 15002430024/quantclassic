"""
BaseConfig - ç»Ÿä¸€é…ç½®åŸºç±»

æä¾›é¢å‘å¯¹è±¡çš„é…ç½®ç®¡ç†æ¡†æ¶ï¼Œæ›¿ä»£å­—å…¸é…ç½®
æ ¸å¿ƒåŠŸèƒ½ï¼š
- ç±»å‹æ£€æŸ¥å’ŒéªŒè¯
- åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼ˆYAML, JSON, Dictï¼‰
- é…ç½®ç»§æ‰¿å’Œåˆå¹¶
- é»˜è®¤å€¼ç®¡ç†
"""

from dataclasses import dataclass, field, fields, asdict
from typing import Dict, Any, Optional, Type, TypeVar, get_type_hints, Union
from pathlib import Path
import warnings
import yaml
import json
from abc import ABC


T = TypeVar('T', bound='BaseConfig')


@dataclass
class BaseConfig(ABC):
    """
    é…ç½®åŸºç±» - æ‰€æœ‰é…ç½®ç±»çš„åŸºç¡€
    
    ç‰¹æ€§ï¼š
    1. ä½¿ç”¨ dataclass æä¾›ç±»å‹æ£€æŸ¥å’Œé»˜è®¤å€¼
    2. æ”¯æŒ YAML/JSON åºåˆ—åŒ–
    3. æ”¯æŒé…ç½®éªŒè¯
    4. æ”¯æŒåµŒå¥—é…ç½®å¯¹è±¡
    
    Example:
        @dataclass
        class ModelConfig(BaseConfig):
            hidden_dim: int = 128
            learning_rate: float = 0.001
            
        config = ModelConfig()
        config.to_yaml('config.yaml')
        config2 = ModelConfig.from_yaml('config.yaml')
    """
    
    def validate(self) -> bool:
        """
        éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§
        
        å­ç±»å¯é‡å†™æ­¤æ–¹æ³•ä»¥å®ç°è‡ªå®šä¹‰éªŒè¯é€»è¾‘
        
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
            
        Raises:
            ValueError: é…ç½®æ— æ•ˆæ—¶
        """
        return True
    
    def to_dict(self) -> Dict[str, Any]:
        """
        è½¬æ¢ä¸ºå­—å…¸
        
        é€’å½’å¤„ç†åµŒå¥—çš„ BaseConfig å¯¹è±¡
        
        Returns:
            é…ç½®å­—å…¸
        """
        result = {}
        for f in fields(self):
            value = getattr(self, f.name)
            
            if isinstance(value, BaseConfig):
                # é€’å½’å¤„ç†åµŒå¥—é…ç½®
                result[f.name] = value.to_dict()
            elif isinstance(value, list):
                # å¤„ç†åˆ—è¡¨ä¸­çš„é…ç½®å¯¹è±¡
                result[f.name] = [
                    item.to_dict() if isinstance(item, BaseConfig) else item
                    for item in value
                ]
            elif isinstance(value, dict):
                # å¤„ç†å­—å…¸ä¸­çš„é…ç½®å¯¹è±¡
                result[f.name] = {
                    k: v.to_dict() if isinstance(v, BaseConfig) else v
                    for k, v in value.items()
                }
            else:
                result[f.name] = value
        
        return result
    
    @classmethod
    def from_dict(cls: Type[T], config_dict: Dict[str, Any]) -> T:
        """
        ä»å­—å…¸åˆ›å»ºé…ç½®å¯¹è±¡
        
        æ”¯æŒåµŒå¥—é…ç½®å¯¹è±¡çš„è‡ªåŠ¨å®ä¾‹åŒ–
        
        Args:
            config_dict: é…ç½®å­—å…¸
            
        Returns:
            é…ç½®å¯¹è±¡å®ä¾‹
        """
        # è·å–ç±»çš„ç±»å‹æ³¨è§£
        type_hints = get_type_hints(cls)
        
        # å‡†å¤‡åˆå§‹åŒ–å‚æ•°
        init_kwargs = {}
        
        for key, value in config_dict.items():
            if key not in type_hints:
                # è·³è¿‡æœªå®šä¹‰çš„å­—æ®µ
                continue
            
            field_type = type_hints[key]
            
            # æ£€æŸ¥æ˜¯å¦ä¸º BaseConfig å­ç±»
            if isinstance(field_type, type) and issubclass(field_type, BaseConfig):
                # é€’å½’åˆ›å»ºåµŒå¥—é…ç½®å¯¹è±¡
                if isinstance(value, dict):
                    init_kwargs[key] = field_type.from_dict(value)
                else:
                    init_kwargs[key] = value
            else:
                init_kwargs[key] = value
        
        # åˆ›å»ºå®ä¾‹
        instance = cls(**init_kwargs)
        
        # éªŒè¯é…ç½®
        instance.validate()
        
        return instance
    
    def to_yaml(self, yaml_path: str, **kwargs):
        """
        ä¿å­˜é…ç½®åˆ° YAML æ–‡ä»¶
        
        Args:
            yaml_path: YAML æ–‡ä»¶è·¯å¾„
            **kwargs: yaml.dump çš„é¢å¤–å‚æ•°
        """
        yaml_path = Path(yaml_path)
        yaml_path.parent.mkdir(parents=True, exist_ok=True)
        
        config_dict = self.to_dict()
        
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.safe_dump(
                config_dict, f,
                default_flow_style=False,
                allow_unicode=True,
                sort_keys=False,
                **kwargs
            )
    
    @classmethod
    def from_yaml(cls: Type[T], yaml_path: str) -> T:
        """
        ä» YAML æ–‡ä»¶åŠ è½½é…ç½®
        
        Args:
            yaml_path: YAML æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å¯¹è±¡å®ä¾‹
        """
        yaml_path = Path(yaml_path)
        
        if not yaml_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {yaml_path}")
        
        with open(yaml_path, 'r', encoding='utf-8') as f:
            config_dict = yaml.safe_load(f)
        
        return cls.from_dict(config_dict)
    
    def to_json(self, json_path: str, **kwargs):
        """
        ä¿å­˜é…ç½®åˆ° JSON æ–‡ä»¶
        
        Args:
            json_path: JSON æ–‡ä»¶è·¯å¾„
            **kwargs: json.dump çš„é¢å¤–å‚æ•°
        """
        json_path = Path(json_path)
        json_path.parent.mkdir(parents=True, exist_ok=True)
        
        config_dict = self.to_dict()
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False, **kwargs)
    
    @classmethod
    def from_json(cls: Type[T], json_path: str) -> T:
        """
        ä» JSON æ–‡ä»¶åŠ è½½é…ç½®
        
        Args:
            json_path: JSON æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å¯¹è±¡å®ä¾‹
        """
        json_path = Path(json_path)
        
        if not json_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        
        with open(json_path, 'r', encoding='utf-8') as f:
            config_dict = json.load(f)
        
        return cls.from_dict(config_dict)
    
    def update(self, **kwargs):
        """
        æ›´æ–°é…ç½®å‚æ•°
        
        Args:
            **kwargs: è¦æ›´æ–°çš„å‚æ•°
            
        Raises:
            ValueError: å‚æ•°ä¸å­˜åœ¨æ—¶
        """
        valid_fields = {f.name for f in fields(self)}
        
        for key, value in kwargs.items():
            if key not in valid_fields:
                raise ValueError(f"æœªçŸ¥é…ç½®é¡¹: {key}")
            setattr(self, key, value)
        
        # æ›´æ–°åé‡æ–°éªŒè¯
        self.validate()
    
    def merge(self: T, other: Union[T, Dict[str, Any]]) -> T:
        """
        åˆå¹¶å¦ä¸€ä¸ªé…ç½®å¯¹è±¡æˆ–å­—å…¸
        
        other çš„é None å€¼ä¼šè¦†ç›–å½“å‰é…ç½®
        
        Args:
            other: å¦ä¸€ä¸ªé…ç½®å¯¹è±¡æˆ–å­—å…¸
            
        Returns:
            åˆå¹¶åçš„æ–°é…ç½®å¯¹è±¡
        """
        # åˆ›å»ºå½“å‰é…ç½®çš„å‰¯æœ¬
        merged_dict = self.to_dict()
        
        if isinstance(other, dict):
            # åˆå¹¶å­—å…¸ä¸­çš„é None å€¼
            for key, value in other.items():
                if value is not None:
                    merged_dict[key] = value
        elif isinstance(other, self.__class__):
            # åˆå¹¶é…ç½®å¯¹è±¡çš„é None å€¼
            for f in fields(other):
                value = getattr(other, f.name)
                if value is not None:
                    merged_dict[f.name] = value
        else:
            raise TypeError(f"åªèƒ½åˆå¹¶ç›¸åŒç±»å‹çš„é…ç½®æˆ–å­—å…¸ï¼ŒæœŸæœ› {self.__class__} æˆ– dictï¼Œå¾—åˆ° {type(other)}")
        
        return self.__class__.from_dict(merged_dict)
    
    def copy(self: T) -> T:
        """
        åˆ›å»ºé…ç½®å¯¹è±¡çš„æ·±æ‹·è´
        
        Returns:
            é…ç½®å¯¹è±¡çš„å‰¯æœ¬
        """
        import copy as copy_module
        return copy_module.deepcopy(self)
    
    def __repr__(self) -> str:
        """å‹å¥½çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        lines = [f"{self.__class__.__name__}("]
        for f in fields(self):
            value = getattr(self, f.name)
            lines.append(f"  {f.name}={repr(value)},")
        lines.append(")")
        return "\n".join(lines)
    
    def __str__(self) -> str:
        """ç®€æ´çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        field_strs = [f"{f.name}={getattr(self, f.name)}" for f in fields(self)]
        return f"{self.__class__.__name__}({', '.join(field_strs)})"


@dataclass
class TaskConfig(BaseConfig):
    """
    ä»»åŠ¡é…ç½® - å®šä¹‰æ¨¡å‹å’Œæ•°æ®é›†
    
    è¿™æ˜¯ QuantClassic ä»»åŠ¡çš„é¡¶å±‚é…ç½®
    
    Args:
        model_class (str): æ¨¡å‹ç±»åï¼Œå¦‚ 'HybridGraphModel'
        model_kwargs (Dict): æ¨¡å‹åˆå§‹åŒ–å‚æ•°
        dataset_class (str): æ•°æ®é›†ç±»åï¼Œå¦‚ 'DataManager'
        dataset_kwargs (Dict): æ•°æ®é›†åˆå§‹åŒ–å‚æ•°
        trainer_class (str): è®­ç»ƒå™¨ç±»åï¼Œå¯é€‰å€¼:
            - '' (é»˜è®¤): ä½¿ç”¨æ¨¡å‹è‡ªå¸¦çš„ fit æ–¹æ³•
            - 'SimpleTrainer': ç®€å•è®­ç»ƒå™¨
            - 'RollingWindowTrainer': æ»šåŠ¨çª—å£è®­ç»ƒ
            - 'RollingDailyTrainer': æ—¥çº§æ»šåŠ¨çª—å£è®­ç»ƒ
        trainer_kwargs (Dict): è®­ç»ƒå™¨åˆå§‹åŒ–å‚æ•°
        use_rolling_loaders (bool): æ˜¯å¦ä½¿ç”¨æ»šåŠ¨çª—å£åŠ è½½å™¨
        backtest_enabled (bool): æ˜¯å¦å¯ç”¨å›æµ‹
        backtest_kwargs (Dict): å›æµ‹å‚æ•°
    """
    # æ¨¡å‹é…ç½®
    model_class: str = ""
    model_kwargs: Dict[str, Any] = field(default_factory=dict)
    
    # æ•°æ®é›†é…ç½®
    dataset_class: str = ""
    dataset_kwargs: Dict[str, Any] = field(default_factory=dict)
    
    # ğŸ†• è®­ç»ƒå™¨é…ç½® - æ”¯æŒæ–°è®­ç»ƒæ¶æ„
    trainer_class: str = ""  # '' ä½¿ç”¨é»˜è®¤, 'SimpleTrainer', 'RollingWindowTrainer', 'RollingDailyTrainer'
    trainer_kwargs: Dict[str, Any] = field(default_factory=dict)
    
    # ğŸ†• æ˜¯å¦ä½¿ç”¨æ»šåŠ¨çª—å£æ—¥æ‰¹æ¬¡åŠ è½½å™¨
    use_rolling_loaders: bool = False
    
    # ğŸ†• æ˜¯å¦ä½¿ç”¨æ—¥æ‰¹æ¬¡åŠ è½½å™¨ï¼ˆåŠ¨æ€å›¾æ¨¡å¼ï¼‰
    use_daily_loaders: bool = False
    
    # å›æµ‹é…ç½®ï¼ˆå¯é€‰ï¼‰
    backtest_enabled: bool = False
    backtest_kwargs: Dict[str, Any] = field(default_factory=dict)
    
    def validate(self) -> bool:
        """éªŒè¯ä»»åŠ¡é…ç½®"""
        if not self.model_class:
            raise ValueError("model_class ä¸èƒ½ä¸ºç©º")
        
        if not self.dataset_class:
            raise ValueError("dataset_class ä¸èƒ½ä¸ºç©º")
        
        # ğŸ†• æ›´æ–°æœ‰æ•ˆè®­ç»ƒå™¨åˆ—è¡¨
        valid_trainers = ['', 'SimpleTrainer', 'RollingWindowTrainer', 'RollingDailyTrainer']
        if self.trainer_class and self.trainer_class not in valid_trainers:
            raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒå™¨: {self.trainer_class}ï¼Œå¯é€‰: {valid_trainers}")
        
        return True


# ==================== ğŸ†• è®­ç»ƒå™¨é…ç½®ï¼ˆå·²ç»Ÿä¸€åˆ° model.train.base_trainerï¼‰====================
# ä¸ºä¿æŒå‘åå…¼å®¹ï¼Œæ­¤å¤„å®šä¹‰åˆ«åã€‚å®é™…ä½¿ç”¨è¯·ç›´æ¥å¼•ç”¨ model.train.TrainerConfig

@dataclass
class TrainerConfigDC(BaseConfig):
    """
    è®­ç»ƒå™¨é…ç½® (DataClassç‰ˆæœ¬) - å…¼å®¹å±‚
    
    âš ï¸ å»ºè®®ç›´æ¥ä½¿ç”¨ model.train.TrainerConfigï¼Œæ­¤ç±»ä½œä¸ºå…¼å®¹åˆ«åä¿ç•™ã€‚
    
    ç”¨äºé…ç½®æ–‡ä»¶ä¸­å®šä¹‰è®­ç»ƒå‚æ•°ï¼Œå¯åºåˆ—åŒ–åˆ° YAML/JSONã€‚
    å­—æ®µä¸ model.train.TrainerConfig ä¿æŒä¸€è‡´ã€‚
    
    Args:
        n_epochs: è®­ç»ƒè½®æ•°
        lr: å­¦ä¹ ç‡
        weight_decay: L2 æ­£åˆ™åŒ–ç³»æ•°
        early_stop: æ—©åœè€å¿ƒå€¼
        optimizer: ä¼˜åŒ–å™¨åç§° ('adam', 'sgd', 'adamw')
        loss_fn: æŸå¤±å‡½æ•°åç§° ('mse', 'mae', 'huber', 'ic', ç­‰)
        loss_kwargs: æŸå¤±å‡½æ•°é¢å¤–å‚æ•°
        use_scheduler: æ˜¯å¦ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler_type: è°ƒåº¦å™¨ç±»å‹ ('plateau', 'cosine', 'step')
        scheduler_patience: è°ƒåº¦å™¨è€å¿ƒå€¼
        scheduler_factor: å­¦ä¹ ç‡è¡°å‡å› å­
        scheduler_min_lr: æœ€å°å­¦ä¹ ç‡
        lambda_corr: ç›¸å…³æ€§æ­£åˆ™åŒ–æƒé‡
        checkpoint_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
        save_best_only: æ˜¯å¦åªä¿å­˜æœ€ä½³æ¨¡å‹
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
        log_interval: æ—¥å¿—æ‰“å°é—´éš”ï¼ˆbatchæ•°ï¼‰
    """
    # åŸºæœ¬è®­ç»ƒå‚æ•°
    n_epochs: int = 100
    lr: float = 0.001
    weight_decay: float = 0.0
    early_stop: int = 20
    
    # ä¼˜åŒ–å™¨é…ç½®
    optimizer: str = 'adam'
    
    # æŸå¤±å‡½æ•°é…ç½®
    loss_fn: str = 'mse'
    loss_kwargs: Dict[str, Any] = field(default_factory=dict)
    lambda_corr: float = 0.0
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½®
    use_scheduler: bool = True
    scheduler_type: str = 'plateau'
    scheduler_patience: int = 5
    scheduler_factor: float = 0.5
    scheduler_min_lr: float = 1e-6
    
    # æ£€æŸ¥ç‚¹é…ç½®
    checkpoint_dir: Optional[str] = None
    save_best_only: bool = True
    
    # æ—¥å¿—é…ç½®
    verbose: bool = True
    log_interval: int = 50  # ä¸ model.train.TrainerConfig å¯¹é½
    
    def __post_init__(self):
        """åˆå§‹åŒ–åè§¦å‘åºŸå¼ƒè­¦å‘Š"""
        warnings.warn(
            "TrainerConfigDC å·²åºŸå¼ƒï¼Œè¯·æ”¹ç”¨ model.train.TrainerConfigã€‚"
            "TrainerConfigDC å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­ç§»é™¤ã€‚\n"
            "è¿ç§»æ–¹å¼: from model.train import TrainerConfig",
            DeprecationWarning,
            stacklevel=2
        )
    
    def validate(self) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§ï¼ˆä¸ model.train.TrainerConfig.validate ä¿æŒä¸€è‡´ï¼‰"""
        if self.n_epochs <= 0:
            raise ValueError("n_epochs å¿…é¡»å¤§äº 0")
        if self.lr <= 0:
            raise ValueError("lr å¿…é¡»å¤§äº 0")
        if self.early_stop < 0:
            raise ValueError("early_stop ä¸èƒ½ä¸ºè´Ÿæ•°")
        if self.optimizer not in ['adam', 'sgd', 'adamw']:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨: {self.optimizer}")
        
        # æ‰©å±•æŸå¤±å‡½æ•°æ”¯æŒåˆ—è¡¨ï¼Œä¸ loss.get_loss_fn ä¿æŒä¸€è‡´
        supported_losses = [
            'mse', 'mae', 'huber', 'ic',  # æ ‡å‡†æŸå¤±
            'mse_corr', 'mae_corr', 'huber_corr', 'ic_corr',  # å¸¦ç›¸å…³æ€§æ­£åˆ™
            'combined', 'unified'  # ç»„åˆ/ç»Ÿä¸€æŸå¤±
        ]
        if self.loss_fn not in supported_losses:
            raise ValueError(
                f"ä¸æ”¯æŒçš„æŸå¤±å‡½æ•°: {self.loss_fn}. "
                f"æ”¯æŒçš„æŸå¤±: {', '.join(supported_losses)}"
            )
        return True
    
    def to_trainer_config(self):
        """
        è½¬æ¢ä¸º model.train.TrainerConfig å®ä¾‹
        
        ç”¨äºä¸è®­ç»ƒå¼•æ“å¯¹æ¥ã€‚
        
        Returns:
            model.train.TrainerConfig å®ä¾‹
        """
        try:
            from model.train import TrainerConfig
        except ImportError:
            from ..model.train import TrainerConfig
        return TrainerConfig(**self.to_dict())


@dataclass
class RollingTrainerConfigDC(TrainerConfigDC):
    """
    æ»šåŠ¨è®­ç»ƒå™¨é…ç½® (DataClassç‰ˆæœ¬) - å…¼å®¹å±‚
    
    âš ï¸ å»ºè®®ç›´æ¥ä½¿ç”¨ model.train.RollingTrainerConfigï¼Œæ­¤ç±»ä½œä¸ºå…¼å®¹åˆ«åä¿ç•™ã€‚
    
    ç»§æ‰¿ TrainerConfigDCï¼Œå¢åŠ æ»šåŠ¨çª—å£ç‰¹æœ‰å‚æ•°ã€‚
    """
    weight_inheritance: bool = True
    save_each_window: bool = True
    reset_optimizer: bool = True
    reset_scheduler: bool = True
    window_epochs: Optional[int] = None
    gc_interval: int = 1
    offload_to_cpu: bool = True
    clear_cache_on_window_end: bool = True
    
    def __post_init__(self):
        """åˆå§‹åŒ–åè§¦å‘åºŸå¼ƒè­¦å‘Š"""
        warnings.warn(
            "RollingTrainerConfigDC å·²åºŸå¼ƒï¼Œè¯·æ”¹ç”¨ model.train.RollingTrainerConfigã€‚"
            "RollingTrainerConfigDC å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­ç§»é™¤ã€‚\n"
            "è¿ç§»æ–¹å¼: from model.train import RollingTrainerConfig",
            DeprecationWarning,
            stacklevel=2
        )
    
    def to_rolling_trainer_config(self):
        """
        è½¬æ¢ä¸º model.train.RollingTrainerConfig å®ä¾‹
        
        ç”¨äºä¸æ»šåŠ¨è®­ç»ƒå¼•æ“å¯¹æ¥ã€‚
        æ³¨æ„ï¼šgc_interval, offload_to_cpu, clear_cache_on_window_end å­—æ®µ
        ä¸ä¼šè¢«ä¼ é€’ï¼Œå› ä¸º RollingTrainerConfig ä¸åŒ…å«è¿™äº›å­—æ®µã€‚
        
        Returns:
            model.train.RollingTrainerConfig å®ä¾‹
        """
        try:
            from model.train import RollingTrainerConfig
        except ImportError:
            from ..model.train import RollingTrainerConfig
        
        # åªä¼ é€’ RollingTrainerConfig æ”¯æŒçš„å­—æ®µ
        config_dict = self.to_dict()
        # ç§»é™¤ RollingTrainerConfig ä¸æ”¯æŒçš„å­—æ®µ
        extra_fields = ['gc_interval', 'offload_to_cpu', 'clear_cache_on_window_end']
        for field_name in extra_fields:
            config_dict.pop(field_name, None)
        
        return RollingTrainerConfig(**config_dict)


if __name__ == '__main__':
    # æµ‹è¯• BaseConfig
    print("=" * 80)
    print("BaseConfig æµ‹è¯•")
    print("=" * 80)
    
    # å®šä¹‰æµ‹è¯•é…ç½®ç±»
    @dataclass
    class TestModelConfig(BaseConfig):
        hidden_dim: int = 128
        learning_rate: float = 0.001
        dropout: float = 0.3
        
        def validate(self) -> bool:
            if self.hidden_dim <= 0:
                raise ValueError("hidden_dim å¿…é¡»å¤§äº 0")
            if not 0 <= self.dropout <= 1:
                raise ValueError("dropout å¿…é¡»åœ¨ [0, 1] èŒƒå›´å†…")
            return True
    
    @dataclass
    class TestDataConfig(BaseConfig):
        batch_size: int = 256
        window_size: int = 40
    
    @dataclass
    class TestTaskConfig(BaseConfig):
        name: str = "test_task"
        model: TestModelConfig = field(default_factory=TestModelConfig)
        data: TestDataConfig = field(default_factory=TestDataConfig)
    
    # æµ‹è¯• 1: åˆ›å»ºé…ç½®
    print("\n1. åˆ›å»ºé…ç½®å¯¹è±¡:")
    config = TestTaskConfig()
    print(f"  {config.name}")
    print(f"  æ¨¡å‹: hidden_dim={config.model.hidden_dim}")
    print(f"  æ•°æ®: batch_size={config.data.batch_size}")
    
    # æµ‹è¯• 2: è½¬æ¢ä¸ºå­—å…¸
    print("\n2. è½¬æ¢ä¸ºå­—å…¸:")
    config_dict = config.to_dict()
    print(f"  keys: {list(config_dict.keys())}")
    print(f"  model.hidden_dim: {config_dict['model']['hidden_dim']}")
    
    # æµ‹è¯• 3: ä»å­—å…¸åˆ›å»º
    print("\n3. ä»å­—å…¸åˆ›å»º:")
    config2 = TestTaskConfig.from_dict(config_dict)
    print(f"  name: {config2.name}")
    print(f"  model.learning_rate: {config2.model.learning_rate}")
    
    # æµ‹è¯• 4: ä¿å­˜å’ŒåŠ è½½ YAML
    print("\n4. YAML åºåˆ—åŒ–:")
    yaml_path = '/tmp/test_config.yaml'
    config.to_yaml(yaml_path)
    print(f"  å·²ä¿å­˜åˆ°: {yaml_path}")
    
    config3 = TestTaskConfig.from_yaml(yaml_path)
    print(f"  å·²åŠ è½½: {config3.name}")
    
    # æµ‹è¯• 5: æ›´æ–°é…ç½®
    print("\n5. æ›´æ–°é…ç½®:")
    config.update(name='updated_task')
    print(f"  æ–°åç§°: {config.name}")
    
    # æµ‹è¯• 6: åˆå¹¶é…ç½®
    print("\n6. åˆå¹¶é…ç½®:")
    other_config = TestTaskConfig(name='merged_task')
    merged = config.merge(other_config)
    print(f"  åˆå¹¶ååç§°: {merged.name}")
    
    # æµ‹è¯• 7: éªŒè¯
    print("\n7. é…ç½®éªŒè¯:")
    try:
        invalid_config = TestModelConfig(hidden_dim=-10)
    except ValueError as e:
        print(f"  âœ… æ•è·åˆ°éªŒè¯é”™è¯¯: {e}")
    
    print("\n" + "=" * 80)
    print("âœ… BaseConfig æµ‹è¯•å®Œæˆ")
    print("=" * 80)
