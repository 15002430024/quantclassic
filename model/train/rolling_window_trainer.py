"""
RollingWindowTrainer - æ»šåŠ¨çª—å£è®­ç»ƒå™¨

å®ç° Walk-Forward éªŒè¯ç­–ç•¥çš„æ»šåŠ¨çª—å£è®­ç»ƒã€‚
æ”¯æŒæƒé‡ç»§æ‰¿æ¨¡å¼å’Œç‹¬ç«‹è®­ç»ƒæ¨¡å¼ã€‚
"""

import copy
import time
import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import (
    Any, Callable, Dict, List, Optional, Tuple, Union
)

import torch
import torch.nn as nn
import numpy as np
import pandas as pd

from .base_trainer import BaseTrainer, TrainerConfig, TrainerCallback
from .simple_trainer import SimpleTrainer


@dataclass
class RollingTrainerConfig(TrainerConfig):
    """
    æ»šåŠ¨çª—å£è®­ç»ƒå™¨é…ç½®
    
    ç»§æ‰¿è‡ª TrainerConfigï¼Œå¢åŠ æ»šåŠ¨çª—å£ç‰¹æœ‰çš„é…ç½®é¡¹ã€‚
    
    Args:
        weight_inheritance: æ˜¯å¦ç»§æ‰¿ä¸Šä¸€çª—å£çš„æ¨¡å‹æƒé‡
        save_each_window: æ˜¯å¦ä¿å­˜æ¯ä¸ªçª—å£çš„æ¨¡å‹
        reset_optimizer: æ¯ä¸ªçª—å£æ˜¯å¦é‡ç½®ä¼˜åŒ–å™¨
        reset_scheduler: æ¯ä¸ªçª—å£æ˜¯å¦é‡ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨
        window_epochs: æ¯ä¸ªçª—å£çš„è®­ç»ƒè½®æ•°ï¼ˆè¦†ç›– n_epochsï¼‰
    """
    # æ»šåŠ¨çª—å£ç‰¹æœ‰é…ç½®
    weight_inheritance: bool = True
    save_each_window: bool = True
    reset_optimizer: bool = True
    reset_scheduler: bool = True
    window_epochs: Optional[int] = None  # None è¡¨ç¤ºä½¿ç”¨ n_epochs
    
    def validate(self) -> bool:
        """éªŒè¯é…ç½®"""
        super().validate()
        return True


# ==================== æ•°æ®ç»“æ„å®šä¹‰ ====================

@dataclass
class WindowData:
    """
    å•ä¸ªæ»šåŠ¨çª—å£çš„æ•°æ®
    
    Args:
        window_id: çª—å£æ ‡è¯†ï¼ˆç´¢å¼•æˆ–æ—¥æœŸï¼‰
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨ï¼ˆå¯é€‰ï¼‰
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆå¯é€‰ï¼‰
        metadata: çª—å£å…ƒæ•°æ®ï¼ˆå¦‚æ—¥æœŸèŒƒå›´ç­‰ï¼‰
    """
    window_id: Union[int, str]
    train_loader: Any
    val_loader: Optional[Any] = None
    test_loader: Optional[Any] = None
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class WindowResult:
    """
    å•ä¸ªçª—å£çš„è®­ç»ƒç»“æœ
    
    Args:
        window_id: çª—å£æ ‡è¯†
        best_epoch: æœ€ä½³ epoch
        best_val_loss: æœ€ä½³éªŒè¯æŸå¤±
        train_losses: è®­ç»ƒæŸå¤±å†å²
        val_losses: éªŒè¯æŸå¤±å†å²
        predictions: é¢„æµ‹ç»“æœï¼ˆå¯é€‰ï¼‰
        save_path: æ¨¡å‹ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        elapsed_time: è®­ç»ƒè€—æ—¶
        skipped: æ˜¯å¦è·³è¿‡è®­ç»ƒï¼ˆä½¿ç”¨å·²æœ‰æ¨¡å‹ï¼‰
    """
    window_id: Union[int, str]
    best_epoch: int = 0
    best_val_loss: float = 0.0
    train_losses: List[float] = field(default_factory=list)
    val_losses: List[float] = field(default_factory=list)
    predictions: Optional[pd.DataFrame] = None
    save_path: Optional[str] = None
    elapsed_time: float = 0.0
    skipped: bool = False


# ==================== æ»šåŠ¨çª—å£è®­ç»ƒå™¨ ====================

class RollingWindowTrainer:
    """
    æ»šåŠ¨çª—å£è®­ç»ƒå™¨
    
    å®ç° Walk-Forward éªŒè¯ç­–ç•¥ï¼š
    1. éå†æ¯ä¸ªæ»šåŠ¨çª—å£
    2. åœ¨å½“å‰çª—å£çš„è®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹
    3. åœ¨å½“å‰çª—å£çš„æµ‹è¯•é›†ä¸Šé¢„æµ‹
    4. ï¼ˆå¯é€‰ï¼‰å°†æ¨¡å‹æƒé‡ä¼ é€’ç»™ä¸‹ä¸€çª—å£
    5. åˆå¹¶æ‰€æœ‰çª—å£çš„é¢„æµ‹ç»“æœ
    
    Features:
    - æ”¯æŒå®Œå…¨ç‹¬ç«‹çš„æ»šåŠ¨çª—å£è®­ç»ƒ
    - æ”¯æŒå¢é‡è®­ç»ƒï¼ˆä½¿ç”¨å‰ä¸€çª—å£æ¨¡å‹åˆå§‹åŒ–ï¼‰
    - è‡ªåŠ¨ç®¡ç†æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
    - æ”¯æŒæ–­ç‚¹ç»­è®­
    
    Example:
        >>> from quantclassic.model.train import RollingWindowTrainer, RollingTrainerConfig
        >>> 
        >>> config = RollingTrainerConfig(
        ...     n_epochs=20,
        ...     weight_inheritance=True,
        ...     save_each_window=True
        ... )
        >>> 
        >>> trainer = RollingWindowTrainer(
        ...     model_factory=lambda: MyModel(d_feat=20),
        ...     config=config,
        ...     device='cuda'
        ... )
        >>> 
        >>> results = trainer.train(rolling_loaders, save_dir='output/models')
        >>> all_predictions = trainer.get_all_predictions()
    """
    
    def __init__(
        self,
        model_factory: Callable[[], nn.Module],
        config: Optional[RollingTrainerConfig] = None,
        device: Optional[str] = None,
        **kwargs
    ):
        """
        åˆå§‹åŒ–æ»šåŠ¨çª—å£è®­ç»ƒå™¨
        
        Args:
            model_factory: æ¨¡å‹å·¥å‚å‡½æ•°ï¼Œæ¯æ¬¡è°ƒç”¨è¿”å›ä¸€ä¸ªæ–°çš„ nn.Module å®ä¾‹
            config: æ»šåŠ¨è®­ç»ƒé…ç½®
            device: è®¡ç®—è®¾å¤‡
            **kwargs: é¢å¤–é…ç½®å‚æ•°
        """
        self.model_factory = model_factory
        self.config = config or RollingTrainerConfig(**kwargs)
        self.device = torch.device(
            device if device else ('cuda' if torch.cuda.is_available() else 'cpu')
        )
        
        # æ—¥å¿—
        self.logger = self._setup_logger()
        
        # è®­ç»ƒçŠ¶æ€
        self.window_results: List[WindowResult] = []
        self.all_predictions: List[pd.DataFrame] = []
        self.current_model_state: Optional[Dict] = None
        self.current_model: Optional[nn.Module] = None
        self.current_optimizer_state: Optional[Dict] = None  # ğŸ†• ä¼˜åŒ–å™¨çŠ¶æ€
        self.current_scheduler_state: Optional[Dict] = None  # ğŸ†• è°ƒåº¦å™¨çŠ¶æ€
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸ”„ åˆå§‹åŒ–æ»šåŠ¨çª—å£è®­ç»ƒå™¨")
        self.logger.info("=" * 80)
        self.logger.info(f"  è®¾å¤‡: {self.device}")
        self.logger.info(f"  è®­ç»ƒç­–ç•¥: {'ç»§æ‰¿æƒé‡ (Warm Start)' if self.config.weight_inheritance else 'ç‹¬ç«‹è®­ç»ƒ'}")
        self.logger.info(f"  æ¯çª—å£ä¿å­˜: {'æ˜¯' if self.config.save_each_window else 'å¦'}")
        self.logger.info(f"  ä¼˜åŒ–å™¨å¤ç”¨: {'å¦' if self.config.reset_optimizer else 'æ˜¯'}")
        self.logger.info(f"  è°ƒåº¦å™¨å¤ç”¨: {'å¦' if self.config.reset_scheduler else 'æ˜¯'}")
    
    def _setup_logger(self) -> logging.Logger:
        """é…ç½®æ—¥å¿—"""
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _get_model_for_window(self, window_idx: int) -> nn.Module:
        """
        è·å–å½“å‰çª—å£çš„æ¨¡å‹
        
        Args:
            window_idx: çª—å£ç´¢å¼•
            
        Returns:
            PyTorch æ¨¡å‹
        """
        if self.config.weight_inheritance and self.current_model_state is not None and window_idx > 0:
            # ç»§æ‰¿ä¸Šä¸€çª—å£çš„æƒé‡
            model = self.model_factory()
            model.to(self.device)
            try:
                model.load_state_dict(self.current_model_state)
                self.logger.info(f"  ğŸ”— ç»§æ‰¿çª—å£ {window_idx} çš„æ¨¡å‹æƒé‡")
            except Exception as e:
                self.logger.warning(f"  âš ï¸ æ— æ³•åŠ è½½å‰ä¸€çª—å£æƒé‡: {e}")
        else:
            # ä½¿ç”¨å…¨æ–°æ¨¡å‹
            model = self.model_factory()
            model.to(self.device)
            self.logger.info(f"  ğŸ†• ä½¿ç”¨å…¨æ–°æ¨¡å‹æƒé‡")
        
        return model
    
    def _check_existing_model(self, save_path: str) -> Optional[Dict]:
        """
        æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²è®­ç»ƒçš„æ¨¡å‹
        
        Args:
            save_path: æ¨¡å‹ä¿å­˜è·¯å¾„
            
        Returns:
            å¦‚æœå­˜åœ¨ï¼Œè¿”å›æ£€æŸ¥ç‚¹å­—å…¸ï¼›å¦åˆ™è¿”å› None
        """
        if save_path and Path(save_path).exists():
            try:
                checkpoint = torch.load(save_path, map_location=self.device)
                self.logger.info(f"  âœ“ å‘ç°å·²è®­ç»ƒæ¨¡å‹: {save_path}")
                return checkpoint
            except Exception as e:
                self.logger.warning(f"  âš ï¸ åŠ è½½å·²å­˜åœ¨æ¨¡å‹å¤±è´¥: {e}")
        return None
    
    def train(
        self,
        rolling_loaders,
        n_epochs: Optional[int] = None,
        save_dir: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è®­ç»ƒæ‰€æœ‰æ»šåŠ¨çª—å£
        
        Args:
            rolling_loaders: æ»šåŠ¨çª—å£æ•°æ®åŠ è½½å™¨é›†åˆ
                - å¯è¿­ä»£å¯¹è±¡ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« train/val/test loader
                - å¦‚ RollingDailyLoaderCollection
            n_epochs: æ¯ä¸ªçª—å£çš„è®­ç»ƒè½®æ•°ï¼ˆè¦†ç›–é…ç½®ï¼‰
            save_dir: æ¨¡å‹ä¿å­˜ç›®å½•
            
        Returns:
            è®­ç»ƒç»“æœæ±‡æ€»å­—å…¸
        """
        n_epochs = n_epochs or self.config.window_epochs or self.config.n_epochs
        n_windows = len(rolling_loaders)
        
        self.logger.info("\n" + "=" * 80)
        self.logger.info("ğŸš€ å¼€å§‹æ»šåŠ¨çª—å£è®­ç»ƒ (Walk-Forward)")
        self.logger.info("=" * 80)
        self.logger.info(f"  æ€»çª—å£æ•°: {n_windows}")
        self.logger.info(f"  æ¯çª—å£è½®æ•°: {n_epochs}")
        
        if save_dir:
            save_dir = Path(save_dir)
            save_dir.mkdir(parents=True, exist_ok=True)
            self.logger.info(f"  ä¿å­˜ç›®å½•: {save_dir}")
        
        start_time = time.time()
        self.window_results = []
        self.all_predictions = []
        
        for window_idx, loaders in enumerate(rolling_loaders):
            self.logger.info("\n" + "-" * 60)
            self.logger.info(f"ğŸ“… çª—å£ {window_idx + 1}/{n_windows}")
            self.logger.info("-" * 60)
            
            # è§£æ loaders
            train_loader = loaders.train if hasattr(loaders, 'train') else loaders[0]
            val_loader = loaders.val if hasattr(loaders, 'val') else (loaders[1] if len(loaders) > 1 else None)
            test_loader = loaders.test if hasattr(loaders, 'test') else (loaders[2] if len(loaders) > 2 else None)
            
            # æ£€æŸ¥è®­ç»ƒé›†æ˜¯å¦ä¸ºç©º
            if train_loader is None or len(train_loader) == 0:
                self.logger.warning(f"  âš ï¸ çª—å£ {window_idx + 1} è®­ç»ƒé›†ä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            # ç¡®å®šä¿å­˜è·¯å¾„
            save_path = None
            if save_dir and self.config.save_each_window:
                save_path = str(save_dir / f"window_{window_idx + 1}.pth")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²è®­ç»ƒæ¨¡å‹ï¼ˆæ–­ç‚¹ç»­è®­ï¼‰
            existing_checkpoint = self._check_existing_model(save_path)
            
            if existing_checkpoint:
                # ä½¿ç”¨å·²æœ‰æ¨¡å‹ï¼Œè·³è¿‡è®­ç»ƒ
                model = self.model_factory()
                model.to(self.device)
                model.load_state_dict(existing_checkpoint['model_state_dict'])
                
                window_result = WindowResult(
                    window_id=window_idx + 1,
                    best_epoch=existing_checkpoint.get('best_epoch', 0),
                    best_val_loss=existing_checkpoint.get('best_score', 0.0),
                    save_path=save_path,
                    skipped=True
                )
            else:
                # è®­ç»ƒæ–°æ¨¡å‹
                window_start = time.time()
                
                # è·å–æ¨¡å‹
                model = self._get_model_for_window(window_idx)
                
                # åˆ›å»ºçª—å£è®­ç»ƒå™¨
                window_trainer = SimpleTrainer(model, self.config, str(self.device))
                
                # ğŸ†• å¤ç”¨ä¼˜åŒ–å™¨/è°ƒåº¦å™¨çŠ¶æ€ï¼ˆå¦‚æœé…ç½®äº†ä¸é‡ç½®ä¸”éé¦–çª—å£ï¼‰
                if not self.config.reset_optimizer and window_idx > 0 and self.current_optimizer_state:
                    try:
                        window_trainer._create_optimizer()  # å…ˆåˆ›å»ºä¼˜åŒ–å™¨
                        window_trainer.optimizer.load_state_dict(self.current_optimizer_state)
                        self.logger.info("  ğŸ”— å¤ç”¨ä¸Šä¸€çª—å£çš„ä¼˜åŒ–å™¨çŠ¶æ€")
                    except Exception as e:
                        self.logger.warning(f"  âš ï¸ æ— æ³•åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€: {e}")
                
                if not self.config.reset_scheduler and window_idx > 0 and self.current_scheduler_state:
                    try:
                        if window_trainer.scheduler is None:
                            window_trainer._create_scheduler()  # å…ˆåˆ›å»ºè°ƒåº¦å™¨
                        window_trainer.scheduler.load_state_dict(self.current_scheduler_state)
                        self.logger.info("  ğŸ”— å¤ç”¨ä¸Šä¸€çª—å£çš„è°ƒåº¦å™¨çŠ¶æ€")
                    except Exception as e:
                        self.logger.warning(f"  âš ï¸ æ— æ³•åŠ è½½è°ƒåº¦å™¨çŠ¶æ€: {e}")
                
                # æ—¥å¿—
                self.logger.info(f"  è®­ç»ƒé›†: {len(train_loader)} batches")
                if val_loader:
                    self.logger.info(f"  éªŒè¯é›†: {len(val_loader)} batches")
                
                # è®­ç»ƒ
                train_result = window_trainer.train(
                    train_loader=train_loader,
                    val_loader=val_loader,
                    n_epochs=n_epochs,
                    save_path=save_path
                )
                
                window_elapsed = time.time() - window_start
                
                window_result = WindowResult(
                    window_id=window_idx + 1,
                    best_epoch=train_result['best_epoch'],
                    best_val_loss=train_result['best_score'],
                    train_losses=train_result['train_losses'],
                    val_losses=train_result['valid_losses'],
                    save_path=save_path,
                    elapsed_time=window_elapsed,
                    skipped=False
                )
                
                # æ›´æ–°å½“å‰æ¨¡å‹
                model = window_trainer.get_model()
            
            # ä¿å­˜æ¨¡å‹çŠ¶æ€ï¼ˆç”¨äºä¸‹ä¸€çª—å£ç»§æ‰¿ï¼‰
            if self.config.weight_inheritance:
                self.current_model_state = copy.deepcopy(model.state_dict())
            self.current_model = model
            
            # ğŸ†• ä¿å­˜ä¼˜åŒ–å™¨/è°ƒåº¦å™¨çŠ¶æ€ï¼ˆç”¨äºä¸‹ä¸€çª—å£å¤ç”¨ï¼‰
            if not window_result.skipped:  # åªæœ‰è®­ç»ƒè¿‡çš„çª—å£æ‰ä¿å­˜
                if not self.config.reset_optimizer and window_trainer.optimizer:
                    self.current_optimizer_state = copy.deepcopy(window_trainer.optimizer.state_dict())
                if not self.config.reset_scheduler and window_trainer.scheduler:
                    self.current_scheduler_state = copy.deepcopy(window_trainer.scheduler.state_dict())
            
            # åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹
            if test_loader and len(test_loader) > 0:
                self.logger.info(f"  æµ‹è¯•é›†: {len(test_loader)} batches")
                predictions = self._predict_window(model, test_loader, window_idx)
                if predictions is not None:
                    window_result.predictions = predictions
                    self.all_predictions.append(predictions)
                    self.logger.info(f"  é¢„æµ‹æ ·æœ¬: {len(predictions):,}")
            
            self.window_results.append(window_result)
            
            self.logger.info(
                f"âœ… çª—å£ {window_idx + 1} å®Œæˆ | "
                f"best_epoch={window_result.best_epoch + 1} | "
                f"best_val_loss={window_result.best_val_loss:.6f}"
            )
        
        # æ±‡æ€»ç»Ÿè®¡
        elapsed = time.time() - start_time
        summary = self._build_summary(elapsed)
        
        self._print_summary(summary)
        
        return summary
    
    def _predict_window(
        self,
        model: nn.Module,
        test_loader,
        window_idx: int
    ) -> Optional[pd.DataFrame]:
        """
        åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            window_idx: çª—å£ç´¢å¼•
            
        Returns:
            é¢„æµ‹ç»“æœ DataFrame
        """
        model.eval()
        predictions = []
        
        with torch.no_grad():
            for batch_data in test_loader:
                # è§£æ batch
                if isinstance(batch_data, (list, tuple)):
                    if len(batch_data) >= 5:
                        # DailyGraphDataLoader æ ¼å¼
                        x, y, adj, stock_ids, dates = batch_data[:5]
                    elif len(batch_data) >= 2:
                        x, y = batch_data[0], batch_data[1]
                        adj = batch_data[2] if len(batch_data) > 2 else None
                        stock_ids = batch_data[3] if len(batch_data) > 3 else None
                        dates = None
                    else:
                        continue
                else:
                    x = batch_data.get('x') or batch_data.get('features')
                    y = batch_data.get('y') or batch_data.get('labels')
                    adj = batch_data.get('adj')
                    stock_ids = batch_data.get('stock_ids')
                    dates = batch_data.get('dates')
                
                x = x.to(self.device)
                if adj is not None:
                    adj = adj.to(self.device)
                
                # å‰å‘ä¼ æ’­
                try:
                    pred = model(x, adj=adj) if adj is not None else model(x)
                except TypeError:
                    pred = model(x)
                
                if isinstance(pred, tuple):
                    pred = pred[0]
                
                pred = pred.cpu().numpy()
                
                # æ„å»ºé¢„æµ‹è®°å½•
                for i in range(len(pred)):
                    record = {
                        'pred': pred[i] if pred.ndim == 1 else pred[i].item(),
                        'window_idx': window_idx + 1
                    }
                    if y is not None:
                        y_np = y.cpu().numpy() if torch.is_tensor(y) else y
                        record['y_true'] = y_np[i] if y_np.ndim == 1 else y_np[i].item()
                    if stock_ids is not None:
                        record['order_book_id'] = stock_ids[i] if isinstance(stock_ids, list) else stock_ids[i].item()
                    if dates is not None:
                        record['trade_date'] = dates if isinstance(dates, str) else str(dates)
                    
                    predictions.append(record)
        
        if predictions:
            return pd.DataFrame(predictions)
        return None
    
    def _build_summary(self, elapsed: float) -> Dict[str, Any]:
        """æ„å»ºè®­ç»ƒæ±‡æ€»"""
        train_losses = [
            r.train_losses[-1] for r in self.window_results
            if r.train_losses and not r.skipped
        ]
        val_losses = [
            r.best_val_loss for r in self.window_results
            if r.best_val_loss > 0
        ]
        best_epochs = [r.best_epoch for r in self.window_results]
        
        total_preds = sum(
            len(df) for df in self.all_predictions
        ) if self.all_predictions else 0
        
        return {
            'n_windows': len(self.window_results),
            'elapsed_time': elapsed,
            'avg_train_loss': float(np.mean(train_losses)) if train_losses else 0.0,
            'avg_val_loss': float(np.mean(val_losses)) if val_losses else 0.0,
            'avg_best_epoch': float(np.mean(best_epochs)) if best_epochs else 0.0,
            'total_predictions': total_preds,
            'window_results': self.window_results
        }
    
    def _print_summary(self, summary: Dict[str, Any]):
        """æ‰“å°è®­ç»ƒæ±‡æ€»"""
        self.logger.info("\n" + "=" * 80)
        self.logger.info("ğŸ“Š æ»šåŠ¨çª—å£è®­ç»ƒæ±‡æ€»")
        self.logger.info("=" * 80)
        self.logger.info(f"  æ€»çª—å£: {summary['n_windows']}")
        self.logger.info(f"  æ€»è€—æ—¶: {summary['elapsed_time']:.1f}s ({summary['elapsed_time']/60:.1f} min)")
        self.logger.info(f"  å¹³å‡è®­ç»ƒæŸå¤±: {summary['avg_train_loss']:.6f}")
        self.logger.info(f"  å¹³å‡éªŒè¯æŸå¤±: {summary['avg_val_loss']:.6f}")
        self.logger.info(f"  å¹³å‡æœ€ä½³è½®æ•°: {summary['avg_best_epoch']:.1f}")
        self.logger.info(f"  æ€»é¢„æµ‹æ ·æœ¬: {summary['total_predictions']:,}")
    
    def get_all_predictions(self) -> pd.DataFrame:
        """
        è·å–æ‰€æœ‰çª—å£çš„åˆå¹¶é¢„æµ‹ç»“æœ
        
        Returns:
            åˆå¹¶çš„ DataFrameï¼ŒåŒ…å«åˆ—:
            - trade_date: äº¤æ˜“æ—¥æœŸï¼ˆå¦‚æœæœ‰ï¼‰
            - order_book_id: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰
            - pred: é¢„æµ‹å€¼
            - y_true: çœŸå®æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ï¼‰
            - window_idx: çª—å£ç´¢å¼•
        """
        if not self.all_predictions:
            return pd.DataFrame()
        
        combined = pd.concat(self.all_predictions, ignore_index=True)
        
        # å»é‡ï¼šå¦‚æœæœ‰é‡å ï¼Œä¿ç•™æœ€åä¸€ä¸ªçª—å£çš„é¢„æµ‹
        if 'trade_date' in combined.columns and 'order_book_id' in combined.columns:
            combined = combined.sort_values(['trade_date', 'order_book_id', 'window_idx'])
            combined = combined.drop_duplicates(
                subset=['trade_date', 'order_book_id'],
                keep='last'
            )
        
        return combined.reset_index(drop=True)
    
    def get_window_predictions(self, window_idx: int) -> Optional[pd.DataFrame]:
        """è·å–æŒ‡å®šçª—å£çš„é¢„æµ‹ç»“æœ"""
        for result in self.window_results:
            if result.window_id == window_idx + 1:
                return result.predictions
        return None
    
    def get_current_model(self) -> Optional[nn.Module]:
        """è·å–å½“å‰ï¼ˆæœ€åä¸€ä¸ªçª—å£ï¼‰çš„æ¨¡å‹"""
        return self.current_model
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒæ±‡æ€»ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        if not self.window_results:
            return {}
        return self._build_summary(0)
