"""
Model Factory - æ¨¡å‹å·¥å‚

æä¾›æ¨¡å‹æ³¨å†Œå’ŒåŠ¨æ€åˆ›å»ºæœºåˆ¶ï¼Œç±»ä¼¼ Qlib çš„ init_instance_by_config
"""

from typing import Dict, Type, Any, Optional
import importlib
import logging


class ModelRegistry:
    """æ¨¡å‹æ³¨å†Œè¡¨"""
    
    _registry: Dict[str, Type] = {}
    
    @classmethod
    def register(cls, name: str, model_class: Type):
        """
        æ³¨å†Œæ¨¡å‹
        
        Args:
            name: æ¨¡å‹åç§°
            model_class: æ¨¡å‹ç±»
        """
        cls._registry[name] = model_class
        logging.info(f"âœ… æ³¨å†Œæ¨¡å‹: {name} -> {model_class.__name__}")
    
    @classmethod
    def get(cls, name: str) -> Optional[Type]:
        """
        è·å–æ¨¡å‹ç±»
        
        Args:
            name: æ¨¡å‹åç§°
            
        Returns:
            æ¨¡å‹ç±»ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        return cls._registry.get(name)
    
    @classmethod
    def list_models(cls) -> list:
        """åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„æ¨¡å‹"""
        return list(cls._registry.keys())
    
    @classmethod
    def clear(cls):
        """æ¸…ç©ºæ³¨å†Œè¡¨"""
        cls._registry.clear()


def register_model(name: str):
    """
    æ¨¡å‹æ³¨å†Œè£…é¥°å™¨
    
    Example:
        @register_model('lstm')
        class LSTMModel(Model):
            pass
    
    Args:
        name: æ¨¡å‹åç§°
    """
    def decorator(model_class: Type):
        ModelRegistry.register(name, model_class)
        return model_class
    return decorator


class ModelFactory:
    """
    æ¨¡å‹å·¥å‚ - åŠ¨æ€åˆ›å»ºæ¨¡å‹å®ä¾‹
    
    å‚ç…§ Qlib çš„ init_instance_by_config è®¾è®¡
    """
    
    @staticmethod
    def create_model(config: Dict[str, Any]):
        """
        æ ¹æ®é…ç½®åˆ›å»ºæ¨¡å‹å®ä¾‹
        
        Args:
            config: æ¨¡å‹é…ç½®å­—å…¸ï¼ŒåŒ…å«:
                - class: æ¨¡å‹ç±»å
                - module_path: æ¨¡å‹æ¨¡å—è·¯å¾„ (å¯é€‰)
                - kwargs: æ¨¡å‹å‚æ•°
        
        Returns:
            æ¨¡å‹å®ä¾‹
            
        Example:
            config = {
                'class': 'LSTMModel',
                'module_path': 'quantclassic.model.pytorch_models',
                'kwargs': {
                    'd_feat': 20,
                    'hidden_size': 64,
                    'num_layers': 2
                }
            }
            model = ModelFactory.create_model(config)
        """
        if 'class' not in config:
            raise ValueError("é…ç½®ä¸­ç¼ºå°‘ 'class' å­—æ®µ")
        
        model_name = config['class']
        
        # 1. å°è¯•ä»æ³¨å†Œè¡¨è·å–
        model_class = ModelRegistry.get(model_name)
        
        # 2. å¦‚æœæ³¨å†Œè¡¨ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»æ¨¡å—è·¯å¾„å¯¼å…¥
        if model_class is None and 'module_path' in config:
            module_path = config['module_path']
            try:
                module = importlib.import_module(module_path)
                model_class = getattr(module, model_name)
            except (ImportError, AttributeError) as e:
                raise ImportError(
                    f"æ— æ³•ä» {module_path} å¯¼å…¥ {model_name}: {e}"
                )
        
        # 3. å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼ŒæŠ›å‡ºå¼‚å¸¸
        if model_class is None:
            raise ValueError(
                f"æ‰¾ä¸åˆ°æ¨¡å‹ '{model_name}'ã€‚"
                f"å·²æ³¨å†Œçš„æ¨¡å‹: {ModelRegistry.list_models()}"
            )
        
        # 4. åˆ›å»ºå®ä¾‹
        kwargs = config.get('kwargs', {})
        
        try:
            model = model_class(**kwargs)
            logging.info(f"âœ… åˆ›å»ºæ¨¡å‹: {model_name}")
            return model
        except Exception as e:
            raise RuntimeError(
                f"åˆ›å»ºæ¨¡å‹ {model_name} å¤±è´¥: {e}"
            )
    
    @staticmethod
    def create_from_yaml(yaml_path: str):
        """
        ä» YAML é…ç½®æ–‡ä»¶åˆ›å»ºæ¨¡å‹
        
        Args:
            yaml_path: YAML é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ¨¡å‹å®ä¾‹
        """
        import yaml
        
        with open(yaml_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        if 'model' not in config:
            raise ValueError("YAML é…ç½®ä¸­ç¼ºå°‘ 'model' å­—æ®µ")
        
        return ModelFactory.create_model(config['model'])


def init_instance_by_config(config: Dict[str, Any]):
    """
    æ ¹æ®é…ç½®åˆå§‹åŒ–å®ä¾‹ï¼ˆå…¼å®¹ Qlib æ¥å£ï¼‰
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        å®ä¾‹å¯¹è±¡
    """
    return ModelFactory.create_model(config)


def create_model_from_composite_config(config, d_feat: int = None):
    """
    ğŸ†• ä» CompositeModelConfig åˆ›å»ºæ¨¡å‹
    
    è¿™æ˜¯æ¨èçš„æ¨¡å‹åˆ›å»ºå…¥å£ï¼Œç»Ÿä¸€ä½¿ç”¨ CompositeModelConfigã€‚
    
    Args:
        config: CompositeModelConfig å¯¹è±¡æˆ–å­—å…¸
        d_feat: è¾“å…¥ç‰¹å¾ç»´åº¦ï¼ˆå¯é€‰ï¼Œè¦†ç›–é…ç½®ä¸­çš„å€¼ï¼‰
        
    Returns:
        æ¨¡å‹å®ä¾‹
        
    Example:
        from quantclassic.model.modular_config import CompositeModelConfig
        from quantclassic.model.model_factory import create_model_from_composite_config
        
        config = CompositeModelConfig(
            temporal=TemporalModuleConfig(rnn_type='lstm', hidden_size=64),
            graph=GraphModuleConfig(enabled=True, gat_type='standard'),
            d_feat=20
        )
        model = create_model_from_composite_config(config)
    """
    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•è½¬æ¢ä¸º CompositeModelConfig
    if isinstance(config, dict):
        try:
            from .modular_config import CompositeModelConfig
            config = CompositeModelConfig.from_dict(config)
        except Exception as e:
            logging.warning(f"æ— æ³•å°†å­—å…¸è½¬æ¢ä¸º CompositeModelConfig: {e}")
            # å›é€€åˆ°æ—§çš„å·¥å‚æ–¹æ³•
            return ModelFactory.create_model(config)
    
    # éªŒè¯é…ç½®
    if hasattr(config, 'validate'):
        config.validate()
    
    # æ ¹æ®é…ç½®åˆ›å»ºå¯¹åº”æ¨¡å‹
    use_graph = getattr(config, 'graph', None) and getattr(config.graph, 'enabled', False)
    
    if use_graph:
        from .hybrid_graph_models import HybridGraphModel
        return HybridGraphModel.from_config(config, d_feat=d_feat)
    else:
        # éå›¾æ¨¡å‹ï¼Œä½¿ç”¨åŸºç¡€ LSTM/GRU
        temporal_config = getattr(config, 'temporal', None)
        if temporal_config:
            rnn_type = getattr(temporal_config, 'rnn_type', 'lstm')
            if rnn_type == 'lstm':
                from .pytorch_models import LSTMModel
                return LSTMModel(
                    d_feat=d_feat or config.d_feat,
                    hidden_size=temporal_config.hidden_size,
                    num_layers=temporal_config.num_layers,
                    dropout=temporal_config.dropout,
                    n_epochs=config.n_epochs,
                    batch_size=config.batch_size,
                    lr=config.learning_rate,
                    early_stop=config.early_stop,
                    device=config.device,
                )
            elif rnn_type == 'gru':
                from .pytorch_models import GRUModel
                return GRUModel(
                    d_feat=d_feat or config.d_feat,
                    hidden_size=temporal_config.hidden_size,
                    num_layers=temporal_config.num_layers,
                    dropout=temporal_config.dropout,
                    n_epochs=config.n_epochs,
                    batch_size=config.batch_size,
                    lr=config.learning_rate,
                    early_stop=config.early_stop,
                    device=config.device,
                )
        
        # é»˜è®¤å›é€€åˆ° LSTM
        from .pytorch_models import LSTMModel
        return LSTMModel(
            d_feat=d_feat or getattr(config, 'd_feat', 20),
            n_epochs=getattr(config, 'n_epochs', 100),
            batch_size=getattr(config, 'batch_size', 256),
            lr=getattr(config, 'learning_rate', 0.001),
            early_stop=getattr(config, 'early_stop', 20),
            device=getattr(config, 'device', 'cuda'),
        )


if __name__ == '__main__':
    print("=" * 80)
    print("Model Factory æµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•æ³¨å†Œæœºåˆ¶
    from base_model import Model
    
    @register_model('test_model')
    class TestModel(Model):
        def __init__(self, param1, param2):
            super().__init__()
            self.param1 = param1
            self.param2 = param2
        
        def fit(self, train_data, valid_data=None, **kwargs):
            print(f"Training with {self.param1}, {self.param2}")
            self.fitted = True
        
        def predict(self, test_data, **kwargs):
            return "predictions"
    
    # æµ‹è¯•åˆ›å»ºæ¨¡å‹
    config = {
        'class': 'test_model',
        'kwargs': {
            'param1': 'value1',
            'param2': 'value2'
        }
    }
    
    model = ModelFactory.create_model(config)
    print(f"\nâœ… åˆ›å»ºæ¨¡å‹æˆåŠŸ: {model}")
    print(f"âœ… å‚æ•°: param1={model.param1}, param2={model.param2}")
    
    # æµ‹è¯•åˆ—å‡ºæ¨¡å‹
    print(f"\nå·²æ³¨å†Œçš„æ¨¡å‹: {ModelRegistry.list_models()}")
    
    print("\nâœ… Model Factory æµ‹è¯•å®Œæˆ")
