"""
build_industry_adj.py - æ„å»ºè¡Œä¸šé‚»æ¥çŸ©é˜µ

âš ï¸ DEPRECATED: æ­¤æ¨¡å—ä¸ºé™æ€åŸºå‡†å·¥å…·ï¼Œå»ºè®®ä½¿ç”¨ data_processor.graph_builder ä½œä¸ºç»Ÿä¸€å…¥å£ã€‚

æ¨èè¿ç§»æ–¹å¼:
    from quantclassic.data_processor.graph_builder import GraphBuilderFactory
    builder = GraphBuilderFactory.create({'type': 'industry', 'stock_col': 'ts_code'})
    adj = builder.build(df)

---

æ ¹æ®è´¢é€šç ”æŠ¥çš„è¦æ±‚ï¼ŒåŸºäºè¡Œä¸šåˆ†ç±»æ„å»ºé™æ€é‚»æ¥çŸ©é˜µï¼š
- åŒè¡Œä¸šè‚¡ç¥¨ä¹‹é—´ A[i,j] = 1
- ä¸åŒè¡Œä¸šè‚¡ç¥¨ä¹‹é—´ A[i,j] = 0

è¿™ç§é™æ€å›¾ç»“æ„é¿å…äº†ä½¿ç”¨ç›®æ ‡åˆ—ï¼ˆå¦‚ alpha_labelï¼‰åŠ¨æ€è®¡ç®—ç›¸å…³æ€§ï¼Œ
ä»è€Œé˜²æ­¢æ•°æ®æ³„éœ²å’Œè®­ç»ƒç›®æ ‡è€¦åˆé—®é¢˜ã€‚

Usage:
    from quantclassic.model.build_industry_adj import build_industry_adjacency_matrix
    
    adj_matrix, stock_list = build_industry_adjacency_matrix(
        df=df,
        stock_col='order_book_id',
        industry_col='industry_name',
        save_path='output/industry_adj_matrix.pt'
    )
"""

import warnings
import torch
import numpy as np
import pandas as pd
from typing import Tuple, Optional, List, Dict
from pathlib import Path
import logging


def build_industry_adjacency_matrix(
    df: pd.DataFrame,
    stock_col: str = 'order_book_id',
    industry_col: str = 'industry_name',
    save_path: Optional[str] = None,
    add_self_loop: bool = True,
    normalize: bool = False
) -> Tuple[torch.Tensor, List[str], Dict[str, int]]:
    """
    åŸºäºè¡Œä¸šåˆ†ç±»æ„å»ºé‚»æ¥çŸ©é˜µï¼ˆç ”æŠ¥ baselineï¼‰
    
    .. deprecated::
        æ­¤å‡½æ•°ä¸ºé—äº§åŸºå‡†å·¥å…·ï¼Œå»ºè®®ä½¿ç”¨ `data_processor.graph_builder.GraphBuilderFactory` ç»Ÿä¸€å…¥å£ã€‚
    
    åŒè¡Œä¸šè‚¡ç¥¨ä¹‹é—´è¿æ¥æƒé‡ä¸º 1ï¼Œä¸åŒè¡Œä¸šä¸º 0ã€‚
    
    Args:
        df: åŒ…å«è‚¡ç¥¨ä»£ç å’Œè¡Œä¸šä¿¡æ¯çš„ DataFrame
        stock_col: è‚¡ç¥¨ä»£ç åˆ—å
        industry_col: è¡Œä¸šåˆ†ç±»åˆ—å
        save_path: ä¿å­˜è·¯å¾„ï¼ˆ.pt æ ¼å¼ï¼‰ï¼ŒNone è¡¨ç¤ºä¸ä¿å­˜
        add_self_loop: æ˜¯å¦æ·»åŠ è‡ªç¯ï¼ˆå¯¹è§’çº¿ä¸º 1ï¼‰
        normalize: æ˜¯å¦å¯¹é‚»æ¥çŸ©é˜µè¿›è¡Œè¡Œå½’ä¸€åŒ–
        
    Returns:
        adj_matrix: [N, N] é‚»æ¥çŸ©é˜µ
        stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆé¡ºåºä¸çŸ©é˜µç´¢å¼•å¯¹åº”ï¼‰
        stock_to_idx: è‚¡ç¥¨ä»£ç åˆ°ç´¢å¼•çš„æ˜ å°„å­—å…¸
    """
    warnings.warn(
        "build_industry_adjacency_matrix å·²å¼ƒç”¨ï¼Œå»ºè®®ä½¿ç”¨ "
        "data_processor.graph_builder.GraphBuilderFactory.create({'type': 'industry'}) ä½œä¸ºç»Ÿä¸€å…¥å£",
        DeprecationWarning,
        stacklevel=2
    )
    logger = logging.getLogger(__name__)
    
    # 1. è·å–å”¯ä¸€è‚¡ç¥¨åˆ—è¡¨å’Œè¡Œä¸šä¿¡æ¯
    stock_industry = df[[stock_col, industry_col]].drop_duplicates(subset=[stock_col])
    stock_list = sorted(stock_industry[stock_col].unique().tolist())
    n_stocks = len(stock_list)
    
    # åˆ›å»ºè‚¡ç¥¨åˆ°ç´¢å¼•çš„æ˜ å°„
    stock_to_idx = {stock: i for i, stock in enumerate(stock_list)}
    
    # 2. åˆ›å»ºè‚¡ç¥¨åˆ°è¡Œä¸šçš„æ˜ å°„
    stock_to_industry = dict(zip(
        stock_industry[stock_col],
        stock_industry[industry_col]
    ))
    
    # 3. æ„å»ºé‚»æ¥çŸ©é˜µ
    adj_matrix = torch.zeros(n_stocks, n_stocks)
    
    # ç»Ÿè®¡è¡Œä¸šä¿¡æ¯
    industries = stock_industry[industry_col].unique()
    industry_counts = stock_industry[industry_col].value_counts()
    
    logger.info(f"æ„å»ºè¡Œä¸šé‚»æ¥çŸ©é˜µ:")
    logger.info(f"  è‚¡ç¥¨æ•°é‡: {n_stocks}")
    logger.info(f"  è¡Œä¸šæ•°é‡: {len(industries)}")
    
    # æŒ‰è¡Œä¸šåˆ†ç»„ï¼ŒåŒè¡Œä¸šè‚¡ç¥¨äº’ç›¸è¿æ¥
    for industry in industries:
        # è·å–è¯¥è¡Œä¸šçš„æ‰€æœ‰è‚¡ç¥¨
        industry_stocks = stock_industry[
            stock_industry[industry_col] == industry
        ][stock_col].tolist()
        
        # è·å–è‚¡ç¥¨ç´¢å¼•
        indices = [stock_to_idx[s] for s in industry_stocks if s in stock_to_idx]
        
        # åŒè¡Œä¸šè‚¡ç¥¨äº’ç›¸è¿æ¥
        for i in indices:
            for j in indices:
                if i != j or add_self_loop:  # å¯é€‰æ‹©æ˜¯å¦æ·»åŠ è‡ªç¯
                    adj_matrix[i, j] = 1.0
    
    # 4. æ·»åŠ è‡ªç¯
    if add_self_loop:
        adj_matrix.fill_diagonal_(1.0)
    
    # 5. å¯é€‰ï¼šè¡Œå½’ä¸€åŒ–
    if normalize:
        row_sum = adj_matrix.sum(dim=1, keepdim=True)
        row_sum[row_sum == 0] = 1  # é¿å…é™¤é›¶
        adj_matrix = adj_matrix / row_sum
    
    # 6. ç»Ÿè®¡è¿æ¥ä¿¡æ¯
    n_edges = (adj_matrix > 0).sum().item()
    avg_neighbors = n_edges / n_stocks
    
    logger.info(f"  æ€»è¾¹æ•°: {n_edges:,}")
    logger.info(f"  å¹³å‡é‚»å±…æ•°: {avg_neighbors:.1f}")
    logger.info(f"  çŸ©é˜µç¨€ç–åº¦: {1 - n_edges / (n_stocks * n_stocks):.2%}")
    
    # 7. ä¿å­˜
    if save_path:
        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜é‚»æ¥çŸ©é˜µå’Œå…ƒæ•°æ®
        torch.save({
            'adj_matrix': adj_matrix,
            'stock_list': stock_list,
            'stock_to_idx': stock_to_idx,
            'n_stocks': n_stocks,
            'n_industries': len(industries),
            'industry_counts': industry_counts.to_dict()
        }, save_path)
        
        logger.info(f"  å·²ä¿å­˜è‡³: {save_path}")
    
    return adj_matrix, stock_list, stock_to_idx


def build_correlation_adjacency_matrix(
    df: pd.DataFrame,
    stock_col: str = 'order_book_id',
    time_col: str = 'trade_date',
    return_col: str = 'close',  # ğŸ”´ æ³¨æ„ï¼šä¸è¦ä½¿ç”¨ç›®æ ‡åˆ—å¦‚ alpha_label
    top_k: int = 10,
    method: str = 'pearson',
    min_periods: int = 60,
    save_path: Optional[str] = None,
    add_self_loop: bool = True
) -> Tuple[torch.Tensor, List[str], Dict[str, int]]:
    """
    åŸºäºæ”¶ç›Šç‡ç›¸å…³æ€§æ„å»ºé‚»æ¥çŸ©é˜µï¼ˆç ”æŠ¥å¤‡é€‰æ–¹æ¡ˆï¼‰
    
    ğŸ”´ é‡è¦ï¼šä½¿ç”¨å†å²æ”¶ç›Šç‡ï¼ˆå¦‚ close çš„ pct_changeï¼‰è€Œéè®­ç»ƒç›®æ ‡åˆ—ï¼Œ
    é¿å…æ•°æ®æ³„éœ²ã€‚
    
    Args:
        df: åŒ…å«è‚¡ç¥¨æ—¶åºæ•°æ®çš„ DataFrame
        stock_col: è‚¡ç¥¨ä»£ç åˆ—å
        time_col: æ—¶é—´åˆ—å
        return_col: ç”¨äºè®¡ç®—ç›¸å…³æ€§çš„åˆ—ï¼ˆå»ºè®®ä½¿ç”¨ä»·æ ¼åˆ—ï¼Œä¼šè‡ªåŠ¨è®¡ç®—æ”¶ç›Šç‡ï¼‰
        top_k: æ¯åªè‚¡ç¥¨é€‰å–ç›¸å…³æ€§æœ€é«˜çš„ k ä¸ªé‚»å±…
        method: ç›¸å…³æ€§è®¡ç®—æ–¹æ³• ('pearson' æˆ– 'spearman')
        min_periods: è®¡ç®—ç›¸å…³æ€§æ‰€éœ€çš„æœ€å°è§‚æµ‹æ•°
        save_path: ä¿å­˜è·¯å¾„
        add_self_loop: æ˜¯å¦æ·»åŠ è‡ªç¯
        
    Returns:
        adj_matrix: [N, N] é‚»æ¥çŸ©é˜µ
        stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        stock_to_idx: è‚¡ç¥¨ä»£ç åˆ°ç´¢å¼•çš„æ˜ å°„
    """
    logger = logging.getLogger(__name__)
    
    # 1. æ„å»ºæ”¶ç›Šç‡çŸ©é˜µ
    logger.info(f"æ„å»ºç›¸å…³æ€§é‚»æ¥çŸ©é˜µ:")
    logger.info(f"  ç›¸å…³æ€§åˆ—: {return_col}")
    logger.info(f"  Top-K é‚»å±…: {top_k}")
    
    # Pivot æˆ [æ—¶é—´, è‚¡ç¥¨] æ ¼å¼
    pivot_df = df.pivot_table(
        index=time_col,
        columns=stock_col,
        values=return_col,
        aggfunc='last'
    )
    
    # å¦‚æœæ˜¯ä»·æ ¼åˆ—ï¼Œè®¡ç®—æ”¶ç›Šç‡
    if return_col in ['close', 'open', 'high', 'low', 'vwap']:
        pivot_df = pivot_df.pct_change()
    
    stock_list = sorted(pivot_df.columns.tolist())
    n_stocks = len(stock_list)
    stock_to_idx = {stock: i for i, stock in enumerate(stock_list)}
    
    logger.info(f"  è‚¡ç¥¨æ•°é‡: {n_stocks}")
    logger.info(f"  æ—¶é—´è·¨åº¦: {len(pivot_df)} å¤©")
    
    # 2. è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
    if method == 'pearson':
        corr_matrix = pivot_df[stock_list].corr(method='pearson', min_periods=min_periods)
    else:
        corr_matrix = pivot_df[stock_list].corr(method='spearman', min_periods=min_periods)
    
    # è½¬æ¢ä¸º numpy
    corr_values = corr_matrix.values
    corr_values = np.nan_to_num(corr_values, nan=0.0)
    
    # 3. æ„å»º Top-K é‚»æ¥çŸ©é˜µ
    adj_matrix = torch.zeros(n_stocks, n_stocks)
    
    for i in range(n_stocks):
        # è·å–ç¬¬ i åªè‚¡ç¥¨ä¸æ‰€æœ‰è‚¡ç¥¨çš„ç›¸å…³æ€§
        correlations = corr_values[i].copy()
        correlations[i] = -np.inf  # æ’é™¤è‡ªå·±
        
        # é€‰å– Top-K
        top_k_indices = np.argsort(correlations)[-top_k:]
        
        for j in top_k_indices:
            if correlations[j] > 0:  # åªä¿ç•™æ­£ç›¸å…³
                adj_matrix[i, j] = correlations[j]
    
    # 4. å¯¹ç§°åŒ–ï¼ˆå¯é€‰ï¼‰
    adj_matrix = (adj_matrix + adj_matrix.T) / 2
    
    # 5. æ·»åŠ è‡ªç¯
    if add_self_loop:
        adj_matrix.fill_diagonal_(1.0)
    
    # 6. ç»Ÿè®¡
    n_edges = (adj_matrix > 0).sum().item()
    logger.info(f"  æ€»è¾¹æ•°: {n_edges:,}")
    logger.info(f"  å¹³å‡é‚»å±…æ•°: {n_edges / n_stocks:.1f}")
    
    # 7. ä¿å­˜
    if save_path:
        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        torch.save({
            'adj_matrix': adj_matrix,
            'stock_list': stock_list,
            'stock_to_idx': stock_to_idx,
            'n_stocks': n_stocks,
            'method': method,
            'top_k': top_k
        }, save_path)
        
        logger.info(f"  å·²ä¿å­˜è‡³: {save_path}")
    
    return adj_matrix, stock_list, stock_to_idx


def load_adjacency_matrix(
    path: str,
    device: str = 'cuda'
) -> Tuple[torch.Tensor, List[str], Dict[str, int]]:
    """
    åŠ è½½é¢„æ„å»ºçš„é‚»æ¥çŸ©é˜µ
    
    Args:
        path: .pt æ–‡ä»¶è·¯å¾„
        device: ç›®æ ‡è®¾å¤‡
        
    Returns:
        adj_matrix, stock_list, stock_to_idx
    """
    data = torch.load(path, map_location=device)
    
    return (
        data['adj_matrix'],
        data['stock_list'],
        data['stock_to_idx']
    )


# ==================== å‘½ä»¤è¡Œæ¥å£ ====================

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='æ„å»ºè¡Œä¸š/ç›¸å…³æ€§é‚»æ¥çŸ©é˜µ')
    parser.add_argument('--data', type=str, required=True, help='æ•°æ®æ–‡ä»¶è·¯å¾„ (.parquet)')
    parser.add_argument('--output', type=str, default='output/industry_adj_matrix.pt', help='è¾“å‡ºè·¯å¾„')
    parser.add_argument('--type', type=str, choices=['industry', 'correlation'], default='industry',
                        help='é‚»æ¥çŸ©é˜µç±»å‹')
    parser.add_argument('--stock-col', type=str, default='order_book_id', help='è‚¡ç¥¨ä»£ç åˆ—å')
    parser.add_argument('--industry-col', type=str, default='industry_name', help='è¡Œä¸šåˆ—å')
    parser.add_argument('--top-k', type=int, default=10, help='ç›¸å…³æ€§çŸ©é˜µçš„ Top-K é‚»å±…æ•°')
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åŠ è½½æ•°æ®
    print(f"åŠ è½½æ•°æ®: {args.data}")
    df = pd.read_parquet(args.data)
    
    # æ„å»ºé‚»æ¥çŸ©é˜µ
    if args.type == 'industry':
        adj_matrix, stock_list, stock_to_idx = build_industry_adjacency_matrix(
            df=df,
            stock_col=args.stock_col,
            industry_col=args.industry_col,
            save_path=args.output
        )
    else:
        adj_matrix, stock_list, stock_to_idx = build_correlation_adjacency_matrix(
            df=df,
            stock_col=args.stock_col,
            return_col='close',  # ä½¿ç”¨æ”¶ç›˜ä»·è®¡ç®—æ”¶ç›Šç‡
            top_k=args.top_k,
            save_path=args.output
        )
    
    print(f"\nâœ… é‚»æ¥çŸ©é˜µæ„å»ºå®Œæˆï¼")
    print(f"   å½¢çŠ¶: {adj_matrix.shape}")
    print(f"   ä¿å­˜è‡³: {args.output}")
