"""
prediction_adapter.py - é¢„æµ‹ç»“æœé€‚é…å™¨

å°† RollingWindowTrainer çš„å¤šå› å­é¢„æµ‹ç»“æœè½¬æ¢ä¸º backtest æ ‡å‡†æ ¼å¼ã€‚
æ”¯æŒå¤šå› å­é›†æˆç­–ç•¥ï¼šç®€å•å¹³å‡ã€ICåŠ æƒã€æœ€ä½³å› å­é€‰æ‹©ç­‰ã€‚

Usage:
    from quantclassic.backtest.prediction_adapter import PredictionAdapter
    
    adapter = PredictionAdapter(config)
    backtest_df = adapter.adapt(
        rolling_predictions,
        stock_col='order_book_id',
        time_col='trade_date',
        label_col='y_ret_10d'
    )
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Union
from scipy.stats import spearmanr
import logging
from pathlib import Path

from .backtest_config import BacktestConfig


class PredictionAdapter:
    """
    é¢„æµ‹ç»“æœé€‚é…å™¨
    
    å°† RollingWindowTrainer.predict_all_windows() çš„è¾“å‡ºè½¬æ¢ä¸º backtest çš„æ ‡å‡†æ ¼å¼ã€‚
    æ”¯æŒå¤šå› å­é›†æˆä¸å•å› å­æ¨¡å¼ã€‚
    
    Features:
        - è‡ªåŠ¨è¯†åˆ«å¤šå› å­/å•å› å­è¾“å‡º
        - å¤šå› å­é›†æˆç­–ç•¥ï¼šmean, ic_weighted, best, custom_weights
        - åˆ—åæ˜ å°„ä¸æ ¼å¼è½¬æ¢
        - æ•°æ®è´¨é‡æ£€æŸ¥ä¸ä¿®å¤
    """
    
    def __init__(self, config: Optional[BacktestConfig] = None):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            config: å›æµ‹é…ç½®ï¼ˆå¯é€‰ï¼‰
        """
        self.config = config or BacktestConfig()
        self.logger = logging.getLogger(__name__)
        
        # å¤šå› å­é›†æˆç»“æœç¼“å­˜
        self._factor_ics: Dict[str, float] = {}
        self._ensemble_weights: Dict[str, float] = {}
    
    def adapt(
        self,
        predictions_df: pd.DataFrame,
        stock_col: str = 'order_book_id',
        time_col: str = 'trade_date',
        label_col: str = 'y_ret_10d',
        ensemble_method: str = 'mean',
        custom_weights: Optional[Dict[str, float]] = None,
        output_factor_col: str = 'factor_value'
    ) -> pd.DataFrame:
        """
        é€‚é…é¢„æµ‹ç»“æœä¸º backtest æ ‡å‡†æ ¼å¼
        
        Args:
            predictions_df: RollingWindowTrainer çš„é¢„æµ‹ç»“æœ DataFrame
            stock_col: åŸå§‹è‚¡ç¥¨åˆ—å
            time_col: åŸå§‹æ—¶é—´åˆ—å
            label_col: åŸå§‹æ ‡ç­¾åˆ—å
            ensemble_method: å¤šå› å­é›†æˆæ–¹æ³•
                - 'mean': ç®€å•å¹³å‡ï¼ˆé»˜è®¤ï¼‰
                - 'ic_weighted': IC åŠ æƒå¹³å‡
                - 'best': é€‰æ‹© IC æœ€é«˜çš„å› å­
                - 'custom': ä½¿ç”¨è‡ªå®šä¹‰æƒé‡
            custom_weights: è‡ªå®šä¹‰æƒé‡å­—å…¸ï¼ˆä»…å½“ ensemble_method='custom' æ—¶ä½¿ç”¨ï¼‰
            output_factor_col: è¾“å‡ºå› å­åˆ—å
            
        Returns:
            é€‚é…åçš„ DataFrameï¼ŒåŒ…å«æ ‡å‡†åˆ—åï¼š
            - ts_code: è‚¡ç¥¨ä»£ç 
            - trade_date: äº¤æ˜“æ—¥æœŸ
            - factor_raw / factor_value: åŸå§‹å› å­å€¼
            - y_true / y_processed: çœŸå®æ ‡ç­¾
            - ä»¥åŠå¯é€‰çš„ pred_factor_* åˆ—
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸ”„ å¼€å§‹é€‚é…é¢„æµ‹ç»“æœ")
        self.logger.info("=" * 60)
        
        df = predictions_df.copy()
        
        # 1. æ£€æµ‹å› å­åˆ—
        factor_cols = self._detect_factor_cols(df)
        self.logger.info(f"  æ£€æµ‹åˆ°å› å­åˆ—: {len(factor_cols)} ä¸ª")
        
        # 2. å¤šå› å­é›†æˆ
        if len(factor_cols) > 1:
            self.logger.info(f"  å¤šå› å­æ¨¡å¼ï¼Œä½¿ç”¨ {ensemble_method} é›†æˆ")
            df = self._ensemble_factors(
                df, factor_cols, label_col, time_col,
                method=ensemble_method,
                custom_weights=custom_weights,
                output_col=output_factor_col
            )
        elif len(factor_cols) == 1:
            self.logger.info(f"  å•å› å­æ¨¡å¼")
            df[output_factor_col] = df[factor_cols[0]]
        else:
            # å°è¯•æŸ¥æ‰¾ pred_alpha
            if 'pred_alpha' in df.columns:
                df[output_factor_col] = df['pred_alpha']
            else:
                raise ValueError("æœªæ‰¾åˆ°å› å­åˆ—ï¼ˆpred_factor_* æˆ– pred_alphaï¼‰")
        
        # 3. åˆ—åæ˜ å°„
        df = self._rename_columns(df, stock_col, time_col, label_col, output_factor_col)
        
        # 4. æ•°æ®è´¨é‡æ£€æŸ¥
        df = self._quality_check(df)
        
        # 5. æ‰“å°æ±‡æ€»
        self._print_summary(df)
        
        return df
    
    def _detect_factor_cols(self, df: pd.DataFrame) -> List[str]:
        """æ£€æµ‹å¤šå› å­åˆ—"""
        return [col for col in df.columns if col.startswith('pred_factor_')]
    
    def _ensemble_factors(
        self,
        df: pd.DataFrame,
        factor_cols: List[str],
        label_col: str,
        time_col: str,
        method: str = 'mean',
        custom_weights: Optional[Dict[str, float]] = None,
        output_col: str = 'factor_value'
    ) -> pd.DataFrame:
        """
        å¤šå› å­é›†æˆ
        
        Args:
            df: æ•°æ®
            factor_cols: å› å­åˆ—ååˆ—è¡¨
            label_col: æ ‡ç­¾åˆ—å
            time_col: æ—¶é—´åˆ—åï¼ˆç”¨äºè®¡ç®— ICï¼‰
            method: é›†æˆæ–¹æ³•
            custom_weights: è‡ªå®šä¹‰æƒé‡
            output_col: è¾“å‡ºåˆ—å
            
        Returns:
            æ·»åŠ é›†æˆå› å­åçš„ DataFrame
        """
        if method == 'mean':
            # ç®€å•å¹³å‡
            df[output_col] = df[factor_cols].mean(axis=1)
            self._ensemble_weights = {col: 1.0/len(factor_cols) for col in factor_cols}
            
        elif method == 'ic_weighted':
            # IC åŠ æƒå¹³å‡
            weights = self._calculate_ic_weights(df, factor_cols, label_col, time_col)
            df[output_col] = (df[factor_cols].values * weights).sum(axis=1)
            self._ensemble_weights = dict(zip(factor_cols, weights))
            
        elif method == 'best':
            # é€‰æ‹©æœ€ä½³å› å­
            ics = self._calculate_factor_ics(df, factor_cols, label_col, time_col)
            best_col = max(ics, key=ics.get)
            df[output_col] = df[best_col]
            self._ensemble_weights = {best_col: 1.0}
            self.logger.info(f"    æœ€ä½³å› å­: {best_col} (IC={ics[best_col]:.4f})")
            
        elif method == 'custom':
            if custom_weights is None:
                raise ValueError("custom æ–¹æ³•éœ€è¦æä¾› custom_weights")
            weights = np.array([custom_weights.get(col, 0) for col in factor_cols])
            # é˜²å¾¡æ€§æ£€æŸ¥ï¼šå¦‚æœæƒé‡ä¹‹å’Œä¸º 0ï¼Œå›é€€åˆ°ç­‰æƒé‡
            if weights.sum() > 0:
                weights = weights / weights.sum()
            else:
                self.logger.warning("    è‡ªå®šä¹‰æƒé‡ä¹‹å’Œä¸º 0ï¼Œå›é€€åˆ°ç­‰æƒé‡")
                weights = np.ones(len(factor_cols)) / len(factor_cols)
            df[output_col] = (df[factor_cols].values * weights).sum(axis=1)
            self._ensemble_weights = dict(zip(factor_cols, weights))
            
        else:
            raise ValueError(f"æœªçŸ¥çš„é›†æˆæ–¹æ³•: {method}")
        
        # åŒæ—¶ä¿ç•™å„å› å­çš„ IC åŠ æƒç‰ˆæœ¬ï¼ˆä¾›åç»­åˆ†æï¼‰
        if method != 'mean':
            df[f'{output_col}_mean'] = df[factor_cols].mean(axis=1)
        
        return df
    
    def _calculate_factor_ics(
        self,
        df: pd.DataFrame,
        factor_cols: List[str],
        label_col: str,
        time_col: str
    ) -> Dict[str, float]:
        """è®¡ç®—å„å› å­çš„ IC"""
        ics = {}
        
        for col in factor_cols:
            ic_values = []
            for date, group in df.groupby(time_col):
                if len(group) < 10:
                    continue
                pred = group[col].values
                label = group[label_col].values
                valid = ~(np.isnan(pred) | np.isnan(label))
                if valid.sum() < 10:
                    continue
                ic, _ = spearmanr(pred[valid], label[valid])
                if not np.isnan(ic):
                    ic_values.append(ic)
            
            ics[col] = np.mean(ic_values) if ic_values else 0.0
            self.logger.info(f"    {col}: IC = {ics[col]:.4f}")
        
        self._factor_ics = ics
        return ics
    
    def _calculate_ic_weights(
        self,
        df: pd.DataFrame,
        factor_cols: List[str],
        label_col: str,
        time_col: str
    ) -> np.ndarray:
        """è®¡ç®— IC åŠ æƒæƒé‡"""
        ics = self._calculate_factor_ics(df, factor_cols, label_col, time_col)
        
        # åªä½¿ç”¨æ­£ IC ä½œä¸ºæƒé‡
        weights = np.array([max(ics[col], 0) for col in factor_cols])
        
        if weights.sum() > 0:
            weights = weights / weights.sum()
        else:
            weights = np.ones(len(factor_cols)) / len(factor_cols)
        
        self.logger.info(f"    ICæƒé‡: {dict(zip(factor_cols, weights.round(3)))}")
        return weights
    
    def _rename_columns(
        self,
        df: pd.DataFrame,
        stock_col: str,
        time_col: str,
        label_col: str,
        factor_col: str
    ) -> pd.DataFrame:
        """åˆ—åæ˜ å°„åˆ° backtest æ ‡å‡†æ ¼å¼"""
        rename_map = {}
        
        # è‚¡ç¥¨åˆ—
        if stock_col in df.columns and stock_col != 'ts_code':
            rename_map[stock_col] = 'ts_code'
        
        # æ—¶é—´åˆ—
        if time_col in df.columns and time_col != 'trade_date':
            rename_map[time_col] = 'trade_date'
        
        # æ ‡ç­¾åˆ—
        if label_col in df.columns:
            rename_map[label_col] = 'y_true'
            df['y_processed'] = df[label_col]  # ä¿ç•™ä¸¤ä¸ªç‰ˆæœ¬
        
        # å› å­åˆ—
        if factor_col in df.columns:
            df['factor_raw'] = df[factor_col]
        
        if rename_map:
            df = df.rename(columns=rename_map)
        
        return df
    
    def _quality_check(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®è´¨é‡æ£€æŸ¥ä¸ä¿®å¤"""
        original_len = len(df)
        
        # ç¡®ä¿æ—¥æœŸæ ¼å¼
        if 'trade_date' in df.columns:
            df['trade_date'] = pd.to_datetime(df['trade_date'])
        
        # æ£€æŸ¥å¿…éœ€åˆ—
        required = ['ts_code', 'trade_date', 'factor_raw']
        missing = [col for col in required if col not in df.columns]
        if missing:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€åˆ—: {missing}")
        
        # ç§»é™¤å› å­ç¼ºå¤±çš„è¡Œ
        df = df.dropna(subset=['factor_raw'])
        
        dropped = original_len - len(df)
        if dropped > 0:
            self.logger.warning(f"  ç§»é™¤ {dropped} è¡Œç¼ºå¤±æ•°æ® ({dropped/original_len:.1%})")
        
        return df
    
    def _print_summary(self, df: pd.DataFrame):
        """æ‰“å°é€‚é…ç»“æœæ±‡æ€»"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info("âœ… é€‚é…å®Œæˆ")
        self.logger.info("=" * 60)
        self.logger.info(f"  æ•°æ®å½¢çŠ¶: {df.shape}")
        self.logger.info(f"  æ—¶é—´èŒƒå›´: {df['trade_date'].min()} ~ {df['trade_date'].max()}")
        self.logger.info(f"  è‚¡ç¥¨æ•°é‡: {df['ts_code'].nunique()}")
        self.logger.info(f"  è¾“å‡ºåˆ—: {list(df.columns)}")
    
    def get_factor_ics(self) -> Dict[str, float]:
        """è·å–å„å› å­çš„ IC"""
        return self._factor_ics
    
    def get_ensemble_weights(self) -> Dict[str, float]:
        """è·å–é›†æˆæƒé‡"""
        return self._ensemble_weights
    
    def save_adapted_data(
        self,
        df: pd.DataFrame,
        output_path: str,
        format: str = 'parquet'
    ):
        """ä¿å­˜é€‚é…åçš„æ•°æ®"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        if format == 'parquet':
            df.to_parquet(output_path, index=False)
        elif format == 'csv':
            df.to_csv(output_path, index=False)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")
        
        self.logger.info(f"  ğŸ’¾ å·²ä¿å­˜: {output_path}")


# ==================== ä¾¿æ·å‡½æ•° ====================

def adapt_predictions(
    predictions_df: pd.DataFrame,
    stock_col: str = 'order_book_id',
    time_col: str = 'trade_date',
    label_col: str = 'y_ret_10d',
    ensemble_method: str = 'mean'
) -> pd.DataFrame:
    """
    ä¾¿æ·å‡½æ•°ï¼šå¿«é€Ÿé€‚é…é¢„æµ‹ç»“æœ
    
    Example:
        from quantclassic.backtest.prediction_adapter import adapt_predictions
        
        backtest_df = adapt_predictions(
            rolling_predictions,
            stock_col='order_book_id',
            time_col='trade_date',
            label_col='y_ret_10d'
        )
    """
    adapter = PredictionAdapter()
    return adapter.adapt(
        predictions_df,
        stock_col=stock_col,
        time_col=time_col,
        label_col=label_col,
        ensemble_method=ensemble_method
    )
